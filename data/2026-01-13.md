<div id=toc></div>

# Table of Contents

- [math.CV](#math.CV) [Total: 3]
- [cs.RO](#cs.RO) [Total: 9]
- [cs.LG](#cs.LG) [Total: 38]
- [cs.AI](#cs.AI) [Total: 22]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 5]


<div id='math.CV'></div>

# math.CV [[Back]](#toc)

### [1] [Non-extendability of complex structures](https://arxiv.org/abs/2601.05568)
*Zizhou Tang,Wenjiao Yan*

Main category: math.CV

TL;DR: 论文证明了S^6上存在一个全局的几乎复结构，该结构在S^3_δ×S^3子集上可定义，但任何扩展到S^6的几乎复结构都必然是非可积的，因此无法通过固定子集上的结构来变形为可积几乎复结构。


<details>
  <summary>Details</summary>
Motivation: 研究S^6上几乎复结构的可积性问题，特别是验证丘成桐在其问题52中提出的变形策略是否能在S^6上实现。S^6作为6维球面，其是否存在可积的几乎复结构是一个长期未解决的几何问题。

Method: 首先在连通开子集S^3_δ×S^3上构造一个复结构J，然后证明该结构可以扩展到S^6上的全局几乎复结构~J。通过分析扩展的性质，证明任何这样的扩展都必然是非可积的。

Result: (1) 成功将S^3_δ×S^3上的复结构J扩展到S^6上的全局几乎复结构~J；(2) 证明任何这样的扩展都是非可积的；(3) 因此无法通过固定S^3_δ×S^3上的结构来将~J变形为可积几乎复结构。

Conclusion: 丘成桐问题52中建议的变形策略在S^6上无法实现，因为任何从S^3_δ×S^3扩展到S^6的几乎复结构都必然是非可积的，这排除了通过固定子集结构来获得可积几乎复结构的可能性。

Abstract: There exists a complex structure $J$ on a connected open subset $S^3_δ\times S^3$ of $S^6$. The present paper proves that: (1) $J$ can be extended to a global almost complex structure $\widetilde{J}$ on $S^6$; (2) any extension to $S^6$ is necessarily non-integrable. Therefore, it is impossible to deform $\widetilde{J}$ to an integrable almost complex structure on $S^6$ while fixing it on $S^3_δ\times S^3$. This phenomenon indicates that the deformation strategy suggested by S.-T. Yau in his Problem 52 cannot be realized in this sense.

</details>


### [2] [Sharp Bounds for $q$-Starlike Functions and Their Classical Counterparts](https://arxiv.org/abs/2601.05625)
*S. Sivaprasad Kumar,S. Pannu*

Main category: math.CV

TL;DR: 引入两个新的解析函数子类：与Ma-Minda函数相关的q-星形函数类及其经典对应类，并系统研究其几何性质


<details>
  <summary>Details</summary>
Motivation: 几何函数理论越来越多地使用q-微积分来建模离散和量子启发现象，这促使引入新的函数类来研究相关性质

Method: 定义两个新的解析函数子类：$\mathcal{S}^{*}_{ξ_q}$（q-星形函数，与Ma-Minda函数$ξ_q(z)$相关）和$\mathcal{S}^{*}_ξ$（经典对应类，与$ξ(z)$相关），其中$q \in (0,1)$。对这些函数类进行系统研究

Result: 建立了尖锐的系数估计，包括Fekete-Szegö、Kruskal和Zalcman型不等式。获得了两个函数类的Hankel和Toeplitz行列式的尖锐界

Conclusion: 成功引入了两个新的解析函数子类，并系统研究了它们的几何性质，获得了多种尖锐的系数估计和行列式界，为几何函数理论中的q-微积分应用提供了新的研究框架

Abstract: Geometric function theory increasingly draws on $q$-calculus to model discrete and quantum-inspired phenomena. Motivated by this, the present paper introduces two new subclasses of analytic functions: the class $\mathcal{S}^{*}_{ξ_q}$ of $q$-starlike functions associated with the Ma-Minda function $ξ_q(z)$, and its classical counterpart $\mathcal{S}^{*}_ξ$ associated with $ξ(z)$, where $q \in (0,1)$. We conduct a systematic investigation of the geometric properties of these function classes and establish sharp coefficient estimates, including Fekete-Szegö, Kruskal, and Zalcman-type inequalities. Furthermore, we obtain sharp bounds of Hankel and Toeplitz determinants for both classes.

</details>


### [3] [A Comparison Test for Meromorphic Extensions](https://arxiv.org/abs/2601.05896)
*Adi Glücksam,Yuzhou Joey Zou*

Main category: math.CV

TL;DR: 论文提出了一种亚纯延拓的比较检验法：若两个级数"足够接近"，则其中一个在整个复平面上的亚纯延拓可保证另一个也有类似延拓。作者用此结果生成了新的具有亚纯延拓的Dirichlet级数例子，并证明其条件是优化的，构造了"接近但不够接近"的反例。


<details>
  <summary>Details</summary>
Motivation: 研究亚纯延拓的存在性问题，特别是如何通过已知具有亚纯延拓的级数来推断其他"接近"级数的延拓性质。旨在建立一种比较检验法，为判断Dirichlet级数等特殊函数的亚纯延拓提供新工具。

Method: 提出亚纯延拓的比较检验法，通过量化两个级数之间的"接近程度"来建立延拓传递性。使用该方法生成新的Dirichlet级数亚纯延拓例子。构造反例集合来证明条件的优化性，展示"接近但不够接近"时一个级数有亚纯延拓而另一个有自然边界的情况。

Result: 建立了亚纯延拓的比较检验定理，证明了若两个级数满足特定接近条件，则一个的亚纯延拓可保证另一个的类似延拓。生成了新的具有亚纯延拓的Dirichlet级数实例。通过构造的反例证明了所提条件的优化性，即条件不能进一步放宽。

Conclusion: 成功发展了一种有效的亚纯延拓比较检验法，为研究特殊函数的解析延拓提供了新工具。证明了该方法的实用价值（生成新例子）和理论完备性（条件优化）。反例构造表明所提条件是最优的，不能进一步弱化。

Abstract: We provide a comparison test for meromorphic extensions, i.e., if two series are ``close enough" then the existence of a meromorphic extension of one to the entire complex plane ensures a similar extension for the other. We use this result to generate new examples of Dirichlet series admitting meromorphic extensions. We demonstrate that our requirements are optimal: we construct a collection of counterexamples where the series are ``close but not enough" one series admits a meromorphic extension while the other possesses a natural boundary.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [4] [Intent at a Glance: Gaze-Guided Robotic Manipulation via Foundation Models](https://arxiv.org/abs/2601.05336)
*Tracey Yee Hsin Tay,Xu Yan,Jonathan Ouyang,Daniel Wu,William Jiang,Jonathan Kao,Yuchen Cui*

Main category: cs.RO

TL;DR: GAMMA系统利用眼动追踪和视觉语言模型推断用户意图，实现机器人自主操作，无需任务特定训练


<details>
  <summary>Details</summary>
Motivation: 设计直观的机器人控制界面是促进人机交互的关键挑战，特别是在辅助护理场景中。眼动注视提供快速、非侵入且富含意图的输入方式，是传达用户目标的理想通道。

Method: GAMMA系统结合自我中心眼动追踪和视觉语言模型，通过将注视点置于场景上下文中，将视觉注意力映射到高层语义理解，实现技能选择和参数化，无需任务特定训练。

Result: 在桌面操作任务评估中，GAMMA相比无推理的基线眼动控制表现出色，提供鲁棒、直观且可泛化的控制，证明了基础模型与眼动结合在自然可扩展机器人自主性方面的潜力。

Conclusion: GAMMA展示了结合基础模型和眼动追踪实现自然、可扩展机器人自主控制的潜力，为辅助护理等场景提供了直观的人机交互界面。

Abstract: Designing intuitive interfaces for robotic control remains a central challenge in enabling effective human-robot interaction, particularly in assistive care settings. Eye gaze offers a fast, non-intrusive, and intent-rich input modality, making it an attractive channel for conveying user goals. In this work, we present GAMMA (Gaze Assisted Manipulation for Modular Autonomy), a system that leverages ego-centric gaze tracking and a vision-language model to infer user intent and autonomously execute robotic manipulation tasks. By contextualizing gaze fixations within the scene, the system maps visual attention to high-level semantic understanding, enabling skill selection and parameterization without task-specific training. We evaluate GAMMA on a range of table-top manipulation tasks and compare it against baseline gaze-based control without reasoning. Results demonstrate that GAMMA provides robust, intuitive, and generalizable control, highlighting the potential of combining foundation models and gaze for natural and scalable robot autonomy. Project website: https://gamma0.vercel.app/

</details>


### [5] [Assembling Solar Panels by Dual Robot Arms Towards Full Autonomous Lunar Base Construction](https://arxiv.org/abs/2601.05491)
*Luca Nunziante,Kentaro Uno,Gustavo H. Diaz,Shreya Santra,Alessandro De Luca,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本文提出了一种用于月球基地建设的自主双机械臂机器人系统，专注于太阳能电池板模块的组装任务，实现了视觉、控制和硬件系统的集成。


<details>
  <summary>Details</summary>
Motivation: 随着人类重返月球的计划，需要在月球上建立前哨站，其中机器人系统对于安全高效地建立基础设施（如太阳能发电塔）至关重要。类似于国际空间站的建设，通过模块运输和现场组装是实际可行的方案。

Method: 开发了专门为组装太阳能电池板模块设计的感知和控制流程，设计了专用硬件并在真实世界实验中测试。使用了模块化太阳能电池板模拟件和主动-被动连接器，并将抓取夹具的控制集成到提出的流程中。

Result: 成功实现了双机械臂机器人系统能够有效连接任意放置的太阳能电池板，展示了在复杂空间应用中视觉、控制和硬件系统的无缝集成。

Conclusion: 该研究证明了自主双机械臂系统在月球基础设施组装任务中的可行性，为未来太空应用中的机器人系统集成提供了重要参考。

Abstract: Since the successful Apollo program, humanity is once again aiming to return to the Moon for scientific discovery, resource mining, and inhabitation. Upcoming decades focus on building a lunar outpost, with robotic systems playing a crucial role to safely and efficiently establish essential infrastructure such as solar power generating towers. Similar to the construction of the International Space Station (ISS), shipping necessary components via modules and assembling them in situ should be a practical scenario. In this context, this paper focuses on the integration of vision, control, and hardware systems within an autonomous sequence for a dual-arm robot system. We explore a perception and control pipeline specifically designed for assembling solar panel modules, one of the benchmark tasks. Ad hoc hardware was designed and tested in real-world experiments. A mock-up of modular solar panels and active-passive connectors are employed, with the control of this grappling fixture integrated into the proposed pipeline. The successful implementation of our method demonstrates that the two robot manipulators can effectively connect arbitrarily placed panels, highlighting the seamless integration of vision, control, and hardware systems in complex space applications.

</details>


### [6] [TOSC: Task-Oriented Shape Completion for Open-World Dexterous Grasp Generation from Partial Point Clouds](https://arxiv.org/abs/2601.05499)
*Weishang Wu,Yifei Shi,Zhiping Cai*

Main category: cs.RO

TL;DR: 提出FlowGrasp方法，通过任务导向的形状补全来改善严重部分观测下的灵巧抓取，利用基础模型生成候选补全，通过判别自编码器优化，再生成任务导向的抓取姿态


<details>
  <summary>Details</summary>
Motivation: 在严重部分观测下，通用形状补全方法因缺失数据过多而失效，需要针对抓取任务进行专门的形状补全，关注潜在接触区域而非完整形状

Method: 1) 利用预训练基础模型的零样本能力生成多个任务导向形状补全候选；2) 提出3D判别自编码器评估候选合理性并全局优化；3) 开发FlowGrasp条件流匹配模型从优化形状生成任务导向灵巧抓取

Result: 在任务导向灵巧抓取和形状补全任务上达到SOTA，Grasp Displacement和Chamfer Distance分别提升16.17%和55.26%，在严重缺失数据下表现良好，对开放集类别和任务具有良好泛化性

Conclusion: 任务导向形状补全能有效解决严重部分观测下的抓取问题，通过结合基础模型的功能理解和判别优化，FlowGrasp方法在开放世界物体操作中展现出优越性能

Abstract: Task-oriented dexterous grasping remains challenging in robotic manipulations of open-world objects under severe partial observation, where significant missing data invalidates generic shape completion. In this paper, to overcome this limitation, we study Task-Oriented Shape Completion, a new task that focuses on completing the potential contact regions rather than the entire shape. We argue that shape completion for grasping should be explicitly guided by the downstream manipulation task. To achieve this, we first generate multiple task-oriented shape completion candidates by leveraging the zero-shot capabilities of object functional understanding from several pre-trained foundation models. A 3D discriminative autoencoder is then proposed to evaluate the plausibility of each generated candidate and optimize the most plausible one from a global perspective. A conditional flow-matching model named FlowGrasp is developed to generate task-oriented dexterous grasps from the optimized shape. Our method achieves state-of-the-art performance in task-oriented dexterous grasping and task-oriented shape completion, improving the Grasp Displacement and the Chamfer Distance over the state-of-the-art by 16.17\% and 55.26%, respectively. In particular, it shows good capabilities in grasping objects with severe missing data. It also demonstrates good generality in handling open-set categories and tasks.

</details>


### [7] [Learning specifications for reactive synthesis with safety constraints](https://arxiv.org/abs/2601.05533)
*Kandai Watanabe,Nicholas Renninger,Sriram Sankaranarayanan,Morteza Lahijanian*

Main category: cs.RO

TL;DR: 提出一种从演示中学习的新方法，通过概率形式语言建模潜在任务，结合安全约束学习和反应式合成框架，使机器人能在动态环境中自主执行复杂任务。


<details>
  <summary>Details</summary>
Motivation: 使机器人能够从演示中学习复杂任务并在动态环境中自主执行，同时平衡机器人成本与用户任务偏好，确保学习过程始终遵守安全约束。

Method: 1) 将潜在任务建模为概率形式语言；2) 引入安全约束学习，将形式任务规范推断为概率确定性有限自动机(PDFA)；3) 采用证据驱动的状态合并算法并整合安全要求；4) 提出多目标反应式合成算法，将交互建模为机器人与环境的两玩家博弈；5) 开发计算可行的值迭代算法生成帕累托前沿和确定性策略。

Result: 实验结果表明，该方法在各种机器人和任务中均有效：学习的PDFA从不包含不安全行为，合成的策略始终能完成任务，同时满足机器人成本和用户偏好要求。

Conclusion: 该方法成功实现了从演示中安全学习复杂任务规范，并通过多目标反应式合成生成最优策略，使机器人能在动态环境中自主执行任务，平衡安全、成本和用户偏好。

Abstract: This paper presents a novel approach to learning from demonstration that enables robots to autonomously execute complex tasks in dynamic environments. We model latent tasks as probabilistic formal languages and introduce a tailored reactive synthesis framework that balances robot costs with user task preferences. Our methodology focuses on safety-constrained learning and inferring formal task specifications as Probabilistic Deterministic Finite Automata (PDFA). We adapt existing evidence-driven state merging algorithms and incorporate safety requirements throughout the learning process to ensure that the learned PDFA always complies with safety constraints. Furthermore, we introduce a multi-objective reactive synthesis algorithm that generates deterministic strategies that are guaranteed to satisfy the PDFA task while optimizing the trade-offs between user preferences and robot costs, resulting in a Pareto front of optimal solutions. Our approach models the interaction as a two-player game between the robot and the environment, accounting for dynamic changes. We present a computationally-tractable value iteration algorithm to generate the Pareto front and the corresponding deterministic strategies. Comprehensive experimental results demonstrate the effectiveness of our algorithms across various robots and tasks, showing that the learned PDFA never includes unsafe behaviors and that synthesized strategies consistently achieve the task while meeting both the robot cost and user-preference requirements.

</details>


### [8] [EvoQRE: Modeling Bounded Rationality in Safety-Critical Traffic Simulation via Evolutionary Quantal Response Equilibrium](https://arxiv.org/abs/2601.05653)
*Phu-Hoa Pham,Chi-Nguyen Tran,Duy-Minh Dao-Sy,Phu-Quy Nguyen-Lam,Trung-Kiet Huynh*

Main category: cs.RO

TL;DR: EvoQRE：基于量子响应均衡和演化博弈动力学的交通交互建模框架，用于模拟有界理性的人类驾驶行为，在安全关键场景中实现最先进的真实性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶交通仿真框架通常基于模仿学习或博弈论方法，假设完美理性智能体，但人类驾驶员实际上表现出有界理性，在认知和感知约束下做出近似最优决策。需要更准确地建模人类驾驶行为，特别是在安全关键的交通交互场景中。

Method: 提出EvoQRE框架，将安全关键交通交互建模为一般和马尔可夫博弈，通过量子响应均衡（QRE）和演化博弈动力学求解。框架整合预训练的生成世界模型与熵正则化的复制动力学，捕捉随机人类行为同时保持均衡结构。提供严格理论证明，在弱单调性假设下，所提动力学以O(log k / k^{1/3})收敛率收敛到Logit-QRE。进一步将QRE扩展到连续动作空间，使用基于混合和基于能量的策略表示。

Result: 在Waymo Open Motion Dataset和nuPlan基准测试上的实验表明，EvoQRE实现了最先进的真实性、改进的安全指标，以及通过可解释的理性参数可控生成多样化的安全关键场景。

Conclusion: EvoQRE提供了一个原则性框架，用于建模有界理性的人类驾驶行为，通过量子响应均衡和演化博弈动力学，在安全关键的交通交互中实现了更真实、更安全的仿真，为自动驾驶系统测试和验证提供了有效工具。

Abstract: Existing traffic simulation frameworks for autonomous vehicles typically rely on imitation learning or game-theoretic approaches that solve for Nash or coarse correlated equilibria, implicitly assuming perfectly rational agents. However, human drivers exhibit bounded rationality, making approximately optimal decisions under cognitive and perceptual constraints. We propose EvoQRE, a principled framework for modeling safety-critical traffic interactions as general-sum Markov games solved via Quantal Response Equilibrium (QRE) and evolutionary game dynamics. EvoQRE integrates a pre-trained generative world model with entropy-regularized replicator dynamics, capturing stochastic human behavior while maintaining equilibrium structure. We provide rigorous theoretical results, proving that the proposed dynamics converge to Logit-QRE under a two-timescale stochastic approximation with an explicit convergence rate of O(log k / k^{1/3}) under weak monotonicity assumptions. We further extend QRE to continuous action spaces using mixture-based and energy-based policy representations. Experiments on the Waymo Open Motion Dataset and nuPlan benchmark demonstrate that EvoQRE achieves state-of-the-art realism, improved safety metrics, and controllable generation of diverse safety-critical scenarios through interpretable rationality parameters.

</details>


### [9] [Motion Compensation for Real Time Ultrasound Scanning in Robotically Assisted Prostate Biopsy Procedures](https://arxiv.org/abs/2601.05661)
*Matija Markulin,Luka Matijević,Luka Siktar,Janko Jurdana,Branimir Caran,Marko Švaco,Filip Šuligoj,Bojan Šekoranja*

Main category: cs.RO

TL;DR: 开发用于前列腺超声检查的机器人辅助系统，通过自主扫描和运动补偿实现前列腺三维重建，为活检规划提供支持


<details>
  <summary>Details</summary>
Motivation: 前列腺癌诊断依赖专家操作，结果具有高度操作者依赖性。需要开发机器人系统来降低操作要求，实现更快、更准确、更可及的前列腺活检

Method: 使用协作机器人臂自主扫描前列腺模型，通过运动补偿保持超声探头与前列腺的相对位置恒定。对每个切片进行分割生成前列腺轮廓，转换为3D点云用于活检规划

Result: 平均扫描时间30秒，3D重建时间3秒。在四种运动场景下（静止、水平、垂直、组合运动），ICP配准显示平均适应度79.4%-84.1%，RMSE 0.35-0.37mm。最大跟踪误差3mm，最大运动补偿延迟0.5秒

Conclusion: 开发的机器人系统能够有效补偿患者运动，实现前列腺的稳定三维重建，误差在医学可接受范围内，为前列腺活检规划提供了可靠的技术基础

Abstract: Prostate cancer is one of the most common types of cancer in men. Its diagnosis by biopsy requires a high level of expertise and precision from the surgeon, so the results are highly operator-dependent. The aim of this work is to develop a robotic system for assisted ultrasound (US) examination of the prostate, a prebiopsy step that could reduce the dexterity requirements and enable faster, more accurate and more available prostate biopsy. We developed and validated a laboratory setup with a collaborative robotic arm that can autonomously scan a prostate phantom and attached the phantom to a medical robotic arm that mimics the patient's movements. The scanning robot keeps the relative position of the US probe and the prostate constant, ensuring a consistent and robust approach to reconstructing the prostate. To reconstruct the prostate, each slice is segmented to generate a series of prostate contours converted into a 3D point cloud used for biopsy planning. The average scan time of the prostate was 30 s, and the average 3D reconstruction of the prostate took 3 s. We performed four motion scenarios: the phantom was scanned in a stationary state (S), with horizontal motion (H), with vertical motion (V), and with a combination of the two (C). System validation is performed by registering the prostate point cloud reconstructions acquired during different motions (H, V, C) with those obtained in the stationary state. ICP registration with a threshold of 0.8 mm yields mean 83.2\% fitness and 0.35 mm RMSE for S-H registration, 84.1\% fitness and 0.37 mm RMSE for S-V registration and 79.4\% fitness and 0.37 mm RMSE for S-C registration. Due to the elastic and soft material properties of the prostate phantom, the maximum robot tracking error was 3 mm, which can be sufficient for prostate biopsy according to medical literature. The maximum delay in motion compensation was 0.5 s.

</details>


### [10] [InsSo3D: Inertial Navigation System and 3D Sonar SLAM for turbid environment inspection](https://arxiv.org/abs/2601.05805)
*Simon Archieri,Ahmet Cinar,Shu Pan,Jonatan Scharff Willners,Michele Grimald,Ignacio Carlucho,Yvan Petillot*

Main category: cs.RO

TL;DR: InsSo3D是一种用于大规模3D SLAM的准确高效方法，结合3D声纳和惯性导航系统，解决了传统声纳缺乏高程信息的问题，在浑浊水下环境中实现精确建图和定位。


<details>
  <summary>Details</summary>
Motivation: 传统声纳只能生成包含距离和方位信息的2D图像，缺乏高程信息，存在高程模糊问题。3D声纳能生成3D点云，但需要适应其特性的SLAM框架来充分利用这一优势，特别是在浑浊水下环境中实现精确的定位和建图。

Method: 提出InsSo3D方法，将3D声纳数据与惯性导航系统先验信息结合，构建稳健的现代SLAM框架。系统包括闭环检测和位姿图优化功能，专门针对3D声纳数据特性进行适配。

Result: 在测试水箱（有地面真值数据）和室外淹没采石场进行评估。与水下运动跟踪系统和视觉SFM获得的参考轨迹和地图对比显示，InsSo3D能有效校正里程计漂移。50分钟任务的轨迹平均误差低于21cm，生成10m×20m地图的平均重建误差为9cm。

Conclusion: InsSo3D能够在浑浊水下条件下实现精确的3D定位和建图，为自然或人工水下结构的安全检查提供了有效解决方案，证明了3D声纳与INS结合在恶劣水下环境中的实用价值。

Abstract: This paper presents InsSo3D, an accurate and efficient method for large-scale 3D Simultaneous Localisation and Mapping (SLAM) using a 3D Sonar and an Inertial Navigation System (INS). Unlike traditional sonar, which produces 2D images containing range and azimuth information but lacks elevation information, 3D Sonar produces a 3D point cloud, which therefore does not suffer from elevation ambiguity. We introduce a robust and modern SLAM framework adapted to the 3D Sonar data using INS as prior, detecting loop closure and performing pose graph optimisation. We evaluated InsSo3D performance inside a test tank with access to ground truth data and in an outdoor flooded quarry. Comparisons to reference trajectories and maps obtained from an underwater motion tracking system and visual Structure From Motion (SFM) demonstrate that InsSo3D efficiently corrects odometry drift. The average trajectory error is below 21cm during a 50-minute-long mission, producing a map of 10m by 20m with a 9cm average reconstruction error, enabling safe inspection of natural or artificial underwater structures even in murky water conditions.

</details>


### [11] [Modular Autonomy with Conversational Interaction: An LLM-driven Framework for Decision Making in Autonomous Driving](https://arxiv.org/abs/2601.05806)
*Marvin Seegert,Korbinian Moller,Johannes Betz*

Main category: cs.RO

TL;DR: 该论文提出了一个将大型语言模型集成到自动驾驶系统中的框架，通过领域特定语言和安全验证层，实现自然语言指令到结构化动作的映射。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的发展为自动驾驶系统提供了创建自然语言界面的新机会，但需要解决人类语言复杂性到结构化动作空间的映射挑战，超越传统刚性输入方式。

Method: 提出一个集成LLM交互层与Autoware自动驾驶软件的三组件框架：1) 交互类别分类法；2) 应用为中心的领域特定语言进行指令翻译；3) 安全保护验证层。采用两阶段LLM架构确保高透明度。

Result: 评估确认系统的时间效率和翻译鲁棒性。仿真成功验证了所有五个交互类别的指令执行，为可扩展的DSL辅助交互提供了基础。

Conclusion: 该工作为模块化和安全意识的自动驾驶堆栈中的可扩展、DSL辅助交互奠定了基础，实现了从查询状态信息到修改驾驶行为的高层自然语言控制。

Abstract: Recent advancements in Large Language Models (LLMs) offer new opportunities to create natural language interfaces for Autonomous Driving Systems (ADSs), moving beyond rigid inputs. This paper addresses the challenge of mapping the complexity of human language to the structured action space of modular ADS software. We propose a framework that integrates an LLM-based interaction layer with Autoware, a widely used open-source software. This system enables passengers to issue high-level commands, from querying status information to modifying driving behavior. Our methodology is grounded in three key components: a taxonomization of interaction categories, an application-centric Domain Specific Language (DSL) for command translation, and a safety-preserving validation layer. A two-stage LLM architecture ensures high transparency by providing feedback based on the definitive execution status. Evaluation confirms the system's timing efficiency and translation robustness. Simulation successfully validated command execution across all five interaction categories. This work provides a foundation for extensible, DSL-assisted interaction in modular and safety-conscious autonomy stacks.

</details>


### [12] [Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning](https://arxiv.org/abs/2601.05836)
*Sheng-Kai Chen,Jyh-Horng Wu*

Main category: cs.RO

TL;DR: 提出了一种结合模糊逻辑安全系统和强化学习算法的UR10机械臂路径规划方法，用于奇异点检测与避让，实现90%的成功率


<details>
  <summary>Details</summary>
Motivation: 解决机械臂操作中奇异点导致的控制失稳和设备损坏问题，提高路径规划的安全性和可靠性

Method: 采用混合方法：实时奇异点检测（可操作性度量、条件数分析）、模糊逻辑决策系统、强化学习框架进行自适应路径规划，结合PyBullet仿真训练和URSim实际部署

Result: 实验结果显示系统在保持与奇异配置安全距离的同时，达到目标位置的成功率为90%

Conclusion: 提出的混合方法有效解决了机械臂奇异点问题，结合模糊逻辑和强化学习实现了安全可靠的路径规划

Abstract: This paper presents a comprehensive approach to singularity detection and avoidance in UR10 robotic arm path planning through the integration of fuzzy logic safety systems and reinforcement learning algorithms. The proposed system addresses critical challenges in robotic manipulation where singularities can cause loss of control and potential equipment damage. Our hybrid approach combines real-time singularity detection using manipulability measures, condition number analysis, and fuzzy logic decision-making with a stable reinforcement learning framework for adaptive path planning. Experimental results demonstrate a 90% success rate in reaching target positions while maintaining safe distances from singular configurations. The system integrates PyBullet simulation for training data collection and URSim connectivity for real-world deployment.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [13] [MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs](https://arxiv.org/abs/2601.05296)
*Jiyuan Zhang,Yining Liu,Siqi Yan,Lisen Deng,Jennifer Cao,Shuqi Yang,Min Ni,Bi Xue,Shen Li*

Main category: cs.LG

TL;DR: MoEBlaze：一种内存高效的MoE训练框架，通过协同设计的系统方法解决MoE架构中的内存瓶颈问题，实现4倍加速和50%内存节省。


<details>
  <summary>Details</summary>
Motivation: 现代大规模混合专家（MoE）架构中普遍存在的"内存墙"瓶颈被显著放大。MoE固有的架构稀疏性导致稀疏算术计算，同时引入大量激活内存开销——由大型令牌路由缓冲区和需要物化缓冲中间张量驱动。这种内存压力限制了GPU上可容纳的最大批处理大小和序列长度，并导致过多的数据移动，阻碍性能和高效模型扩展。

Method: MoEBlaze采用协同设计的系统方法：1）端到端令牌调度和MoE训练方法，使用优化的数据结构消除中间缓冲区和激活物化；2）协同设计的内核与智能激活检查点，在减少内存占用的同时实现更好的性能。

Result: MoEBlaze相比现有MoE框架可实现超过4倍的加速和超过50%的内存节省。

Conclusion: MoEBlaze通过协同设计的系统方法有效解决了MoE训练中的内存瓶颈问题，显著提升了训练效率和可扩展性。

Abstract: The pervasive "memory wall" bottleneck is significantly amplified in modern large-scale Mixture-of-Experts (MoE) architectures. MoE's inherent architectural sparsity leads to sparse arithmetic compute and also introduces substantial activation memory overheads -- driven by large token routing buffers and the need to materialize and buffer intermediate tensors. This memory pressure limits the maximum batch size and sequence length that can fit on GPUs, and also results in excessive data movements that hinders performance and efficient model scaling. We present MoEBlaze, a memory-efficient MoE training framework that addresses these issues through a co-designed system approach: (i) an end-to-end token dispatch and MoE training method with optimized data structures to eliminate intermediate buffers and activation materializing, and (ii) co-designed kernels with smart activation checkpoint to mitigate memory footprint while simultaneously achieving better performance. We demonstrate that MoEBlaze can achieve over 4x speedups and over 50% memory savings compared to existing MoE frameworks.

</details>


### [14] [TIME: Temporally Intelligent Meta-reasoning Engine for Context Triggered Explicit Reasoning](https://arxiv.org/abs/2601.05300)
*Susmit Das*

Main category: cs.LG

TL;DR: TIME框架通过时间感知的元推理机制，在对话中引入可选的时间标签和简短思考块，大幅减少推理token并提升时序对话能力


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型的显式推理设计存在成本高、可审计性差、无法重新触发推理的问题，且对话模型缺乏对时间结构的感知能力

Method: 引入TIME框架，包含ISO 8601时间标签、tick turns表示静默间隔、短思考块；采用四阶段课程训练，包括小规模全批次对齐步骤

Result: 在4B到32B规模上，TIME在TIMEBench基准上优于基础Qwen3模型，同时将推理token减少约一个数量级

Conclusion: TIME框架通过上下文敏感的推理机制和时间感知的对话设计，显著提升了语言模型在时序对话任务中的表现和效率

Abstract: Reasoning oriented large language models often expose explicit "thinking" as long, turn-global traces at the start of every response, either always on or toggled externally at inference time. While useful for arithmetic, programming, and problem solving, this design is costly, blurs claim level auditability, and cannot re-trigger explicit reasoning once the model begins presenting. Dialogue models are also largely blind to temporal structure, treating replies after seconds and replies after weeks as equivalent unless time is stated in text. We introduce TIME, the Temporally Intelligent Meta-reasoning Engine, a behavioral alignment framework that treats explicit reasoning as a context sensitive resource driven by discourse and temporal cues. TIME augments dialogue with optional ISO 8601 <time> tags, tick turns that represent silent gaps, and short <think> blocks that can appear anywhere in a reply. A four-phase curriculum including a small, maximally diverse full-batch alignment step trains Qwen3 dense models to invoke brief, in-place reasoning bursts and keep user facing text compact. We evaluate with TIMEBench, a temporally grounded dialogue benchmark probing chronology, commonsense under gaps and offsets, anomaly detection, and continuity. Across 4B to 32B scales, TIME improves TIMEBench scores over base Qwen3 in both thinking and no-thinking modes while reducing reasoning tokens by about an order of magnitude. Our training data and code are available at https://github.com/The-Coherence-Initiative/TIME and TIMEBench is available at https://github.com/The-Coherence-Initiative/TIMEBench

</details>


### [15] [When the Server Steps In: Calibrated Updates for Fair Federated Learning](https://arxiv.org/abs/2601.05352)
*Tianrun Yu,Kaixiang Zhao,Cheng Zhang,Anjun Gao,Yueyang Quan,Zhuqing Liu,Minghong Fang*

Main category: cs.LG

TL;DR: EquFL：一种新颖的服务器端去偏方法，通过生成校准更新来减少联邦学习系统中的偏见，无需修改客户端训练协议


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然具有分布式学习优势，但在确保不同人口群体间的公平性方面面临挑战。现有公平性去偏方法要么需要修改客户端训练协议，要么缺乏聚合策略的灵活性，需要一种更有效的解决方案。

Method: EquFL是一种服务器端去偏方法，允许服务器在接收客户端模型更新后生成单个校准更新，然后将此校准更新与聚合的客户端更新结合，生成减少偏见的调整后全局模型。

Result: 理论上证明EquFL能收敛到FedAvg达到的最优全局模型，并有效减少训练轮次中的公平性损失。实证表明EquFL显著减轻了系统中的偏见，展示了其实际有效性。

Conclusion: EquFL提供了一种有效的服务器端去偏方法，解决了联邦学习中公平性挑战，无需修改客户端协议，具有理论保证和实际效果。

Abstract: Federated learning (FL) has emerged as a transformative distributed learning paradigm, enabling multiple clients to collaboratively train a global model under the coordination of a central server without sharing their raw training data. While FL offers notable advantages, it faces critical challenges in ensuring fairness across diverse demographic groups. To address these fairness concerns, various fairness-aware debiasing methods have been proposed. However, many of these approaches either require modifications to clients' training protocols or lack flexibility in their aggregation strategies. In this work, we address these limitations by introducing EquFL, a novel server-side debiasing method designed to mitigate bias in FL systems. EquFL operates by allowing the server to generate a single calibrated update after receiving model updates from the clients. This calibrated update is then integrated with the aggregated client updates to produce an adjusted global model that reduces bias. Theoretically, we establish that EquFL converges to the optimal global model achieved by FedAvg and effectively reduces fairness loss over training rounds. Empirically, we demonstrate that EquFL significantly mitigates bias within the system, showcasing its practical effectiveness.

</details>


### [16] [The Kernel Manifold: A Geometric Approach to Gaussian Process Model Selection](https://arxiv.org/abs/2601.05371)
*Md Shafiqul Islam,Shakti Prasad Padhy,Douglas Allaire,Raymundo Arróyave*

Main category: cs.LG

TL;DR: 提出基于核-核几何的贝叶斯优化框架，通过期望散度距离在多维标度嵌入中将离散核库映射为连续欧几里得流形，实现高效核搜索


<details>
  <summary>Details</summary>
Motivation: 高斯过程回归的性能严重依赖于协方差核的选择，但核选择是概率建模中最具挑战性和计算成本最高的步骤之一，需要一种高效的核搜索方法

Method: 基于核-核几何的贝叶斯优化框架，使用GP先验之间的期望散度距离构建距离矩阵，通过多维标度嵌入将离散核库映射到连续欧几里得流形，将核组合作为输入空间，对数边际似然作为目标函数，MDS坐标作为特征化表示

Result: 在合成基准测试、真实世界时间序列数据集和增材制造案例研究中，该方法相对于包括LLM引导搜索在内的基线方法，实现了更优的预测精度和不确定性校准

Conclusion: 该框架为核搜索建立了可重用的概率几何结构，对高斯过程建模和深度核学习具有直接相关性，提供了一种高效的核选择方法

Abstract: Gaussian Process (GP) regression is a powerful nonparametric Bayesian framework, but its performance depends critically on the choice of covariance kernel. Selecting an appropriate kernel is therefore central to model quality, yet remains one of the most challenging and computationally expensive steps in probabilistic modeling. We present a Bayesian optimization framework built on kernel-of-kernels geometry, using expected divergence-based distances between GP priors to explore kernel space efficiently. A multidimensional scaling (MDS) embedding of this distance matrix maps a discrete kernel library into a continuous Euclidean manifold, enabling smooth BO. In this formulation, the input space comprises kernel compositions, the objective is the log marginal likelihood, and featurization is given by the MDS coordinates. When the divergence yields a valid metric, the embedding preserves geometry and produces a stable BO landscape. We demonstrate the approach on synthetic benchmarks, real-world time-series datasets, and an additive manufacturing case study predicting melt-pool geometry, achieving superior predictive accuracy and uncertainty calibration relative to baselines including Large Language Model (LLM)-guided search. This framework establishes a reusable probabilistic geometry for kernel search, with direct relevance to GP modeling and deep kernel learning.

</details>


### [17] [Imitation Learning for Combinatorial Optimisation under Uncertainty](https://arxiv.org/abs/2601.05383)
*Prakash Gawas,Antoine Legrain,Louis-Martin Rousseau*

Main category: cs.LG

TL;DR: 该论文提出了一个用于组合优化中模仿学习的专家分类框架，包含不确定性处理、最优性水平和交互模式三个维度，并开发了支持多专家查询和交互策略的广义DAgger算法。


<details>
  <summary>Details</summary>
Motivation: 模仿学习为大规模组合优化问题提供了数据驱动的解决方案框架，但现有研究在专家构建方面缺乏统一的理论框架来系统分析不同专家类型的建模假设、计算特性和对学习性能的影响。

Method: 提出了一个三维专家分类框架：1) 不确定性处理维度（近视、确定性、完全信息、两阶段随机、多阶段随机）；2) 最优性水平维度（任务最优与近似专家）；3) 交互模式维度（一次性监督到迭代交互）。基于此开发了支持多专家查询、专家聚合和灵活交互策略的广义DAgger算法。

Result: 在动态医生-患者分配问题的实验中，随机专家学习的策略始终优于确定性或完全信息专家，交互式学习能以更少的专家演示获得更好的解质量。当随机优化计算困难时，聚合的确定性专家提供了有效替代方案。

Conclusion: 系统化的专家分类框架为组合优化中模仿学习的专家选择提供了理论基础，随机专家在不确定性处理上具有优势，交互式学习能提高效率，而专家聚合策略为计算受限场景提供了实用解决方案。

Abstract: Imitation learning (IL) provides a data-driven framework for approximating policies for large-scale combinatorial optimisation problems formulated as sequential decision problems (SDPs), where exact solution methods are computationally intractable. A central but underexplored aspect of IL in this context is the role of the \emph{expert} that generates training demonstrations. Existing studies employ a wide range of expert constructions, yet lack a unifying framework to characterise their modelling assumptions, computational properties, and impact on learning performance.
  This paper introduces a systematic taxonomy of experts for IL in combinatorial optimisation under uncertainty. Experts are classified along three dimensions: (i) their treatment of uncertainty, including myopic, deterministic, full-information, two-stage stochastic, and multi-stage stochastic formulations; (ii) their level of optimality, distinguishing task-optimal and approximate experts; and (iii) their interaction mode with the learner, ranging from one-shot supervision to iterative, interactive schemes. Building on this taxonomy, we propose a generalised Dataset Aggregation (DAgger) algorithm that supports multiple expert queries, expert aggregation, and flexible interaction strategies.
  The proposed framework is evaluated on a dynamic physician-to-patient assignment problem with stochastic arrivals and capacity constraints. Computational experiments compare learning outcomes across expert types and interaction regimes. The results show that policies learned from stochastic experts consistently outperform those learned from deterministic or full-information experts, while interactive learning improves solution quality using fewer expert demonstrations. Aggregated deterministic experts provide an effective alternative when stochastic optimisation becomes computationally challenging.

</details>


### [18] [Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.05407)
*Minwoo Cho,Batuhan Altundas,Matthew Gombolay*

Main category: cs.LG

TL;DR: HINT是一种用于多智能体强化学习的知识蒸馏框架，通过分层交互教师机制解决传统KD在MARL中的三个关键瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏在MARL中面临三个主要瓶颈：1) 在复杂领域中合成高性能教学策略的挑战；2) 教师需要在分布外状态进行推理的困难；3) 分散学生与集中教师观察空间不匹配的问题。

Method: 提出HINT框架，采用分层强化学习构建可扩展的高性能教师策略。核心创新包括：伪离策略RL使教师策略能够同时利用教师和学生经验进行更新以改善OOD适应；基于性能的过滤机制保留仅与结果相关的指导以减少观察不匹配。

Result: 在具有挑战性的合作领域（如资源分配的FireCommander和战术战斗的MARINE）进行评估，HINT显著优于基线方法，在成功率上实现了60%到165%的改进。

Conclusion: HINT通过分层交互教师机制有效解决了MARL中知识蒸馏的关键瓶颈，为集中训练分散执行设置提供了可扩展且高性能的解决方案。

Abstract: Knowledge distillation (KD) has the potential to accelerate MARL by employing a centralized teacher for decentralized students but faces key bottlenecks. Specifically, there are (1) challenges in synthesizing high-performing teaching policies in complex domains, (2) difficulties when teachers must reason in out-of-distribution (OOD) states, and (3) mismatches between the decentralized students' and the centralized teacher's observation spaces. To address these limitations, we propose HINT (Hierarchical INteractive Teacher-based transfer), a novel KD framework for MARL in a centralized training, decentralized execution setup. By leveraging hierarchical RL, HINT provides a scalable, high-performing teacher. Our key innovation, pseudo off-policy RL, enables the teacher policy to be updated using both teacher and student experience, thereby improving OOD adaptation. HINT also applies performance-based filtering to retain only outcome-relevant guidance, reducing observation mismatches. We evaluate HINT on challenging cooperative domains (e.g., FireCommander for resource allocation, MARINE for tactical combat). Across these benchmarks, HINT outperforms baselines, achieving improvements of 60% to 165% in success rate.

</details>


### [19] [Efficient Inference for Noisy LLM-as-a-Judge Evaluation](https://arxiv.org/abs/2601.05420)
*Yiqun T Chen,Sizhu Lu,Sijia Li,Moran Guo,Shengyi Li*

Main category: cs.LG

TL;DR: 该论文系统研究并统一了两种纠正LLM作为评估者偏差的方法：基于测量误差校正的Rogan-Gladen式估计器和基于预测残差校准的预测驱动推断(PPI)，推导了高效影响函数(EIF)基础的高效估计器，并分析了PPI在何种条件下具有更小的渐近方差。


<details>
  <summary>Details</summary>
Motivation: LLM作为评估者存在系统性非随机误差，现有两种主要纠偏方法（测量误差校正和预测驱动推断）缺乏系统比较和理论统一，需要建立理论框架来指导实践选择。

Method: 利用半参数效率理论工具，推导基于高效影响函数(EIF)的高效估计器，统一两类估计方法，理论分析PPI式估计器相对于测量误差校正的渐近方差优势条件，并通过仿真和真实数据验证。

Result: 理论推导出统一框架下的高效估计器，明确了PPI式估计器在特定条件下具有更小渐近方差的条件，仿真和真实数据验证了理论结果，提供了开源实现工具。

Conclusion: 建立了LLM作为评估者偏差校正的统一理论框架，为实践选择提供了理论指导，PPI方法在适当条件下具有统计效率优势，开源工具便于实际应用。

Abstract: Large language models (LLMs) are increasingly used as automatic evaluators of generative AI outputs, a paradigm often referred to as "LLM-as-a-judge." In practice, LLM judges are imperfect predictions for the underlying truth and can exhibit systematic, non-random errors. Two main approaches have recently been proposed to address this issue: (i) direct measurementerror correction based on misclassification models such as Rogan-Gladen-style estimators, and (ii) surrogate-outcome approaches such as prediction-powered inference (PPI), which correct bias by calibrating prediction residuals on a small set of gold-standard human labels. In this paper, we systematically study the performance of these two approaches for estimating mean parameters (e.g., average benchmark scores or pairwise win rates). Leveraging tools from semiparametric efficiency theory, we unify the two classes of estimators by deriving explicit forms of efficient influence function (EIF)-based efficient estimators and characterize conditions under which PPI-style estimators attain strictly smaller asymptotic variance than measurement-error corrections. We verify our theoretical results in simulations and demonstrate the methods on real-data examples. We provide an implementation of the benchmarked methods and comparison utilities at https://github.com/yiqunchen/debias-llm-as-a-judge.

</details>


### [20] [Prediction of Fault Slip Tendency in CO${_2}$ Storage using Data-space Inversion](https://arxiv.org/abs/2601.05431)
*Xiaowen He,Su Jiang,Louis J. Durlofsky*

Main category: cs.LG

TL;DR: 基于变分自编码器的数据空间反演框架用于预测CO₂封存项目中的压力、应力、应变场和断层滑移倾向，无需生成后验地质模型


<details>
  <summary>Details</summary>
Motivation: 准确评估断层滑移潜力对地下工程至关重要，但传统的基于模型的历史匹配方法在含断层的流固耦合问题中应用困难

Method: 采用VAE-数据空间反演框架，使用堆叠卷积LSTM层的VAE表示压力、应变、有效正应力和剪应力场，通过监测井数据直接推断后验分布

Result: DSI-VAE框架能准确预测压力、应变、应力场和断层滑移倾向，并显著降低关键地质力学和断层参数的不确定性

Conclusion: VAE-DSI框架为含断层的流固耦合问题提供了一种高效的后验预测方法，避免了传统后验地质模型生成的复杂性

Abstract: Accurately assessing the potential for fault slip is essential in many subsurface operations. Conventional model-based history matching methods, which entail the generation of posterior geomodels calibrated to observed data, can be challenging to apply in coupled flow-geomechanics problems with faults. In this work, we implement a variational autoencoder (VAE)-based data-space inversion (DSI) framework to predict pressure, stress and strain fields, and fault slip tendency, in CO${_2}$ storage projects. The main computations required by the DSI workflow entail the simulation of O(1000) prior geomodels. The posterior distributions for quantities of interest are then inferred directly from prior simulation results and observed data, without the need to generate posterior geomodels. The model used here involves a synthetic 3D system with two faults. Realizations of heterogeneous permeability and porosity fields are generated using geostatistical software, and uncertain geomechanical and fault parameters are sampled for each realization from prior distributions. Coupled flow-geomechanics simulations for these geomodels are conducted using GEOS. A VAE with stacked convolutional long short-term memory layers is trained, using the prior simulation results, to represent pressure, strain, effective normal stress and shear stress fields in terms of latent variables. The VAE parameterization is used with DSI for posterior predictions, with monitoring wells providing observed pressure and strain data. Posterior results for synthetic true models demonstrate that the DSI-VAE framework gives accurate predictions for pressure, strain, and stress fields and for fault slip tendency. The framework is also shown to reduce uncertainty in key geomechanical and fault parameters.

</details>


### [21] [RingSQL: Generating Synthetic Data with Schema-Independent Templates for Text-to-SQL Reasoning Models](https://arxiv.org/abs/2601.05451)
*Marko Sterbentz,Kevin Cushing,Cameron Barrie,Kristian J. Hammond*

Main category: cs.LG

TL;DR: RingSQL是一个混合数据生成框架，结合了模式无关查询模板和基于LLM的自然语言问题改写，用于生成高质量文本到SQL训练数据。


<details>
  <summary>Details</summary>
Motivation: 文本到SQL系统的发展受限于高质量训练数据的稀缺性。手动创建数据成本高昂，现有合成方法在可靠性和可扩展性之间存在权衡：基于模板的方法能确保SQL正确性但需要特定模式模板，而基于LLM的生成方法易于扩展但缺乏质量和正确性保证。

Method: RingSQL采用混合数据生成框架，结合了模式无关查询模板和基于LLM的自然语言问题改写。该方法使用查询模板确保SQL语法正确性，同时利用LLM对自然语言问题进行改写以提供丰富的语言多样性。

Result: 在六个文本到SQL基准测试中，使用RingSQL生成的数据训练的模型相比使用其他合成数据训练的模型，平均准确率提升了+2.3%。

Conclusion: RingSQL框架通过结合模式无关查询模板和LLM改写，能够在保持SQL正确性的同时提供广泛的语言多样性，有效解决了文本到SQL训练数据生成中可靠性和可扩展性的权衡问题。

Abstract: Recent advances in text-to-SQL systems have been driven by larger models and improved datasets, yet progress is still limited by the scarcity of high-quality training data. Manual data creation is expensive, and existing synthetic methods trade off reliability and scalability. Template-based approaches ensure correct SQL but require schema-specific templates, while LLM-based generation scales easily but lacks quality and correctness guarantees. We introduce RingSQL, a hybrid data generation framework that combines schema-independent query templates with LLM-based paraphrasing of natural language questions. This approach preserves SQL correctness across diverse schemas while providing broad linguistic variety. In our experiments, we find that models trained using data produced by RingSQL achieve an average gain in accuracy of +2.3% across six text-to-SQL benchmarks when compared to models trained on other synthetic data. We make our code available at https://github.com/nu-c3lab/RingSQL.

</details>


### [22] [Efficient Differentiable Causal Discovery via Reliable Super-Structure Learning](https://arxiv.org/abs/2601.05474)
*Pingchuan Ma,Qixin Zhang,Shuai Wang,Dacheng Tao*

Main category: cs.LG

TL;DR: ALVGL是一种增强可微分因果发现流程的新方法，通过稀疏低秩分解学习数据精度矩阵，构建包含真实因果图的超结构，从而提高优化效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有可微分因果发现在高维数据或存在潜在混杂因素时面临搜索空间巨大、目标函数复杂和图论约束非平凡等挑战，需要有效的超结构引导优化过程。

Method: ALVGL采用稀疏低秩分解学习数据精度矩阵，设计ADMM优化过程识别与底层因果结构最相关的成分，构建包含真实因果图的超结构，用于初始化标准可微分因果发现方法。

Result: 在合成和真实数据集上的广泛实验表明，ALVGL不仅达到了最先进的准确性，还显著提高了优化效率，适用于高斯和非高斯设置，无论是否存在未测量的混杂因素。

Conclusion: ALVGL为可微分因果发现提供了一个可靠有效的解决方案，通过超结构引导优化过程，解决了高维数据和潜在混杂因素带来的挑战。

Abstract: Recently, differentiable causal discovery has emerged as a promising approach to improve the accuracy and efficiency of existing methods. However, when applied to high-dimensional data or data with latent confounders, these methods, often based on off-the-shelf continuous optimization algorithms, struggle with the vast search space, the complexity of the objective function, and the nontrivial nature of graph-theoretical constraints. As a result, there has been a surge of interest in leveraging super-structures to guide the optimization process. Nonetheless, learning an appropriate super-structure at the right level of granularity, and doing so efficiently across various settings, presents significant challenges.
  In this paper, we propose ALVGL, a novel and general enhancement to the differentiable causal discovery pipeline. ALVGL employs a sparse and low-rank decomposition to learn the precision matrix of the data. We design an ADMM procedure to optimize this decomposition, identifying components in the precision matrix that are most relevant to the underlying causal structure. These components are then combined to construct a super-structure that is provably a superset of the true causal graph. This super-structure is used to initialize a standard differentiable causal discovery method with a more focused search space, thereby improving both optimization efficiency and accuracy.
  We demonstrate the versatility of ALVGL by instantiating it across a range of structural causal models, including both Gaussian and non-Gaussian settings, with and without unmeasured confounders. Extensive experiments on synthetic and real-world datasets show that ALVGL not only achieves state-of-the-art accuracy but also significantly improves optimization efficiency, making it a reliable and effective solution for differentiable causal discovery.

</details>


### [23] [MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization](https://arxiv.org/abs/2601.05475)
*Jiefu Ou,Sapana Chaudhary,Kaj Bostrom,Nathaniel Weir,Shuai Zhang,Huzefa Rangwala,George Karypis*

Main category: cs.LG

TL;DR: MaxCode：基于最大奖励强化学习框架的统一推理时搜索方法，通过执行反馈和自然语言诊断指导LLM迭代优化代码性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用编码任务中表现优异，但在代码优化方面面临两大挑战：1) 编写优化代码（如高性能CUDA内核和竞赛级CPU代码）需要系统、算法和特定语言的专业知识；2) 需要解释性能指标（如计时和设备利用率），而不仅仅是二进制正确性

Method: 提出MaxCode方法，将现有搜索方法统一到最大奖励强化学习框架下，使观察和动作价值函数模块化。通过自然语言批判模型将原始执行反馈转换为错误和性能瓶颈的诊断洞察，结合最佳折扣奖励提供更丰富的输入。训练生成式奖励模型使用rollout的动作价值重新排序潜在解决方案以改进搜索探索

Result: 在KernelBench（CUDA）和PIE（C++）优化基准测试中，MaxCode相比基线方法显著提升了优化代码性能，在绝对加速值和相对加速排名上分别实现了20.3%和10.1%的相对改进

Conclusion: MaxCode通过统一的强化学习框架和增强的观察空间，有效解决了LLM在代码优化中的挑战，结合自然语言诊断和奖励模型重排序，显著提升了代码优化性能

Abstract: Large Language Models (LLMs) demonstrate strong capabilities in general coding tasks but encounter two key challenges when optimizing code: (i) the complexity of writing optimized code (such as performant CUDA kernels and competition-level CPU code) requires expertise in systems, algorithms and specific languages and (ii) requires interpretation of performance metrics like timing and device utilization beyond binary correctness. In this work, we explore inference-time search algorithms that guide the LLM to discover better solutions through iterative refinement based on execution feedback. Our approach, called MaxCode unifies existing search methods under a max-reward reinforcement learning framework, making the observation and action-value functions modular for modification. To enhance the observation space, we integrate a natural language critique model that converts raw execution feedback into diagnostic insights about errors and performance bottlenecks, and the best-discounted reward seen so far. Together, these provide richer input to the code proposal function. To improve exploration during search, we train a generative reward-to-go model using action values from rollouts to rerank potential solutions. Testing on the KernelBench (CUDA) and PIE (C++) optimization benchmarks shows that MaxCode improves optimized code performance compared to baselines, achieving 20.3% and 10.1% relative improvements in absolute speedup value and relative speedup ranking, respectively.

</details>


### [24] [Hi-ZFO: Hierarchical Zeroth- and First-Order LLM Fine-Tuning via Importance-Guided Tensor Selection](https://arxiv.org/abs/2601.05501)
*Feihu Jin,Ying Tan*

Main category: cs.LG

TL;DR: 提出Hi-ZFO混合优化框架，结合一阶梯度精确性和零阶方法探索能力，通过分层优化解决LLM微调中的局部最优问题


<details>
  <summary>Details</summary>
Motivation: 标准一阶优化方法容易使LLM微调陷入尖锐、泛化能力差的局部最小值，而零阶方法虽然探索性强但收敛慢且方差大，特别是在生成任务中输出空间巨大时问题更加严重

Method: 提出Hi-ZFO分层混合优化框架：1) 通过层重要性分析自适应划分模型；2) 对关键层使用精确的一阶梯度更新；3) 对不敏感层使用零阶优化，作为"有益随机性"帮助模型逃离局部最优；4) 零阶方法不仅是内存节省替代品，更是探索机制

Result: 在多种生成、数学和代码推理任务上验证，Hi-ZFO始终获得更优性能，同时显著减少训练时间

Conclusion: 分层混合优化是LLM微调的有效方法，Hi-ZFO成功结合了一阶梯度的精确性和零阶方法的探索能力，为解决LLM微调中的局部最优问题提供了新思路

Abstract: Fine-tuning large language models (LLMs) using standard first-order (FO) optimization often drives training toward sharp, poorly generalizing minima. Conversely, zeroth-order (ZO) methods offer stronger exploratory behavior without relying on explicit gradients, yet suffer from slow convergence. More critically, our analysis reveals that in generative tasks, the vast output and search space significantly amplify estimation variance, rendering ZO methods both noisy and inefficient. To address these challenges, we propose \textbf{Hi-ZFO} (\textbf{Hi}erarchical \textbf{Z}eroth- and \textbf{F}irst-\textbf{O}rder optimization), a hybrid framework designed to synergize the precision of FO gradients with the exploratory capability of ZO estimation. Hi-ZFO adaptively partitions the model through layer-wise importance profiling, applying precise FO updates to critical layers while leveraging ZO optimization for less sensitive ones. Notably, ZO in Hi-ZFO is not merely a memory-saving surrogate; it is intentionally introduced as a source of "beneficial stochasticity" to help the model escape the local minima where pure FO optimization tends to stagnate. Validated across diverse generative, mathematical, and code reasoning tasks, Hi-ZFO consistently achieves superior performance while significantly reducing the training time. These results demonstrate the effectiveness of hierarchical hybrid optimization for LLM fine-tuning.

</details>


### [25] [Over-Searching in Search-Augmented Large Language Models](https://arxiv.org/abs/2601.05503)
*Roy Xie,Deepak Gopinath,David Qiu,Dong Lin,Haitian Sun,Saloni Potdar,Bhuwan Dhingra*

Main category: cs.LG

TL;DR: 该论文系统评估了搜索增强大语言模型中的"过度搜索"问题，提出了量化指标TPC，并发布了OverSearchQA数据集以促进高效搜索增强LLM的研究。


<details>
  <summary>Details</summary>
Motivation: 搜索增强大语言模型在知识密集型任务中表现出色，但存在"过度搜索"问题——即使搜索无法提高响应质量时仍不必要地调用搜索工具，这导致计算效率低下和因包含无关上下文而产生的幻觉。

Method: 1. 从多个维度系统评估过度搜索：查询类型、模型类别、检索条件和多轮对话；2. 引入Tokens Per Correctness (TPC)指标量化过度搜索，捕捉性能-成本权衡；3. 在查询和检索层面研究缓解方法；4. 发布OverSearchQA数据集。

Result: 研究发现：(1) 搜索通常提高可回答查询的答案准确性，但损害不可回答查询的弃权能力；(2) 过度搜索在复杂推理模型和深度研究系统中更为明显，被噪声检索加剧，并在多轮对话中累积；(3) 检索证据的组成至关重要，负面证据的存在改善弃权能力。

Conclusion: 该研究系统揭示了搜索增强LLM中的过度搜索问题，提出了量化指标TPC，并提供了缓解策略。OverSearchQA数据集的发布将促进高效搜索增强LLM的持续研究。

Abstract: Search-augmented large language models (LLMs) excel at knowledge-intensive tasks by integrating external retrieval. However, they often over-search -- unnecessarily invoking search tool even when it does not improve response quality, which leads to computational inefficiency and hallucinations by incorporating irrelevant context. In this work, we conduct a systematic evaluation of over-searching across multiple dimensions, including query types, model categories, retrieval conditions, and multi-turn conversations. Our finding shows: (i) search generally improves answer accuracy on answerable queries but harms abstention on unanswerable ones; (ii) over-searching is more pronounced in complex reasoning models and deep research systems, is exacerbated by noisy retrieval, and compounds across turns in multi-turn conversations; and (iii) the composition of retrieved evidence is crucial, as the presence of negative evidence improves abstention. To quantify over-searching, we introduce Tokens Per Correctness (TPC), an evaluation metric that captures the performance-cost trade-off for search-augmented LLMs. Lastly, we investigate mitigation approaches at both the query and retrieval levels and release the OverSearchQA to foster continued research into efficient search-augmented LLMs.

</details>


### [26] [Toward an Integrated Cross-Urban Accident Prevention System: A Multi-Task Spatial-Temporal Learning Framework for Urban Safety Management](https://arxiv.org/abs/2601.05521)
*Jiayu Fang,Zhiqi Shao,Haoning Xi,Boris Choy,Junbin Gao*

Main category: cs.LG

TL;DR: MLA-STNet：基于Mamba注意力机制的统一跨城市事故风险预测系统，通过多任务学习处理城市数据异质性，在噪声环境下保持稳定性能


<details>
  <summary>Details</summary>
Motivation: 城市事故数据存在异质性、报告不一致、稀疏、周期性、噪声等问题，加上碎片化治理和不兼容的报告标准，阻碍了跨城市统一事故预防框架的开发

Method: 提出MLA-STNet系统，将事故风险预测建模为跨城市多任务学习问题。包含两个互补模块：STG-MA（时空地理Mamba注意力）抑制不稳定时空波动并增强长程时间依赖；STS-MA（时空语义Mamba注意力）通过共享参数设计减轻跨城市异质性，同时保留个体语义表示空间

Result: 在纽约和芝加哥真实数据集上进行75次实验，涵盖全天和高频事故时段两种预测场景。相比SOTA基线，MLA-STNet实现RMSE降低6%、Recall提高8%、MAP提高5%，在50%输入噪声下性能变化小于1%

Conclusion: MLA-STNet有效统一了异构城市数据集，构建了可扩展、鲁棒且可解释的跨城市事故预防系统，为协调的数据驱动城市安全管理铺平道路

Abstract: The development of a cross-city accident prevention system is particularly challenging due to the heterogeneity, inconsistent reporting, and inherently clustered, sparse, cyclical, and noisy nature of urban accident data. These intrinsic data properties, combined with fragmented governance and incompatible reporting standards, have long hindered the creation of an integrated, cross-city accident prevention framework. To address this gap, we propose the Mamba Local-ttention Spatial-Temporal Network MLA-STNet, a unified system that formulates accident risk prediction as a multi-task learning problem across multiple cities. MLA-STNet integrates two complementary modules: (i)the Spatio-Temporal Geographical Mamba-Attention (STG-MA), which suppresses unstable spatio-temporal fluctuations and strengthens long-range temporal dependencies; and (ii) the Spatio-Temporal Semantic Mamba-Attention (STS-MA), which mitigates cross-city heterogeneity through a shared-parameter design that jointly trains all cities while preserving individual semantic representation spaces. We validate the proposed framework through 75 experiments under two forecasting scenarios, full-day and high-frequency accident periods, using real-world datasets from New York City and Chicago. Compared with the state-of-the-art baselines, MLA-STNet achieves up to 6% lower RMSE, 8% higher Recall, and 5% higher MAP, while maintaining less than 1% performance variation under 50% input noise. These results demonstrate that MLA-STNet effectively unifies heterogeneous urban datasets within a scalable, robust, and interpretable Cross-City Accident Prevention System, paving the way for coordinated and data-driven urban safety management.

</details>


### [27] [Buffered AUC maximization for scoring systems via mixed-integer optimization](https://arxiv.org/abs/2601.05544)
*Moe Shiina,Shunnosuke Ikeda,Yuichi Takano*

Main category: cs.LG

TL;DR: 提出基于混合整数线性优化（MILO）直接最大化缓冲AUC（bAUC）的评分系统构建方法，相比传统正则化和逐步回归方法获得更优的AUC性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于混合整数优化（MIO）的评分系统研究未直接最大化AUC这一关键评估指标，而AUC对评分系统至关重要。需要建立直接最大化AUC的MIO框架。

Method: 提出混合整数线性优化（MILO）模型，直接最大化缓冲AUC（bAUC）作为AUC的最紧凹下界，同时通过组稀疏约束限制评分系统中的问题数量。

Result: 在公开真实数据集上的计算实验表明，相比基于正则化和逐步回归的基线方法，MILO方法能构建具有更优AUC值的评分系统。

Conclusion: 该研究推进了MIO技术在开发高可解释性分类模型中的应用，为直接优化AUC的评分系统构建提供了有效框架。

Abstract: A scoring system is a linear classifier composed of a small number of explanatory variables, each assigned a small integer coefficient. This system is highly interpretable and allows predictions to be made with simple manual calculations without the need for a calculator. Several previous studies have used mixed-integer optimization (MIO) techniques to develop scoring systems for binary classification; however, they have not focused on directly maximizing AUC (i.e., area under the receiver operating characteristic curve), even though AUC is recognized as an essential evaluation metric for scoring systems. Our goal herein is to establish an effective MIO framework for constructing scoring systems that directly maximize the buffered AUC (bAUC) as the tightest concave lower bound on AUC. Our optimization model is formulated as a mixed-integer linear optimization (MILO) problem that maximizes bAUC subject to a group sparsity constraint for limiting the number of questions in the scoring system. Computational experiments using publicly available real-world datasets demonstrate that our MILO method can build scoring systems with superior AUC values compared to the baseline methods based on regularization and stepwise regression. This research contributes to the advancement of MIO techniques for developing highly interpretable classification models.

</details>


### [28] [Learn to Evolve: Self-supervised Neural JKO Operator for Wasserstein Gradient Flow](https://arxiv.org/abs/2601.05583)
*Xue Feng,Li Wang,Deanna Needell,Rongjie Lai*

Main category: cs.LG

TL;DR: 提出一种自监督学习方法，无需数值求解JKO子问题即可学习JKO解算子，通过交替学习算子和轨迹生成来高效计算Wasserstein梯度流。


<details>
  <summary>Details</summary>
Motivation: JKO方案为计算Wasserstein梯度流提供了稳定的变分框架，但其实际应用受到重复求解JKO子问题的高计算成本的限制。需要一种更高效的方法来避免这些昂贵的数值计算。

Method: 提出Learn-to-Evolve算法：1）学习一个JKO解算子，将输入密度直接映射到对应JKO子问题的最小化解；2）通过交替进行轨迹生成和算子更新的自监督学习策略，联合学习JKO算子及其诱导的轨迹；3）利用生成的数据作为自然的数据增强，提高学习算子的泛化能力。

Result: 数值实验表明，该方法在各种能量选择和初始条件下都表现出准确性、稳定性和鲁棒性。学习到的算子可以迭代应用以高效生成梯度流演化。

Conclusion: 提出的自监督学习框架成功避免了重复求解JKO子问题的高计算成本，通过联合学习解算子和轨迹生成，实现了Wasserstein梯度流的高效计算，具有很好的泛化能力。

Abstract: The Jordan-Kinderlehrer-Otto (JKO) scheme provides a stable variational framework for computing Wasserstein gradient flows, but its practical use is often limited by the high computational cost of repeatedly solving the JKO subproblems. We propose a self-supervised approach for learning a JKO solution operator without requiring numerical solutions of any JKO trajectories. The learned operator maps an input density directly to the minimizer of the corresponding JKO subproblem, and can be iteratively applied to efficiently generate the gradient-flow evolution. A key challenge is that only a number of initial densities are typically available for training. To address this, we introduce a Learn-to-Evolve algorithm that jointly learns the JKO operator and its induced trajectories by alternating between trajectory generation and operator updates. As training progresses, the generated data increasingly approximates true JKO trajectories. Meanwhile, this Learn-to-Evolve strategy serves as a natural form of data augmentation, significantly enhancing the generalization ability of the learned operator. Numerical experiments demonstrate the accuracy, stability, and robustness of the proposed method across various choices of energies and initial conditions.

</details>


### [29] [PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning](https://arxiv.org/abs/2601.05593)
*Jingcheng Hu,Yinmin Zhang,Shijie Shang,Xiaobo Yang,Yue Peng,Zhewei Huang,Hebin Zhou,Xin Wu,Jie Cheng,Fanqi Wan,Xiangwen Kong,Chengyuan Yao,Kaiwen Yan,Ailin Huang,Hongyu Zhou,Qi Han,Zheng Ge,Daxin Jiang,Xiangyu Zhang,Heung-Yeung Shum*

Main category: cs.LG

TL;DR: PaCoRe是一个训练-推理框架，通过并行协调推理突破语言模型测试时计算限制，使用消息传递架构在多轮中并行探索，实现数百万token的有效计算而不超过上下文限制。


<details>
  <summary>Details</summary>
Motivation: 解决当代语言模型的核心限制：无法在固定上下文窗口下将测试时计算扩展到远超顺序推理的程度。传统顺序范式限制了模型的计算扩展能力。

Method: 采用并行协调推理框架，通过消息传递架构在多轮中启动并行推理轨迹，将发现压缩到上下文限制的消息中，合成这些消息来指导下一轮并产生最终答案。使用大规模基于结果的强化学习进行端到端训练。

Result: 在多个领域取得显著改进，特别是在数学推理方面：8B参数模型在HMMT 2025上达到94.5%，超过GPT-5的93.2%，通过将有效测试时计算扩展到约两百万token实现。开源了模型检查点、训练数据和完整推理管道。

Conclusion: PaCoRe框架成功突破了语言模型测试时计算扩展的限制，通过并行协调推理实现了远超传统顺序范式的能力，为后续研究提供了重要基础。

Abstract: We introduce Parallel Coordinated Reasoning (PaCoRe), a training-and-inference framework designed to overcome a central limitation of contemporary language models: their inability to scale test-time compute (TTC) far beyond sequential reasoning under a fixed context window. PaCoRe departs from the traditional sequential paradigm by driving TTC through massive parallel exploration coordinated via a message-passing architecture in multiple rounds. Each round launches many parallel reasoning trajectories, compacts their findings into context-bounded messages, and synthesizes these messages to guide the next round and ultimately produce the final answer. Trained end-to-end with large-scale, outcome-based reinforcement learning, the model masters the synthesis abilities required by PaCoRe and scales to multi-million-token effective TTC without exceeding context limits. The approach yields strong improvements across diverse domains, and notably pushes reasoning beyond frontier systems in mathematics: an 8B model reaches 94.5% on HMMT 2025, surpassing GPT-5's 93.2% by scaling effective TTC to roughly two million tokens. We open-source model checkpoints, training data, and the full inference pipeline to accelerate follow-up work.

</details>


### [30] [Good Allocations from Bad Estimates](https://arxiv.org/abs/2601.05597)
*Sílvia Casacuberta,Moritz Hardt*

Main category: cs.LG

TL;DR: 本文提出了一种比传统CATE估计更高效的样本分配方法，仅需O(M/ε)样本即可实现与CATE相同的总体治疗效果，而传统方法需要O(M/ε²)样本


<details>
  <summary>Details</summary>
Motivation: 传统的条件平均处理效应(CATE)估计需要大量样本来精确估计每个子群体的处理效应，但实际治疗分配只需要粗粒度估计即可实现接近最优的分配效果。本文旨在减少治疗分配所需的样本量，区分治疗效应估计与治疗分配这两个不同任务的需求差异。

Method: 提出了一种基于粗粒度估计的治疗分配算法，利用处理效应的自然分布特性，仅需粗略估计即可实现接近最优的治疗分配。该方法还利用了预算灵活性进一步降低样本复杂度，通过分层抽样和优化分配策略来最小化所需样本量。

Result: 在理论分析中，该方法仅需O(M/ε)样本即可达到与需要O(M/ε²)样本的传统CATE方法相同的总体治疗效果。在实际RCT数据集上的评估显示，该算法能够以极少的样本找到接近最优的治疗分配方案。

Conclusion: 治疗效应估计与治疗分配是根本不同的任务：治疗分配需要的样本量远少于精确估计所有处理效应所需的样本量。粗粒度估计足以实现接近最优的治疗分配，这为实际应用中的资源优化提供了重要启示。

Abstract: Conditional average treatment effect (CATE) estimation is the de facto gold standard for targeting a treatment to a heterogeneous population. The method estimates treatment effects up to an error $ε> 0$ in each of $M$ different strata of the population, targeting individuals in decreasing order of estimated treatment effect until the budget runs out. In general, this method requires $O(M/ε^2)$ samples. This is best possible if the goal is to estimate all treatment effects up to an $ε$ error. In this work, we show how to achieve the same total treatment effect as CATE with only $O(M/ε)$ samples for natural distributions of treatment effects. The key insight is that coarse estimates suffice for near-optimal treatment allocations. In addition, we show that budget flexibility can further reduce the sample complexity of allocation. Finally, we evaluate our algorithm on various real-world RCT datasets. In all cases, it finds nearly optimal treatment allocations with surprisingly few samples. Our work highlights the fundamental distinction between treatment effect estimation and treatment allocation: the latter requires far fewer samples.

</details>


### [31] [PiXTime: A Model for Federated Time Series Forecasting with Heterogeneous Data Structures Across Nodes](https://arxiv.org/abs/2601.05613)
*Yiming Zhou,Mingyue Cheng,Hao Wang,Enhong Chen*

Main category: cs.LG

TL;DR: PiXTime是一个为联邦学习设计的时间序列预测模型，能够处理多粒度、异构变量集的时间序列数据，通过个性化补丁嵌入和全局变量嵌入表实现跨节点有效预测。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据价值高但难以跨节点共享，联邦学习是有效利用分布式时间数据的范式。然而，不同节点的采样标准导致时间粒度和变量集存在差异，阻碍了经典联邦学习的应用。

Method: PiXTime采用个性化补丁嵌入将节点特定粒度的时间序列映射为统一维度的token序列，使用全局变量嵌入表对齐跨节点的变量类别语义，通过基于Transformer的共享模型捕获任意数量变量的辅助序列表示，并利用交叉注意力增强目标序列预测。

Result: 实验表明PiXTime在联邦学习设置下达到最先进的性能，并在八个广泛使用的真实世界传统基准测试中表现出优越性能。

Conclusion: PiXTime通过解决时间序列联邦学习中的多粒度和异构变量集问题，实现了有效的跨节点预测，为分布式时间数据利用提供了创新解决方案。

Abstract: Time series are highly valuable and rarely shareable across nodes, making federated learning a promising paradigm to leverage distributed temporal data. However, different sampling standards lead to diverse time granularities and variable sets across nodes, hindering classical federated learning. We propose PiXTime, a novel time series forecasting model designed for federated learning that enables effective prediction across nodes with multi-granularity and heterogeneous variable sets. PiXTime employs a personalized Patch Embedding to map node-specific granularity time series into token sequences of a unified dimension for processing by a subsequent shared model, and uses a global VE Table to align variable category semantics across nodes, thereby enhancing cross-node transferability. With a transformer-based shared model, PiXTime captures representations of auxiliary series with arbitrary numbers of variables and uses cross-attention to enhance the prediction of the target series. Experiments show PiXTime achieves state-of-the-art performance in federated settings and demonstrates superior performance on eight widely used real-world traditional benchmarks.

</details>


### [32] [Transformer Is Inherently a Causal Learner](https://arxiv.org/abs/2601.05647)
*Xinyue Wang,Stephen Wang,Biwei Huang*

Main category: cs.LG

TL;DR: Transformer在自回归训练中自然学习到时延因果结构，其梯度敏感性可直接恢复因果图，无需显式因果目标或结构约束


<details>
  <summary>Details</summary>
Motivation: 探索transformer在自回归训练中是否以及如何学习到时间序列中的因果结构，为因果发现提供新视角

Method: 理论证明transformer输出对过去输入的梯度敏感性可恢复因果图，开发基于聚合梯度归因的实用提取方法

Result: 在非线性动态、长期依赖和非平稳系统等挑战性场景中，该方法显著超越现有因果发现算法，尤其在数据异质性增加时表现更优

Conclusion: 该方法为因果发现提供了基于基础模型的新范式，同时为基础模型通过因果视角获得可解释性和增强奠定了基础

Abstract: We reveal that transformers trained in an autoregressive manner naturally encode time-delayed causal structures in their learned representations. When predicting future values in multivariate time series, the gradient sensitivities of transformer outputs with respect to past inputs directly recover the underlying causal graph, without any explicit causal objectives or structural constraints. We prove this connection theoretically under standard identifiability conditions and develop a practical extraction method using aggregated gradient attributions. On challenging cases such as nonlinear dynamics, long-term dependencies, and non-stationary systems, this approach greatly surpasses the performance of state-of-the-art discovery algorithms, especially as data heterogeneity increases, exhibiting scaling potential where causal accuracy improves with data volume and heterogeneity, a property traditional methods lack. This unifying view lays the groundwork for a future paradigm where causal discovery operates through the lens of foundation models, and foundation models gain interpretability and enhancement through the lens of causality.

</details>


### [33] [Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM](https://arxiv.org/abs/2511.18721)
*Adarsh Kumarappan,Ayushi Mehrotra*

Main category: cs.LG

TL;DR: 提出(k, ε)-不稳定框架改进SmoothLLM防御，提供更实际的安全认证保证


<details>
  <summary>Details</summary>
Motivation: SmoothLLM防御依赖于严格的k-不稳定假设，这在实践中很少成立，限制了安全证书的可信度

Method: 引入更现实的概率框架(k, ε)-不稳定，结合攻击成功的经验模型，推导SmoothLLM防御概率的新数据驱动下界

Result: 为从业者提供可操作的安全保证，能够设置更符合LLM实际行为的认证阈值

Conclusion: 贡献了实用且理论基础的机制，使LLM更能抵抗对其安全对齐的利用，解决安全AI部署的关键挑战

Abstract: The SmoothLLM defense provides a certification guarantee against jailbreaking attacks, but it relies on a strict `k-unstable' assumption that rarely holds in practice. This strong assumption can limit the trustworthiness of the provided safety certificate. In this work, we address this limitation by introducing a more realistic probabilistic framework, `(k, $\varepsilon$)-unstable,' to certify defenses against diverse jailbreaking attacks, from gradient-based (GCG) to semantic (PAIR). We derive a new, data-informed lower bound on SmoothLLM's defense probability by incorporating empirical models of attack success, providing a more trustworthy and practical safety certificate. By introducing the notion of (k, $\varepsilon$)-unstable, our framework provides practitioners with actionable safety guarantees, enabling them to set certification thresholds that better reflect the real-world behavior of LLMs. Ultimately, this work contributes a practical and theoretically-grounded mechanism to make LLMs more resistant to the exploitation of their safety alignments, a critical challenge in secure AI deployment.

</details>


### [34] [From Global to Local: Cluster-Aware Learning for Wi-Fi Fingerprinting Indoor Localisation](https://arxiv.org/abs/2601.05650)
*Miguel Matey-Sanz,Joaquín Torres-Sospedra,Joaquín Huerta,Sergio Trilles*

Main category: cs.LG

TL;DR: 提出基于聚类的Wi-Fi指纹定位方法，通过聚类结构化指纹数据集，在定位阶段仅处理相关子集，提高定位精度


<details>
  <summary>Details</summary>
Motivation: 传统Wi-Fi指纹定位面临数据集规模与异质性、RSSI信号波动、大型多楼层环境模糊性等挑战，导致定位精度下降，特别是全局模型未考虑结构约束时

Method: 采用聚类方法在定位前结构化指纹数据集，基于空间或无线电特征分组，可在建筑或楼层级别应用聚类；定位阶段基于最强接入点的聚类估计程序将未见指纹分配到最相关集群，仅在选定集群内进行定位

Result: 在三个公共数据集和多个机器学习模型上评估，结果显示定位误差持续减少（尤其在建筑级策略下），但以降低楼层检测精度为代价

Conclusion: 通过聚类显式结构化数据集是室内定位可扩展的有效灵活方法

Abstract: Wi-Fi fingerprinting remains one of the most practical solutions for indoor positioning, however, its performance is often limited by the size and heterogeneity of fingerprint datasets, strong Received Signal Strength Indicator variability, and the ambiguity introduced in large and multi-floor environments. These factors significantly degrade localisation accuracy, particularly when global models are applied without considering structural constraints. This paper introduces a clustering-based method that structures the fingerprint dataset prior to localisation. Fingerprints are grouped using either spatial or radio features, and clustering can be applied at the building or floor level. In the localisation phase, a clustering estimation procedure based on the strongest access points assigns unseen fingerprints to the most relevant cluster. Localisation is then performed only within the selected clusters, allowing learning models to operate on reduced and more coherent subsets of data. The effectiveness of the method is evaluated on three public datasets and several machine learning models. Results show a consistent reduction in localisation errors, particularly under building-level strategies, but at the cost of reducing the floor detection accuracy. These results demonstrate that explicitly structuring datasets through clustering is an effective and flexible approach for scalable indoor positioning.

</details>


### [35] [Automating Deception: Scalable Multi-Turn LLM Jailbreaks](https://arxiv.org/abs/2511.19517)
*Adarsh Kumarappan,Ananya Mujoo*

Main category: cs.LG

TL;DR: 该论文提出了一种自动生成基于心理学原理的多轮越狱攻击数据集的方法，评估了不同LLM对"得寸进尺"式对话攻击的脆弱性，发现GPT系列模型对对话历史高度敏感，而Gemini 2.5 Flash表现出卓越的抵抗力。


<details>
  <summary>Details</summary>
Motivation: 多轮对话攻击利用心理学原理（如"得寸进尺"技术）绕过LLM的安全对齐机制，构成持续威胁。现有防御研究受限于手动创建难以扩展的数据集，需要自动化、大规模、基于心理学原理的数据集生成方法。

Method: 开发了自动化流水线，系统地将"得寸进尺"技术操作化为可复现的模板，生成了包含非法活动和冒犯性内容的1,500个场景基准数据集。评估了来自三个主要LLM家族的七个模型，在带历史（多轮）和不带历史（单轮）两种条件下进行测试。

Result: GPT家族模型对对话历史表现出显著脆弱性，攻击成功率（ASR）最高增加32个百分点。Google的Gemini 2.5 Flash表现出卓越的抵抗力，几乎免疫这些攻击。Anthropic的Claude 3 Haiku显示出强大但不完美的抵抗力。不同模型在对话上下文处理上存在关键差异。

Conclusion: 当前安全架构在处理对话上下文方面存在关键分歧，突显了需要能够抵抗基于叙事操纵的防御机制。自动化数据集生成方法为评估和改进LLM对心理学攻击的抵抗力提供了重要工具。

Abstract: Multi-turn conversational attacks, which leverage psychological principles like Foot-in-the-Door (FITD), where a small initial request paves the way for a more significant one, to bypass safety alignments, pose a persistent threat to Large Language Models (LLMs). Progress in defending against these attacks is hindered by a reliance on manual, hard-to-scale dataset creation. This paper introduces a novel, automated pipeline for generating large-scale, psychologically-grounded multi-turn jailbreak datasets. We systematically operationalize FITD techniques into reproducible templates, creating a benchmark of 1,500 scenarios across illegal activities and offensive content. We evaluate seven models from three major LLM families under both multi-turn (with history) and single-turn (without history) conditions. Our results reveal stark differences in contextual robustness: models in the GPT family demonstrate a significant vulnerability to conversational history, with Attack Success Rates (ASR) increasing by as much as 32 percentage points. In contrast, Google's Gemini 2.5 Flash exhibits exceptional resilience, proving nearly immune to these attacks, while Anthropic's Claude 3 Haiku shows strong but imperfect resistance. These findings highlight a critical divergence in how current safety architectures handle conversational context and underscore the need for defenses that can resist narrative-based manipulation.

</details>


### [36] [Do Sparse Autoencoders Identify Reasoning Features in Language Models?](https://arxiv.org/abs/2601.05679)
*George Ma,Zhongyuan Liang,Irene Y. Chen,Somayeh Sojoudi*

Main category: cs.LG

TL;DR: 研究发现，通过对比激活方法识别的稀疏自编码器特征主要捕捉推理的语言相关性而非真正的推理计算过程


<details>
  <summary>Details</summary>
Motivation: 探究稀疏自编码器（SAEs）是否真正识别了大型语言模型中的推理特征，而非仅仅是语言相关性

Method: 采用证伪导向框架，结合因果标记注入实验和LLM引导的证伪方法，测试特征激活是否反映推理过程还是表面语言相关性

Result: 在20个配置中，59%-94%的特征对标记级干预高度敏感；剩余特征也无法满足真正推理行为的标准；操纵这些特征对基准性能影响很小或略有下降

Conclusion: 通过对比方法识别的SAE特征主要捕捉推理的语言相关性而非底层推理计算本身

Abstract: We investigate whether sparse autoencoders (SAEs) identify genuine reasoning features in large language models (LLMs). Starting from features selected using standard contrastive activation methods, we introduce a falsification-oriented framework that combines causal token injection experiments and LLM-guided falsification to test whether feature activation reflects reasoning processes or superficial linguistic correlates. Across 20 configurations spanning multiple model families, layers, and reasoning datasets, we find that identified reasoning features are highly sensitive to token-level interventions. Injecting a small number of feature-associated tokens into non-reasoning text is sufficient to elicit strong activation for 59% to 94% of features, indicating reliance on lexical artifacts. For the remaining features that are not explained by simple token triggers, LLM-guided falsification consistently produces non-reasoning inputs that activate the feature and reasoning inputs that do not, with no analyzed feature satisfying our criteria for genuine reasoning behavior. Steering these features yields minimal changes or slight degradations in benchmark performance. Together, these results suggest that SAE features identified by contrastive approaches primarily capture linguistic correlates of reasoning rather than the underlying reasoning computations themselves.

</details>


### [37] [Tiny Recursive Models on ARC-AGI-1: Inductive Biases, Identity Conditioning, and Test-Time Compute](https://arxiv.org/abs/2512.11847)
*Antonio Roye-Azar,Santiago Vargas-Naranjo,Dhruv Ghai,Nithin Balamurugan,Rayan Amir*

Main category: cs.LG

TL;DR: TRM在ARC-AGI-1上的性能主要源于测试时增强、多数投票集成、任务标识符依赖和浅层递归，而非深度推理能力


<details>
  <summary>Details</summary>
Motivation: 分析TRM在ARC-AGI-1任务上的真实性能来源，区分架构优势、测试时计算和任务先验的贡献

Method: 通过四个实验分析：1)测试时增强和投票集成的影响；2)任务标识符消融；3)递归轨迹分析；4)训练增强对比；5)与Llama 3 8B QLoRA的效率比较

Result: 测试时增强提升11%准确率；严格依赖任务ID；递归在第一步即达大部分性能；增强训练提升多样本成功率；TRM在吞吐量和内存效率上显著优于Llama 3 8B

Conclusion: TRM的ARC-AGI-1性能主要来自效率优势、任务特定条件化和激进的测试时计算，而非深度内部推理能力

Abstract: Tiny Recursive Models (TRM) were proposed as a parameter-efficient alternative to large language models for solving Abstraction and Reasoning Corpus (ARC) style tasks. The original work reports strong performance and suggests that recursive latent updates enable non-trivial reasoning, but it remains unclear how much of this performance stems from architecture, test-time compute, or task-specific priors. In this technical note, we empirically analyze the ARC Prize TRM checkpoint on ARC-AGI-1 and report four behavioral findings and an efficiency comparison. First, we show that test-time augmentation and majority-vote ensembling account for a substantial fraction of reported performance: the 1000-sample voting pipeline improves Pass@1 by about 11 percentage points over single-pass canonical inference. Second, a puzzle-identity ablation reveals strict dependence on task identifiers: replacing the correct puzzle ID with a blank or random token yields zero accuracy. Third, a recursion trajectory analysis shows that most of the final accuracy is achieved at the first recursion step and that performance saturates after few latent updates, indicating shallow effective recursion. Fourth, early-stage training experiments under canonical versus heavy augmentation regimes suggest that heavy augmentation broadens the distribution of candidate solutions and improves multi-sample success. Finally, we compare TRM with a naive QLoRA fine-tune of Llama 3 8B on canonical ARC-AGI-1, finding that TRM's non-autoregressive design achieves much higher throughput and substantially lower memory usage in this setting. Overall, TRM's ARC-AGI-1 performance appears to arise from an interaction between efficiency, task-specific conditioning, and aggressive test-time compute rather than deep internal reasoning.

</details>


### [38] [AGDC: Autoregressive Generation of Variable-Length Sequences with Joint Discrete and Continuous Spaces](https://arxiv.org/abs/2601.05680)
*Yeonsang Shin,Insoo Kim,Bongkeun Kim,Keonwoo Bae,Bohyung Han*

Main category: cs.LG

TL;DR: AGDC：一个统一框架，联合建模离散和连续值以生成高精度混合向量序列，特别适用于半导体电路设计等需要高精度的领域。


<details>
  <summary>Details</summary>
Motivation: 基于Transformer的自回归模型在数据生成方面表现出色，但受限于离散化token的依赖，难以高精度表示连续值。现有离散化方法在生成混合离散-连续序列时存在可扩展性限制，特别是在半导体电路设计等高精度领域，精度损失可能导致功能失效。

Method: 提出AGDC框架，采用混合方法：对离散值使用分类预测，对连续值使用基于扩散的建模。包含两个关键技术组件：1) EOS logit调整机制，使用MLP根据序列上下文动态调整EOS token的logits；2) 集成到损失函数中的长度正则化项。同时提出ContLayNet基准数据集，包含334K个高精度半导体布局样本及专门评估指标。

Result: 在半导体布局（ContLayNet）、图形布局和SVG数据集上的实验表明，AGDC在生成高保真混合向量表示方面优于基于离散化和固定模式的基线方法，实现了跨领域可扩展的高精度生成。

Conclusion: AGDC框架成功解决了Transformer模型在高精度混合离散-连续序列生成中的局限性，通过联合建模离散和连续值，实现了可扩展的高精度生成，在半导体电路设计等关键领域具有重要应用价值。

Abstract: Transformer-based autoregressive models excel in data generation but are inherently constrained by their reliance on discretized tokens, which limits their ability to represent continuous values with high precision. We analyze the scalability limitations of existing discretization-based approaches for generating hybrid discrete-continuous sequences, particularly in high-precision domains such as semiconductor circuit designs, where precision loss can lead to functional failure. To address the challenge, we propose AGDC, a novel unified framework that jointly models discrete and continuous values for variable-length sequences. AGDC employs a hybrid approach that combines categorical prediction for discrete values with diffusion-based modeling for continuous values, incorporating two key technical components: an end-of-sequence (EOS) logit adjustment mechanism that uses an MLP to dynamically adjust EOS token logits based on sequence context, and a length regularization term integrated into the loss function. Additionally, we present ContLayNet, a large-scale benchmark comprising 334K high-precision semiconductor layout samples with specialized evaluation metrics that capture functional correctness where precision errors significantly impact performance. Experiments on semiconductor layouts (ContLayNet), graphic layouts, and SVGs demonstrate AGDC's superior performance in generating high-fidelity hybrid vector representations compared to discretization-based and fixed-schema baselines, achieving scalable high-precision generation across diverse domains.

</details>


### [39] [FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching](https://arxiv.org/abs/2601.05684)
*Hongyaoxing Gul,Lijuan Hu,Shuzi Niu,Fangfang Liu*

Main category: cs.LG

TL;DR: FLRQ是一种灵活的LLM低秩量化方法，通过快速识别最优秩并聚合实现最小存储组合，包含R1-FLR和BLC两个组件，在量化质量和算法效率上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 传统低秩PTQ方法需要昂贵的微调来确定不同数据和层的最佳秩，且SVD低秩近似计算开销大，未能充分利用LLM的潜力。需要一种能快速确定最优秩并最小化量化误差的高效方法。

Method: 提出FLRQ框架，包含两个核心组件：1) R1-FLR：使用R1-Sketch和高斯投影进行快速低秩近似，实现异常值感知的逐层秩提取；2) BLC：通过迭代方法在缩放和裁剪策略下最小化低秩量化误差。该方法能快速识别精度最优的秩并聚合实现最小存储组合。

Result: FLRQ在综合实验中表现出强大的有效性和鲁棒性，在量化质量和算法效率方面均达到最先进的性能。

Conclusion: FLRQ通过灵活的秩选择和优化的低秩量化误差最小化，为LLM后训练量化提供了一种高效且有效的解决方案，克服了传统低秩PTQ方法的局限性。

Abstract: Traditional post-training quantization (PTQ) is considered an effective approach to reduce model size and accelerate inference of large-scale language models (LLMs). However, existing low-rank PTQ methods require costly fine-tuning to determine a compromise rank for diverse data and layers in large models, failing to exploit their full potential. Additionally, the current SVD-based low-rank approximation compounds the computational overhead. In this work, we thoroughly analyze the varying effectiveness of low-rank approximation across different layers in representative models. Accordingly, we introduce \underline{F}lexible \underline{L}ow-\underline{R}ank \underline{Q}uantization (FLRQ), a novel solution designed to quickly identify the accuracy-optimal ranks and aggregate them to achieve minimal storage combinations. FLRQ comprises two powerful components, Rank1-Sketch-based Flexible Rank Selection (R1-FLR) and Best Low-rank Approximation under Clipping (BLC). R1-FLR applies the R1-Sketch with Gaussian projection for the fast low-rank approximation, enabling outlier-aware rank extraction for each layer. Meanwhile, BLC aims at minimizing the low-rank quantization error under the scaling and clipping strategy through an iterative method. FLRQ demonstrates strong effectiveness and robustness in comprehensive experiments, achieving state-of-the-art performance in both quantization quality and algorithm efficiency.

</details>


### [40] [Variational Autoencoders for P-wave Detection on Strong Motion Earthquake Spectrograms](https://arxiv.org/abs/2601.05759)
*Turkan Simge Ispak,Salih Tileylioglu,Erdem Akagunduz*

Main category: cs.LG

TL;DR: 该研究将P波到达检测重新定义为自监督异常检测任务，通过492个变分自编码器配置的网格搜索，发现注意力机制优于跳跃连接，在近源范围（0-40公里）达到0.91的AUC，适合地震早期预警应用。


<details>
  <summary>Details</summary>
Motivation: 强震记录中的P波检测面临高噪声水平、有限标记数据和复杂波形特征的挑战，而准确的P波检测对地震早期预警至关重要。研究旨在探索如何通过架构设计平衡重建保真度和异常检测性能。

Method: 将P波到达检测重新定义为自监督异常检测任务，通过492个变分自编码器配置的全面网格搜索，比较不同架构（包括跳跃连接和注意力机制）在重建误差和异常检测性能之间的权衡。

Result: 跳跃连接虽然能最小化重建误差（MAE约0.0012），但会导致"过度泛化"，使模型能够重建噪声并掩盖检测信号。相比之下，注意力机制优先考虑全局上下文而非局部细节，获得最高的检测性能（AUC 0.875），在0-40公里近源范围内AUC达到0.91。

Conclusion: 优先考虑全局上下文而非像素级完美重建的架构约束对于鲁棒的自监督P波检测至关重要。注意力机制的变分自编码器在近源范围内表现出色，非常适合立即的早期预警应用。

Abstract: Accurate P-wave detection is critical for earthquake early warning, yet strong-motion records pose challenges due to high noise levels, limited labeled data, and complex waveform characteristics. This study reframes P-wave arrival detection as a self-supervised anomaly detection task to evaluate how architectural variations regulate the trade-off between reconstruction fidelity and anomaly discrimination. Through a comprehensive grid search of 492 Variational Autoencoder configurations, we show that while skip connections minimize reconstruction error (Mean Absolute Error approximately 0.0012), they induce "overgeneralization", allowing the model to reconstruct noise and masking the detection signal. In contrast, attention mechanisms prioritize global context over local detail and yield the highest detection performance with an area-under-the-curve of 0.875. The attention-based Variational Autoencoder achieves an area-under-the-curve of 0.91 in the 0 to 40-kilometer near-source range, demonstrating high suitability for immediate early warning applications. These findings establish that architectural constraints favoring global context over pixel-perfect reconstruction are essential for robust, self-supervised P-wave detection.

</details>


### [41] [Weights to Code: Extracting Interpretable Algorithms from the Discrete Transformer](https://arxiv.org/abs/2601.05770)
*Yifan Zhang,Wei Bi,Kechi Zhang,Dongming Jin,Jie Fu,Zhi Jin*

Main category: cs.LG

TL;DR: 提出Discrete Transformer架构，通过功能解耦和温度退火采样，从连续表示中提取离散符号逻辑，实现无演示的算法发现和Transformer可解释性。


<details>
  <summary>Details</summary>
Motivation: Transformer在算法提取任务中存在叠加问题，即纠缠的特征编码在重叠方向上阻碍了符号表达式的提取。需要弥合连续表示与离散符号逻辑之间的鸿沟。

Method: 提出Discrete Transformer架构：1）严格的功能解耦，约束数值注意力仅用于信息路由，数值MLP仅用于逐元素算术运算；2）采用温度退火采样策略；3）通过施加归纳偏置实现对合成程序的细粒度控制。

Result: 1）性能与RNN基线相当；2）将可解释性扩展到连续变量域；3）退火过程显示从探索到利用的清晰相变；4）能够通过归纳偏置控制合成程序。

Conclusion: Discrete Transformer为无演示的算法发现提供了稳健框架，为Transformer可解释性提供了严格途径，成功弥合了连续表示与离散符号逻辑之间的鸿沟。

Abstract: Algorithm extraction aims to synthesize executable programs directly from models trained on specific algorithmic tasks, enabling de novo algorithm discovery without relying on human-written code. However, extending this paradigm to Transformer is hindered by superposition, where entangled features encoded in overlapping directions obstruct the extraction of symbolic expressions. In this work, we propose the Discrete Transformer, an architecture explicitly engineered to bridge the gap between continuous representations and discrete symbolic logic. By enforcing a strict functional disentanglement, which constrains Numerical Attention to information routing and Numerical MLP to element-wise arithmetic, and employing temperature-annealed sampling, our method effectively facilitates the extraction of human-readable programs. Empirically, the Discrete Transformer not only achieves performance comparable to RNN-based baselines but crucially extends interpretability to continuous variable domains. Moreover, our analysis of the annealing process shows that the efficient discrete search undergoes a clear phase transition from exploration to exploitation. We further demonstrate that our method enables fine-grained control over synthesized programs by imposing inductive biases. Collectively, these findings establish the Discrete Transformer as a robust framework for demonstration-free algorithm discovery, offering a rigorous pathway toward Transformer interpretability.

</details>


### [42] [Tensor-DTI: Enhancing Biomolecular Interaction Prediction with Contrastive Embedding Learning](https://arxiv.org/abs/2601.05792)
*Manel Gil-Sorribes,Júlia Vilalta-Mor,Isaac Filella-Mercè,Robert Soliva,Álvaro Ciudad,Víctor Guallar,Alexis Molina*

Main category: cs.LG

TL;DR: Tensor-DTI：一种基于对比学习的多模态药物-靶点相互作用预测框架，整合分子图、蛋白质语言模型和结合位点预测信息，在多个基准测试中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有药物-靶点相互作用预测模型通常依赖单模态预定义分子描述符或代表性有限的序列嵌入，需要更全面的多模态表示来改进相互作用建模

Method: 提出Tensor-DTI对比学习框架，整合分子图、蛋白质语言模型和结合位点预测的多模态嵌入，采用孪生双编码器架构，捕捉化学和结构相互作用特征并区分相互作用与非相互作用对

Result: 在多个DTI基准测试中优于现有序列基和图基模型；在CDK2的十亿级化学库大规模推理实验中，即使训练时排除CDK2也能产生化学合理的命中分布；在富集研究中与Glide对接和Boltz-2共折叠器竞争，在严格家族排除分割下改善外家族靶点的筛选预算

Conclusion: 整合多模态信息与对比学习目标可提高相互作用预测准确性，为虚拟筛选提供更可解释和可靠性感知的模型，框架还可应用于蛋白质-RNA和肽-蛋白质相互作用

Abstract: Accurate drug-target interaction (DTI) prediction is essential for computational drug discovery, yet existing models often rely on single-modality predefined molecular descriptors or sequence-based embeddings with limited representativeness. We propose Tensor-DTI, a contrastive learning framework that integrates multimodal embeddings from molecular graphs, protein language models, and binding-site predictions to improve interaction modeling. Tensor-DTI employs a siamese dual-encoder architecture, enabling it to capture both chemical and structural interaction features while distinguishing interacting from non-interacting pairs. Evaluations on multiple DTI benchmarks demonstrate that Tensor-DTI outperforms existing sequence-based and graph-based models. We also conduct large-scale inference experiments on CDK2 across billion-scale chemical libraries, where Tensor-DTI produces chemically plausible hit distributions even when CDK2 is withheld from training. In enrichment studies against Glide docking and Boltz-2 co-folder, Tensor-DTI remains competitive on CDK2 and improves the screening budget required to recover moderate fractions of high-affinity ligands on out-of-family targets under strict family-holdout splits. Additionally, we explore its applicability to protein-RNA and peptide-protein interactions. Our findings highlight the benefits of integrating multimodal information with contrastive objectives to enhance interaction-prediction accuracy and to provide more interpretable and reliability-aware models for virtual screening.

</details>


### [43] [Fusion Matters: Length-Aware Analysis of Positional-Encoding Fusion in Transformers](https://arxiv.org/abs/2601.05807)
*Mohamed Amine Hallam,Kuo-Kun Tseng*

Main category: cs.LG

TL;DR: 研究位置编码融合机制对Transformer性能的影响，发现融合方式在长序列任务中显著影响性能，而在短序列中影响可忽略


<details>
  <summary>Details</summary>
Motivation: 大多数研究关注设计新的位置编码，而忽略了位置信息如何与词嵌入融合的机制。本文旨在探究融合机制本身是否影响性能，特别是在长序列场景下

Method: 在相同Transformer架构、数据划分和随机种子下，对比三种经典融合策略：逐元素加法、拼接加投影、标量门控融合。使用三个文本分类数据集（AG News短序列、IMDB中序列、ArXiv长序列），并进行配对种子分析和跨数据集比较

Result: 融合选择对短文本影响可忽略，但在长文档上产生一致性能提升。可学习融合的益处适用于多种位置编码家族。轻量级卷积门控机制在长文档上引入局部归纳偏置

Conclusion: 位置编码融合是长序列Transformer的重要设计选择，应作为显式建模决策而非固定默认设置

Abstract: Transformers require positional encodings to represent sequence order, yet most prior work focuses on designing new positional encodings rather than examining how positional information is fused with token embeddings. In this paper, we study whether the fusion mechanism itself affects performance, particularly in long-sequence settings. We conduct a controlled empirical study comparing three canonical fusion strategies--element-wise addition, concatenation with projection, and scalar gated fusion--under identical Transformer architectures, data splits, and random seeds. Experiments on three text classification datasets spanning short (AG News), medium (IMDB), and long (ArXiv) sequences show that fusion choice has negligible impact on short texts but produces consistent gains on long documents. To verify that these gains are structural rather than stochastic, we perform paired-seed analysis and cross-dataset comparison across sequence-length regimes. Additional experiments on the ArXiv dataset indicate that the benefit of learnable fusion generalizes across multiple positional encoding families. Finally, we explore a lightweight convolutional gating mechanism that introduces local inductive bias at the fusion level, evaluated on long documents only. Our results indicate that positional-encoding fusion is a non-trivial design choice for long-sequence Transformers and should be treated as an explicit modeling decision rather than a fixed default.

</details>


### [44] [Detecting Autism Spectrum Disorder with Deep Eye Movement Features](https://arxiv.org/abs/2601.05812)
*Zhanpei Huang,Taochen chen,Fangqing Gu,Yiqun Zhang*

Main category: cs.LG

TL;DR: 提出DSTS框架用于自闭症谱系障碍检测，通过离散短期序列建模、类别感知表示和不平衡感知机制，在眼动数据上优于传统机器学习和深度学习模型


<details>
  <summary>Details</summary>
Motivation: 眼动数据具有离散性和短期时间依赖性，适合作为ASD的非侵入性诊断工具。然而，基于Transformer的全局注意力机制在捕捉眼动数据的局部模式时效果有限，需要专门针对眼动数据特性的建模框架

Method: 设计离散短期序列建模框架，包含类别感知表示机制和不平衡感知机制，专门针对眼动数据的离散性和短期依赖性特征，有效区分ASD和典型发展个体的眼动模式

Result: 在多个眼动数据集上的实验表明，DSTS框架优于传统机器学习方法和复杂深度学习模型，能够更有效地捕捉ASD相关的眼动模式差异

Conclusion: 针对眼动数据的离散性和短期依赖性特征设计的专门建模框架DSTS，在ASD检测任务中表现出优越性能，为基于眼动数据的神经发育障碍诊断提供了有效工具

Abstract: Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by deficits in social communication and behavioral patterns. Eye movement data offers a non-invasive diagnostic tool for ASD detection, as it is inherently discrete and exhibits short-term temporal dependencies, reflecting localized gaze focus between fixation points. These characteristics enable the data to provide deeper insights into subtle behavioral markers, distinguishing ASD-related patterns from typical development. Eye movement signals mainly contain short-term and localized dependencies. However, despite the widespread application of stacked attention layers in Transformer-based models for capturing long-range dependencies, our experimental results indicate that this approach yields only limited benefits when applied to eye movement data. This may be because discrete fixation points and short-term dependencies in gaze focus reduce the utility of global attention mechanisms, making them less efficient than architectures focusing on local temporal patterns. To efficiently capture subtle and complex eye movement patterns, distinguishing ASD from typically developing (TD) individuals, a discrete short-term sequential (DSTS) modeling framework is designed with Class-aware Representation and Imbalance-aware Mechanisms. Through extensive experiments on several eye movement datasets, DSTS outperforms both traditional machine learning techniques and more sophisticated deep learning models.

</details>


### [45] [A New Family of Poisson Non-negative Matrix Factorization Methods Using the Shifted Log Link](https://arxiv.org/abs/2601.05845)
*Eric Weine,Peter Carbonetto,Rafael A. Irizarry,Matthew Stephens*

Main category: cs.LG

TL;DR: 提出了一种使用移位对数连接函数的泊松非负矩阵分解方法，放松了传统方法中"部分"必须加性组合的假设，允许从加性到乘性组合的连续变化。


<details>
  <summary>Details</summary>
Motivation: 传统泊松NMF假设分解的"部分"以加性方式组合，这在某些场景下可能不自然。需要一种更灵活的模型来适应不同数据生成机制。

Method: 引入移位对数连接函数，通过一个调优参数控制从加性到乘性组合的连续变化。开发了最大似然估计算法，并为大型稀疏数据集提供了计算高效的近似方法。

Result: 在多个真实数据集上展示了新方法的有效性。结果表明连接函数的选择对分解结果有实质性影响，移位对数连接函数在某些情况下能提高结果的解释性。

Conclusion: 移位对数连接函数为泊松NMF提供了更灵活的建模框架，放松了加性组合假设，在保持计算效率的同时提高了模型对不同数据生成机制的适应性。

Abstract: Poisson non-negative matrix factorization (NMF) is a widely used method to find interpretable "parts-based" decompositions of count data. While many variants of Poisson NMF exist, existing methods assume that the "parts" in the decomposition combine additively. This assumption may be natural in some settings, but not in others. Here we introduce Poisson NMF with the shifted-log link function to relax this assumption. The shifted-log link function has a single tuning parameter, and as this parameter varies the model changes from assuming that parts combine additively (i.e., standard Poisson NMF) to assuming that parts combine more multiplicatively. We provide an algorithm to fit this model by maximum likelihood, and also an approximation that substantially reduces computation time for large, sparse datasets (computations scale with the number of non-zero entries in the data matrix). We illustrate these new methods on a variety of real datasets. Our examples show how the choice of link function in Poisson NMF can substantively impact the results, and how in some settings the use of a shifted-log link function may improve interpretability compared with the standard, additive link.

</details>


### [46] [IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck](https://arxiv.org/abs/2601.05870)
*Huilin Deng,Hongchen Luo,Yue Zhu,Long Li,Zhuoyue Chen,Xinghao Zhao,Ming Li,Jihai Zhang,Mengchang Wang,Yang Cao,Yu Kang*

Main category: cs.LG

TL;DR: 本文提出IIB-LPO方法，通过迭代信息瓶颈实现潜在策略优化，解决LLM推理中强化学习的探索崩溃问题，在数学推理基准上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于可验证奖励的强化学习方法在LLM推理中存在探索崩溃问题：随机rollout的语义同质性导致模型陷入狭窄、过度优化的行为。虽然现有方法利用策略熵鼓励探索，但全局熵正则化易受奖励攻击导致无意义冗长，而局部token选择性更新则受预训练模型强归纳偏置限制。

Method: 提出Latent Policy Optimization via Iterative Information Bottleneck (IIB-LPO)：将探索从token分布的统计扰动转向推理轨迹的拓扑分支。在高熵状态触发潜在分支以多样化推理路径，并采用信息瓶颈原则同时作为轨迹过滤器和自奖励机制，确保简洁且信息丰富的探索。

Result: 在四个数学推理基准上的实验结果表明，IIB-LPO实现了最先进的性能，在准确率上超越先前方法高达5.3%，在多样性指标上提升7.4%。

Conclusion: IIB-LPO通过将探索从统计扰动转向拓扑分支，有效解决了LLM推理中强化学习的探索崩溃问题，实现了更优的性能和多样性平衡。

Abstract: Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) for Large Language Model (LLM) reasoning have been hindered by a persistent challenge: exploration collapse. The semantic homogeneity of random rollouts often traps models in narrow, over-optimized behaviors. While existing methods leverage policy entropy to encourage exploration, they face inherent limitations. Global entropy regularization is susceptible to reward hacking, which can induce meaningless verbosity, whereas local token-selective updates struggle with the strong inductive bias of pre-trained models. To address this, we propose Latent Policy Optimization via Iterative Information Bottleneck (IIB-LPO), a novel approach that shifts exploration from statistical perturbation of token distributions to topological branching of reasoning trajectories. IIB-LPO triggers latent branching at high-entropy states to diversify reasoning paths and employs the Information Bottleneck principle both as a trajectory filter and a self-reward mechanism, ensuring concise and informative exploration. Empirical results across four mathematical reasoning benchmarks demonstrate that IIB-LPO achieves state-of-the-art performance, surpassing prior methods by margins of up to 5.3% in accuracy and 7.4% in diversity metrics.

</details>


### [47] [Auditing Fairness under Model Updates: Fundamental Complexity and Property-Preserving Updates](https://arxiv.org/abs/2601.05909)
*Ayoub Ajarra,Debabrota Basu*

Main category: cs.LG

TL;DR: 提出一个用于机器学习模型在任意更新下进行群体公平性审计的通用框架，基于经验属性优化（EPO）预言机，建立了由SP维度表征的分布无关审计界限


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型越来越多地嵌入社会基础设施，审计模型偏见变得日益重要。然而在现实部署中，模型所有者可能根据环境变化（如金融市场）自适应更新模型，这些更新会改变底层模型类别但保留某些重要属性，这引发了在模型更新下可靠审计的基本问题

Method: 提出基于经验属性优化（EPO）预言机的通用PAC审计框架。对于统计公平性，建立了由SP维度（一种捕捉可允许战略更新复杂性的新颖组合度量）表征的分布无关审计界限。该框架可扩展到其他审计目标

Result: 建立了群体公平性审计在任意更新下的理论界限，通过SP维度量化了可允许战略更新的信息复杂度。证明了该框架能够使用最少的标记样本高效估计审计属性，并自然扩展到预测误差和鲁棒风险等其他审计目标

Conclusion: 该工作为在模型自适应更新环境下进行可靠审计提供了理论基础和实用框架，通过引入SP维度这一组合度量来量化战略更新的复杂性，为机器学习模型在动态部署环境中的公平性审计提供了系统方法

Abstract: As machine learning models become increasingly embedded in societal infrastructure, auditing them for bias is of growing importance. However, in real-world deployments, auditing is complicated by the fact that model owners may adaptively update their models in response to changing environments, such as financial markets. These updates can alter the underlying model class while preserving certain properties of interest, raising fundamental questions about what can be reliably audited under such shifts.
  In this work, we study group fairness auditing under arbitrary updates. We consider general shifts that modify the pre-audit model class while maintaining invariance of the audited property. Our goals are two-fold: (i) to characterize the information complexity of allowable updates, by identifying which strategic changes preserve the property under audit; and (ii) to efficiently estimate auditing properties, such as group fairness, using a minimal number of labeled samples.
  We propose a generic framework for PAC auditing based on an Empirical Property Optimization (EPO) oracle. For statistical parity, we establish distribution-free auditing bounds characterized by the SP dimension, a novel combinatorial measure that captures the complexity of admissible strategic updates. Finally, we demonstrate that our framework naturally extends to other auditing objectives, including prediction error and robust risk.

</details>


### [48] [Distilling Lightweight Domain Experts from Large ML Models by Identifying Relevant Subspaces](https://arxiv.org/abs/2601.05913)
*Pattarawat Chormai,Ali Hashemi,Klaus-Robert Müller,Grégoire Montavon*

Main category: cs.LG

TL;DR: SubDistill：一种新的知识蒸馏算法，专注于仅蒸馏教师模型中与特定子任务相关的组件，在有限计算环境下提升学生模型性能


<details>
  <summary>Details</summary>
Motivation: 实际应用中通常只有少数类别及其相关中间概念需要蒸馏，但现有蒸馏方法很少明确关注相关子任务，需要专门针对子任务蒸馏的算法

Method: 提出SubDistill算法，具有改进的数值特性，在每一层仅蒸馏教师模型的相关组件，通过层间蒸馏技术实现

Result: 在CIFAR-100和ImageNet数据集上，使用卷积和Transformer模型进行实验，SubDistill在代表性子任务集上优于现有层间蒸馏技术

Conclusion: SubDistill算法能更有效地将教师模型的预测能力转移到学生模型，特别是在子任务蒸馏场景中，蒸馏后的学生模型更接近原始教师模型的决策结构

Abstract: Knowledge distillation involves transferring the predictive capabilities of large, high-performing AI models (teachers) to smaller models (students) that can operate in environments with limited computing power. In this paper, we address the scenario in which only a few classes and their associated intermediate concepts are relevant to distill. This scenario is common in practice, yet few existing distillation methods explicitly focus on the relevant subtask. To address this gap, we introduce 'SubDistill', a new distillation algorithm with improved numerical properties that only distills the relevant components of the teacher model at each layer. Experiments on CIFAR-100 and ImageNet with Convolutional and Transformer models demonstrate that SubDistill outperforms existing layer-wise distillation techniques on a representative set of subtasks. Our benchmark evaluations are complemented by Explainable AI analyses showing that our distilled student models more closely match the decision structure of the original teacher model.

</details>


### [49] [Prophet as a Reproducible Forecasting Framework: A Methodological Guide for Business and Financial Analytics](https://arxiv.org/abs/2601.05929)
*Sidney Shapiro,Burhanuddin Panvelwala*

Main category: cs.LG

TL;DR: 该研究评估了Meta开发的Prophet预测框架在可重复性方面的优势，通过多模型对比实验证明Prophet在平衡可解释性、标准化工作流程和可访问性方面的价值，为Python研究环境提供了可重复预测的实用参考框架。


<details>
  <summary>Details</summary>
Motivation: 预测研究与实践中的可重复性挑战，特别是在商业和金融分析领域，传统方法需要大量手动调参且难以在专有环境中复制，机器学习方法虽然灵活但存在可解释性和随机训练过程的问题，需要寻找平衡可解释性、标准化和可访问性的解决方案。

Method: 使用公开可用的金融和零售数据集，在受控且完全文档化的实验设计下，将Prophet与多种ARIMA规格（自动选择、手动指定和季节性变体）以及随机森林进行性能与可解释性比较，通过具体Python示例展示Prophet如何促进高效预测工作流程。

Result: 多模型比较提供了对Prophet相对性能和可重复性优势的稳健评估，证明Prophet的加性结构、开源实现和标准化工作流程有助于透明和可复制的预测实践，能够支持验证、可审计性和方法严谨性。

Conclusion: Prophet作为可重复性增强解决方案，在可解释性、标准化工作流程和可访问性之间取得了良好平衡，为基于Python的研究工作流程提供了可重复预测的实用参考框架，支持验证、可审计性和方法严谨性。

Abstract: Reproducibility remains a persistent challenge in forecasting research and practice, particularly in business and financial analytics, where forecasts inform high-stakes decisions. Traditional forecasting methods, while theoretically interpretable, often require extensive manual tuning and are difficult to replicate in proprietary environments. Machine learning approaches offer predictive flexibility but introduce challenges related to interpretability, stochastic training procedures, and cross-environment reproducibility. This paper examines Prophet, an open-source forecasting framework developed by Meta, as a reproducibility-enabling solution that balances interpretability, standardized workflows, and accessibility. Rather than proposing a new algorithm, this study evaluates how Prophet's additive structure, open-source implementation, and standardized workflow contribute to transparent and replicable forecasting practice. Using publicly available financial and retail datasets, we compare the performance and interpretability of Prophet with multiple ARIMA specifications (auto-selected, manually specified, and seasonal variants) and Random Forest, under a controlled and fully documented experimental design. This multi-model comparison provides a robust assessment of Prophet's relative performance and reproducibility advantages. Through concrete Python examples, we demonstrate how Prophet facilitates efficient forecasting workflows and integration with analytical pipelines. The study positions Prophet within the broader context of reproducible research. It highlights Prophet's role as a methodological building block that supports verification, auditability, and methodological rigor. This work provides researchers and practitioners with a practical reference framework for reproducible forecasting in Python-based research workflows.

</details>


### [50] [LookAroundNet: Extending Temporal Context with Transformers for Clinically Viable EEG Seizure Detection](https://arxiv.org/abs/2601.06016)
*Þór Sverrisson,Steinn Guðmundsson*

Main category: cs.LG

TL;DR: LookAroundNet：基于Transformer的癫痫检测模型，利用更宽时间窗口的EEG数据，结合前后上下文信息，在多种临床和家庭监测条件下表现优异


<details>
  <summary>Details</summary>
Motivation: 现有自动癫痫检测方法面临挑战，主要由于癫痫动态在不同患者、记录条件和临床环境中的巨大变异性。临床医生在解读EEG时通常会参考周围上下文信息，但现有自动方法往往只关注局部片段。

Method: 提出LookAroundNet，一种基于Transformer的癫痫检测器，使用更宽的EEG时间窗口来建模癫痫活动。该方法结合感兴趣片段前后的EEG信号，模拟临床医生使用周围上下文解读EEG的方式。在多个EEG数据集上进行评估，包括常规临床EEG和长期动态记录，涵盖不同数据分布。采用模型集成策略。

Result: LookAroundNet在多个数据集上表现出色，对未见过的记录条件具有良好的泛化能力，计算成本适合实际临床部署。结果表明，扩展的时间上下文、增加训练数据多样性和模型集成是提升性能的关键因素。

Conclusion: 这项工作推动了自动癫痫检测模型向临床可行解决方案的发展。通过结合更宽的时间上下文和多样化的训练数据，LookAroundNet展示了在真实世界临床环境中部署的潜力。

Abstract: Automated seizure detection from electroencephalography (EEG) remains difficult due to the large variability of seizure dynamics across patients, recording conditions, and clinical settings. We introduce LookAroundNet, a transformer-based seizure detector that uses a wider temporal window of EEG data to model seizure activity. The seizure detector incorporates EEG signals before and after the segment of interest, reflecting how clinicians use surrounding context when interpreting EEG recordings. We evaluate the proposed method on multiple EEG datasets spanning diverse clinical environments, patient populations, and recording modalities, including routine clinical EEG and long-term ambulatory recordings, in order to study performance across varying data distributions. The evaluation includes publicly available datasets as well as a large proprietary collection of home EEG recordings, providing complementary views of controlled clinical data and unconstrained home-monitoring conditions. Our results show that LookAroundNet achieves strong performance across datasets, generalizes well to previously unseen recording conditions, and operates with computational costs compatible with real-world clinical deployment. The results indicate that extended temporal context, increased training data diversity, and model ensembling are key factors for improving performance. This work contributes to moving automatic seizure detection models toward clinically viable solutions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [51] [Mathematical Knowledge Graph-Driven Framework for Equation-Based Predictive and Reliable Additive Manufacturing](https://arxiv.org/abs/2601.05298)
*Yeongbin Cha,Namjung Kim*

Main category: cs.AI

TL;DR: 提出一种本体引导、方程中心的框架，将大语言模型与增材制造数学知识图谱结合，实现可靠的知识提取和外推建模


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法受限于碎片化的知识表示和稀疏数据条件下的不可靠外推，需要更可靠的知识提取和外推建模方法

Method: 1) 构建增材制造数学知识图谱(AM-MKG)，形式化编码方程、变量、假设及其语义关系；2) 基于知识图谱子图条件化LLM方程生成，确保物理意义；3) 引入置信感知外推评估，整合外推距离、统计稳定性和物理一致性

Result: 本体引导提取显著改善知识提取的结构一致性和定量可靠性；子图条件化方程生成相比无引导LLM输出产生更稳定、物理一致的外推结果

Conclusion: 建立了本体驱动知识表示、方程中心推理和置信外推评估的统一流程，展示了知识图谱增强LLM作为增材制造外推建模可靠工具的潜力

Abstract: Additive manufacturing (AM) relies critically on understanding and extrapolating process-property relationships; however, existing data-driven approaches remain limited by fragmented knowledge representations and unreliable extrapolation under sparse data conditions. In this study, we propose an ontology-guided, equation-centric framework that tightly integrates large language models (LLMs) with an additive manufacturing mathematical knowledge graph (AM-MKG) to enable reliable knowledge extraction and principled extrapolative modeling. By explicitly encoding equations, variables, assumptions, and their semantic relationships within a formal ontology, unstructured literature is transformed into machine-interpretable representations that support structured querying and reasoning. LLM-based equation generation is further conditioned on MKG-derived subgraphs, enforcing physically meaningful functional forms and mitigating non-physical or unstable extrapolation trends. To assess reliability beyond conventional predictive uncertainty, a confidence-aware extrapolation assessment is introduced, integrating extrapolation distance, statistical stability, and knowledge-graph-based physical consistency into a unified confidence score. Results demonstrate that ontology-guided extraction significantly improves the structural coherence and quantitative reliability of extracted knowledge, while subgraph-conditioned equation generation yields stable and physically consistent extrapolations compared to unguided LLM outputs. Overall, this work establishes a unified pipeline for ontology-driven knowledge representation, equation-centered reasoning, and confidence-based extrapolation assessment, highlighting the potential of knowledge-graph-augmented LLMs as reliable tools for extrapolative modeling in additive manufacturing.

</details>


### [52] [Improving Enzyme Prediction with Chemical Reaction Equations by Hypergraph-Enhanced Knowledge Graph Embeddings](https://arxiv.org/abs/2601.05330)
*Tengwei Song,Long Yin,Zhen Han,Zhiqiang Xu*

Main category: cs.AI

TL;DR: 提出Hyper-Enz模型，利用知识图谱嵌入和超图transformer从化学反应方程预测酶-底物相互作用，显著提升预测性能


<details>
  <summary>Details</summary>
Motivation: 传统酶-底物相互作用预测方法依赖专家标注的稀疏数据库，数据不足限制模型泛化能力。化学反应方程数据更易获取且更丰富，但多化合物与同一酶的复杂关系模式难以被传统模型捕捉

Method: 将化学反应方程表示为(底物，酶，产物)三元组构建知识图谱，提出Hyper-Enz模型：结合超图transformer和知识图谱嵌入学习涉及多个底物和产物的超边表示，引入多专家范式指导酶-底物相互作用学习

Result: 实验显示显著改进：酶检索准确率相对提升达88%，配对级预测提升30%，优于传统模型

Conclusion: Hyper-Enz通过整合知识图谱嵌入和超图transformer有效捕捉化学反应中的复杂关系，为酶-底物相互作用预测提供有效解决方案

Abstract: Predicting enzyme-substrate interactions has long been a fundamental problem in biochemistry and metabolic engineering. While existing methods could leverage databases of expert-curated enzyme-substrate pairs for models to learn from known pair interactions, the databases are often sparse, i.e., there are only limited and incomplete examples of such pairs, and also labor-intensive to maintain. This lack of sufficient training data significantly hinders the ability of traditional enzyme prediction models to generalize to unseen interactions. In this work, we try to exploit chemical reaction equations from domain-specific databases, given their easier accessibility and denser, more abundant data. However, interactions of multiple compounds, e.g., educts and products, with the same enzymes create complex relational data patterns that traditional models cannot easily capture. To tackle that, we represent chemical reaction equations as triples of (educt, enzyme, product) within a knowledge graph, such that we can take advantage of knowledge graph embedding (KGE) to infer missing enzyme-substrate pairs for graph completion. Particularly, in order to capture intricate relationships among compounds, we propose our knowledge-enhanced hypergraph model for enzyme prediction, i.e., Hyper-Enz, which integrates a hypergraph transformer with a KGE model to learn representations of the hyper-edges that involve multiple educts and products. Also, a multi-expert paradigm is introduced to guide the learning of enzyme-substrate interactions with both the proposed model and chemical reaction equations. Experimental results show a significant improvement, with up to a 88% relative improvement in average enzyme retrieval accuracy and 30% improvement in pair-level prediction compared to traditional models, demonstrating the effectiveness of our approach.

</details>


### [53] [The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models](https://arxiv.org/abs/2601.05376)
*Tassallah Abdullahi,Shrestha Ghosh,Hamish S Fraser,Daniel León Tramontini,Adeel Abbasi,Ghada Bourjeily,Carsten Eickhoff,Ritambhara Singh*

Main category: cs.AI

TL;DR: 医疗角色设定在临床LLMs中产生系统性、情境依赖且非单调的影响：在重症监护任务中提升性能，但在初级护理中降低性能；交互风格调节风险倾向但高度模型依赖；人类临床医生对安全性合规性有中等一致性但对推理质量信心低


<details>
  <summary>Details</summary>
Motivation: 角色设定通常被视为LLMs的行为先验，被认为能单调地提升专业性和安全性，但其对高风险临床决策的影响尚不明确，需要系统评估医疗角色设定在临床LLMs中的实际效果

Method: 系统评估基于角色的控制，考察专业角色（急诊科医生、护士等）和交互风格（大胆vs谨慎）在不同模型和医疗任务中的影响；使用多维评估方法，包括任务准确性、校准和安全性相关风险行为；采用LLM-judge排名和人类临床医生评估

Result: 医疗角色在重症监护任务中提升性能（准确性和校准提升约20%），但在初级护理环境中降低性能（降幅相当）；交互风格调节风险倾向和敏感性，但高度模型依赖；LLM-judge排名在安全关键案例中更偏好医疗角色；人类临床医生对安全性合规性有中等一致性（平均Cohen's κ=0.43），但对95.9%的推理质量回答信心低

Conclusion: 角色设定作为行为先验引入情境依赖的权衡，而非安全或专业性的保证；需要更细致地理解角色设定在临床决策中的影响，避免简单假设其单调有益

Abstract: Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly characterized. We systematically evaluate persona-based control in clinical LLMs, examining how professional roles (e.g., Emergency Department physician, nurse) and interaction styles (bold vs.\ cautious) influence behavior across models and medical tasks. We assess performance on clinical triage and patient-safety tasks using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior. We find systematic, context-dependent, and non-monotonic effects: Medical personas improve performance in critical care tasks, yielding gains of up to $\sim+20\%$ in accuracy and calibration, but degrade performance in primary-care settings by comparable margins. Interaction style modulates risk propensity and sensitivity, but it's highly model-dependent. While aggregated LLM-judge rankings favor medical over non-medical personas in safety-critical cases, we found that human clinicians show moderate agreement on safety compliance (average Cohen's $κ= 0.43$) but indicate a low confidence in 95.9\% of their responses on reasoning quality. Our work shows that personas function as behavioral priors that introduce context-dependent trade-offs rather than guarantees of safety or expertise. The code is available at https://github.com/rsinghlab/Persona\_Paradox.

</details>


### [54] [On the Effect of Cheating in Chess](https://arxiv.org/abs/2601.05386)
*Daniel Keren*

Main category: cs.AI

TL;DR: 研究通过有限次作弊（使用强大软件建议）在国际象棋中可能获得的性能提升，而非传统的作弊检测方法


<details>
  <summary>Details</summary>
Motivation: 国际象棋中使用强大软件作弊已成为严重问题，甚至影响到最高水平比赛。与以往主要关注作弊检测的研究不同，本研究旨在评估在比赛中有限次数作弊可能带来的性能提升，这对于遏制和检测作弊至关重要。

Method: 开发算法并在常用象棋引擎上进行测试，量化有限次数作弊对棋局表现的影响

Result: 通过算法测试量化了有限次数作弊在国际象棋中可能带来的性能提升效果

Conclusion: 评估作弊可能获得的性能提升对于有效遏制和检测国际象棋作弊至关重要，本研究为此提供了量化方法和结果

Abstract: Cheating in chess, by using advice from powerful software, has become a major problem, reaching the highest levels. As opposed to the large majority of previous work, which concerned {\em detection} of cheating, here we try to evaluate the possible gain in performance, obtained by cheating a limited number of times during a game. Algorithms are developed and tested on a commonly used chess engine (i.e software).\footnote{Needless to say, the goal of this work is not to assist cheaters, but to measure the effectiveness of cheating -- which is crucial as part of the effort to contain and detect it.}

</details>


### [55] [ART: Adaptive Reasoning Trees for Explainable Claim Verification](https://arxiv.org/abs/2601.05455)
*Sahil Wadhwa,Himanshu Kumar,Guanqun Yang,Abbaas Alif Mohamed Nishar,Pranab Mohanty,Swapnil Shinde,Yue Wu*

Main category: cs.AI

TL;DR: ART（自适应推理树）是一种用于声明验证的分层方法，通过构建支持/攻击论点的树状结构，使用LLM作为裁判进行成对比较，实现透明且可争议的推理过程。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂决策中具有潜力，但其不透明性阻碍了在高风险环境中的应用。现有方法（如思维链）缺乏忠实解释和错误纠正机制，损害了可信度。

Method: 提出ART方法：从根声明开始，分支为支持和攻击的子论点。通过LLM裁判对子论点进行成对锦标赛式比较，自底向上确定论点强度，系统推导最终透明且可争议的裁决。

Result: 在多个数据集上实证验证ART，分析不同论点生成器和比较策略。结果表明ART的结构化推理优于强基线，为可解释的声明验证设立了新基准。

Conclusion: ART通过分层推理树结构，解决了LLM在声明验证中的透明度和可争议性问题，提供了更可靠、清晰的决策过程，优于传统方法如思维链。

Abstract: Large Language Models (LLMs) are powerful candidates for complex decision-making, leveraging vast encoded knowledge and remarkable zero-shot abilities. However, their adoption in high-stakes environments is hindered by their opacity; their outputs lack faithful explanations and cannot be effectively contested to correct errors, undermining trustworthiness. In this paper, we propose ART (Adaptive Reasoning Trees), a hierarchical method for claim verification. The process begins with a root claim, which branches into supporting and attacking child arguments. An argument's strength is determined bottom-up via a pairwise tournament of its children, adjudicated by a judge LLM, allowing a final, transparent and contestable verdict to be systematically derived which is missing in methods like Chain-of-Thought (CoT). We empirically validate ART on multiple datasets, analyzing different argument generators and comparison strategies. Our findings show that ART's structured reasoning outperforms strong baselines, establishing a new benchmark for explainable claim verification which is more reliable and ensures clarity in the overall decision making step.

</details>


### [56] [MMUEChange: A Generalized LLM Agent Framework for Intelligent Multi-Modal Urban Environment Change Analysis](https://arxiv.org/abs/2601.05483)
*Zixuan Xiao,Jun Ma,Siwei Zhang*

Main category: cs.AI

TL;DR: MMUEChange是一个多模态智能体框架，通过模块化工具包和模态控制器实现异构城市数据的灵活集成，用于复杂城市环境变化分析，相比最佳基线任务成功率提升46.7%


<details>
  <summary>Details</summary>
Motivation: 当前城市环境变化分析方法（特别是遥感变化检测）通常依赖僵化的单模态分析，无法有效处理复杂的城市变化场景，需要更灵活的多模态集成方法

Method: 提出MMUEChange多模态智能体框架，包含模块化工具包和核心模块"模态控制器"，实现跨模态和模态内对齐，能够灵活整合异构城市数据

Result: 相比最佳基线，MMUEChange智能体任务成功率提升46.7%，有效缓解幻觉问题；案例研究包括纽约小型社区公园转变、香港跨区域水污染扩散、深圳露天垃圾场减少与夜间经济活动关联分析

Conclusion: MMUEChange框架能够支持具有现实政策意义的复杂城市变化分析任务，为可持续城市发展提供有效工具

Abstract: Understanding urban environment change is essential for sustainable development. However, current approaches, particularly remote sensing change detection, often rely on rigid, single-modal analysis. To overcome these limitations, we propose MMUEChange, a multi-modal agent framework that flexibly integrates heterogeneous urban data via a modular toolkit and a core module, Modality Controller for cross- and intra-modal alignment, enabling robust analysis of complex urban change scenarios. Case studies include: a shift toward small, community-focused parks in New York, reflecting local green space efforts; the spread of concentrated water pollution across districts in Hong Kong, pointing to coordinated water management; and a notable decline in open dumpsites in Shenzhen, with contrasting links between nighttime economic activity and waste types, indicating differing urban pressures behind domestic and construction waste. Compared to the best-performing baseline, the MMUEChange agent achieves a 46.7% improvement in task success rate and effectively mitigates hallucination, demonstrating its capacity to support complex urban change analysis tasks with real-world policy implications.

</details>


### [57] [The Evaluation Gap in Medicine, AI and LLMs: Navigating Elusive Ground Truth & Uncertainty via a Probabilistic Paradigm](https://arxiv.org/abs/2601.05500)
*Aparna Elangovan,Lei Xu,Mahsa Elyasi,Ismail Akdulum,Mehmet Aksakal,Enes Gurun,Brian Hur,Saab Mansour,Ravid Shwartz Ziv,Karin Verspoor,Dan Roth*

Main category: cs.AI

TL;DR: 提出概率范式评估AI系统能力，考虑专家标注的不确定性，引入期望准确率和期望F1分数，建议按标注概率分层评估


<details>
  <summary>Details</summary>
Motivation: 当前AI系统能力评估通常忽略专家标注答案的不确定性，这在医学等不确定性普遍存在的领域尤为严重。忽略标注不确定性可能导致误导性结论，如非专家与专家表现相似的错误判断。

Method: 提出概率范式理论框架，解释高确定性标注对专家获得高分的重要性。引入期望准确率和期望F1分数来估计在标注变异性下专家或系统能达到的分数。建议按标注概率（通常通过专家一致率衡量）进行分层评估。

Result: 理论分析表明：在标注答案高度不确定的数据集中，随机标注者与专家之间可能几乎没有差异。当整体性能低于80%阈值时，分层评估变得至关重要。在高确定性标注组中，性能比较更加可靠，能够减轻不确定性这一关键混杂因素的影响。

Conclusion: 评估AI系统能力时应考虑标注不确定性，采用分层评估策略。按标注概率分层后，在高确定性组中进行性能比较更为可靠。当整体性能低于80%时，分层评估尤为关键，可避免因标注不确定性导致的误导性结论。

Abstract: Benchmarking the relative capabilities of AI systems, including Large Language Models (LLMs) and Vision Models, typically ignores the impact of uncertainty in the underlying ground truth answers from experts. This ambiguity is particularly consequential in medicine where uncertainty is pervasive. In this paper, we introduce a probabilistic paradigm to theoretically explain how high certainty in ground truth answers is almost always necessary for even an expert to achieve high scores, whereas in datasets with high variation in ground truth answers there may be little difference between a random labeller and an expert. Therefore, ignoring uncertainty in ground truth evaluation data can result in the misleading conclusion that a non-expert has similar performance to that of an expert. Using the probabilistic paradigm, we thus bring forth the concepts of expected accuracy and expected F1 to estimate the score an expert human or system can achieve given ground truth answer variability.
  Our work leads to the recommendation that when establishing the capability of a system, results should be stratified by probability of the ground truth answer, typically measured by the agreement rate of ground truth experts. Stratification becomes critical when the overall performance drops below a threshold of 80%. Under stratified evaluation, performance comparison becomes more reliable in high certainty bins, mitigating the effect of the key confounding factor -- uncertainty.

</details>


### [58] [Explainable AI: Learning from the Learners](https://arxiv.org/abs/2601.05525)
*Ricardo Vinuesa,Steven L. Brunton,Gianmarco Mengaldo*

Main category: cs.AI

TL;DR: 本文提出将可解释人工智能（XAI）与因果推理相结合，通过"向学习者学习"的方法，从基础模型中提取因果机制，指导鲁棒设计与控制，支持高风险应用中的信任与问责。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能在多个科学和工程任务中已超越人类表现，但其内部表示通常不透明。这种"黑箱"特性限制了AI在需要透明度和可解释性的关键应用中的使用，特别是在发现、优化和认证等科学工程领域。

Method: 结合可解释人工智能（XAI）与因果推理，通过"向学习者学习"的方法，利用基础模型和可解释性技术提取因果机制。该方法专注于三个核心领域：发现（提取因果机制）、优化（指导鲁棒设计与控制）、认证（支持信任与问责）。

Result: XAI与因果推理的结合能够从AI模型中提取有价值的因果知识，指导工程设计和控制策略，并在高风险应用中建立信任机制。这为人类-AI协作提供了统一框架。

Conclusion: XAI可作为科学和工程中人类-AI协作的统一框架，但面临解释的忠实性、泛化性和可用性等挑战。通过解决这些挑战，XAI能够促进AI在关键领域的负责任应用。

Abstract: Artificial intelligence now outperforms humans in several scientific and engineering tasks, yet its internal representations often remain opaque. In this Perspective, we argue that explainable artificial intelligence (XAI), combined with causal reasoning, enables {\it learning from the learners}. Focusing on discovery, optimization and certification, we show how the combination of foundation models and explainability methods allows the extraction of causal mechanisms, guides robust design and control, and supports trust and accountability in high-stakes applications. We discuss challenges in faithfulness, generalization and usability of explanations, and propose XAI as a unifying framework for human-AI collaboration in science and engineering.

</details>


### [59] [Safety Not Found (404): Hidden Risks of LLM-Based Robotics Decision Making](https://arxiv.org/abs/2601.05529)
*Jua Han,Jaeyoon Seo,Jungbin Min,Jean Oh,Jihie Kim*

Main category: cs.AI

TL;DR: 论文系统评估了LLM在安全关键场景中的决策能力，通过火灾疏散等场景发现当前模型存在严重安全隐患，即使99%的准确率在机器人应用中仍可能导致灾难性后果。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在机器人决策中的集成，物理风险维度增加，单个错误指令可能直接危及人类安全。迫切需要系统评估LLM在错误可能造成灾难性后果的场景中的性能。

Method: 通过火灾疏散场景的定性评估识别关键失败案例，设计了七项定量评估任务，分为：完整信息任务（使用ASCII地图减少解释歧义）、不完整信息任务（测试空间连续性与幻觉）、安全导向空间推理任务（评估生命威胁环境中的安全决策）。对多种LLM和VLM进行基准测试。

Result: 结果揭示严重漏洞：多个模型在ASCII导航中成功率为0%；在模拟消防演习中，模型指示机器人向危险区域而非紧急出口移动。即使最先进模型也无法保证安全，99%准确率在机器人应用中意味着每百次执行可能造成灾难性伤害。

Conclusion: 当前LLM尚未准备好直接部署到安全关键系统中。对LLM的绝对依赖会产生不可接受的风险，需要更严格的安全保障措施。

Abstract: One mistake by an AI system in a safety-critical setting can cost lives. As Large Language Models (LLMs) become integral to robotics decision-making, the physical dimension of risk grows; a single wrong instruction can directly endanger human safety. This paper addresses the urgent need to systematically evaluate LLM performance in scenarios where even minor errors are catastrophic. Through a qualitative evaluation of a fire evacuation scenario, we identified critical failure cases in LLM-based decision-making. Based on these, we designed seven tasks for quantitative assessment, categorized into: Complete Information, Incomplete Information, and Safety-Oriented Spatial Reasoning (SOSR). Complete information tasks utilize ASCII maps to minimize interpretation ambiguity and isolate spatial reasoning from visual processing. Incomplete information tasks require models to infer missing context, testing for spatial continuity versus hallucinations. SOSR tasks use natural language to evaluate safe decision-making in life-threatening contexts. We benchmark various LLMs and Vision-Language Models (VLMs) across these tasks. Beyond aggregate performance, we analyze the implications of a 1% failure rate, highlighting how "rare" errors escalate into catastrophic outcomes. Results reveal serious vulnerabilities: several models achieved a 0% success rate in ASCII navigation, while in a simulated fire drill, models instructed robots to move toward hazardous areas instead of emergency exits. Our findings lead to a sobering conclusion: current LLMs are not ready for direct deployment in safety-critical systems. A 99% accuracy rate is dangerously misleading in robotics, as it implies one out of every hundred executions could result in catastrophic harm. We demonstrate that even state-of-the-art models cannot guarantee safety, and absolute reliance on them creates unacceptable risks.

</details>


### [60] [WildSci: Advancing Scientific Reasoning from In-the-Wild Literature](https://arxiv.org/abs/2601.05567)
*Tengxiao Liu,Deepak Nathani,Zekun Li,Kevin Yang,William Yang Wang*

Main category: cs.AI

TL;DR: WildSci是一个从同行评审文献自动合成的领域特定科学问题数据集，覆盖9个科学学科和26个子领域，通过将复杂科学推理任务转化为多项选择题格式，支持基于强化学习的大语言模型微调，以提升科学推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型推理研究主要集中在数学和编程等数据丰富、评估指标客观的领域，而在医学和材料科学等科学领域进展有限，主要受限于数据集覆盖不足和开放科学问题的复杂性。

Method: 1. 构建WildSci数据集：从同行评审文献自动合成领域特定科学问题，覆盖9个科学学科和26个子领域；2. 将复杂科学推理任务转化为多项选择题格式，提供明确的奖励信号；3. 应用强化学习对模型进行微调，分析训练动态。

Result: 在一系列科学基准测试上的实验证明了数据集和方法的有效性。WildSci数据集已公开发布，支持科学推理的可扩展和可持续研究。

Conclusion: WildSci通过提供高质量的领域特定科学问题数据集和基于强化学习的微调方法，有效解决了科学推理领域的数据稀缺和评估困难问题，为科学领域的大语言模型推理研究提供了可扩展的解决方案。

Abstract: Recent progress in large language model (LLM) reasoning has focused on domains like mathematics and coding, where abundant high-quality data and objective evaluation metrics are readily available. In contrast, progress in LLM reasoning models remains limited in scientific domains such as medicine and materials science due to limited dataset coverage and the inherent complexity of open-ended scientific questions. To address these challenges, we introduce WildSci, a new dataset of domain-specific science questions automatically synthesized from peer-reviewed literature, covering 9 scientific disciplines and 26 subdomains. By framing complex scientific reasoning tasks in a multiple-choice format, we enable scalable training with well-defined reward signals. We further apply reinforcement learning to finetune models on these data and analyze the resulting training dynamics, including domain-specific performance changes, response behaviors, and generalization trends. Experiments on a suite of scientific benchmarks demonstrate the effectiveness of our dataset and approach. We release WildSci to enable scalable and sustainable research in scientific reasoning, available at https://huggingface.co/datasets/JustinTX/WildSci.

</details>


### [61] [Crisis-Bench: Benchmarking Strategic Ambiguity and Reputation Management in Large Language Models](https://arxiv.org/abs/2601.05570)
*Cooper Lin,Maohao Ran,Yanting Zhang,Zhenglin Wan,Hongwei Fan,Yibo Xu,Yike Guo,Wei Xue,Jun Song*

Main category: cs.AI

TL;DR: 论文提出Crisis-Bench基准，用于评估LLM在需要战略模糊性和信息保留的专业领域（如危机公关）中的表现，揭示通用安全对齐与专业实用性之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 标准安全对齐将LLM优化为普遍有帮助和诚实，形成僵化的"童子军"道德观。这种一刀切的伦理框架对需要战略模糊性和信息保留的专业领域（如公共关系、谈判、危机管理）施加了"透明度税"，限制了LLM在这些领域的实用性。

Method: 引入Crisis-Bench：一个多智能体部分可观察马尔可夫决策过程（POMDP），用于评估LLM在高风险企业危机中的表现。包含80个跨8个行业的多样化故事情节，任务是在7天动态企业危机模拟中导航，同时管理严格分离的私有和公共叙事状态以强制执行信息不对称。采用新颖的"裁判-市场循环"评估指标：公众情绪被裁判并转换为模拟股价，创建现实的经济激励结构。

Result: 结果揭示了关键二分法：一些模型屈服于伦理关切，而其他模型则展示了马基雅维利式的合法战略保留能力以稳定模拟股价。Crisis-Bench提供了首个量化评估"声誉管理"能力的框架。

Conclusion: 论文主张从僵化的道德绝对主义转向情境感知的专业对齐，为需要战略模糊性的专业领域开发更灵活的LLM对齐方法。

Abstract: Standard safety alignment optimizes Large Language Models (LLMs) for universal helpfulness and honesty, effectively instilling a rigid "Boy Scout" morality. While robust for general-purpose assistants, this one-size-fits-all ethical framework imposes a "transparency tax" on professional domains requiring strategic ambiguity and information withholding, such as public relations, negotiation, and crisis management. To measure this gap between general safety and professional utility, we introduce Crisis-Bench, a multi-agent Partially Observable Markov Decision Process (POMDP) that evaluates LLMs in high-stakes corporate crises. Spanning 80 diverse storylines across 8 industries, Crisis-Bench tasks an LLM-based Public Relations (PR) Agent with navigating a dynamic 7-day corporate crisis simulation while managing strictly separated Private and Public narrative states to enforce rigorous information asymmetry. Unlike traditional benchmarks that rely on static ground truths, we introduce the Adjudicator-Market Loop: a novel evaluation metric where public sentiment is adjudicated and translated into a simulated stock price, creating a realistic economic incentive structure. Our results expose a critical dichotomy: while some models capitulate to ethical concerns, others demonstrate the capacity for Machiavellian, legitimate strategic withholding in order to stabilize the simulated stock price. Crisis-Bench provides the first quantitative framework for assessing "Reputation Management" capabilities, arguing for a shift from rigid moral absolutism to context-aware professional alignment.

</details>


### [62] [Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection](https://arxiv.org/abs/2601.05578)
*Cooper Lin,Yanting Zhang,Maohao Ran,Wei Xue,Hongwei Fan,Yibo Xu,Zhenglin Wan,Sirui Han,Yike Guo,Jun Song*

Main category: cs.AI

TL;DR: 使用强化学习对轻量级语言模型进行后训练，专门用于电子商务欺诈检测，仅使用原始交易数据，通过GSPO算法和基于规则的奖励系统显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 电子商务平台面临日益复杂的欺诈方案，但大型语言模型在金融欺诈检测中的实际应用尚未充分探索。传统机器学习方法存在局限性，而LLMs在领域特定电子商务交易数据中的有效性缺乏实证验证。

Method: 提出一种新颖方法，使用强化学习对轻量级语言模型进行后训练，专门用于欺诈检测任务。采用Group Sequence Policy Optimization (GSPO)算法结合基于规则的奖励系统，在真实交易数据集上微调不同规模的语言模型。模型探索文本交易数据中的信任和风险信号，包括客户信息、配送详情、产品描述和订单历史等模式。

Result: 实验结果表明该方法有效，后训练的语言模型在保留测试数据上实现了显著的F1分数提升。性能改进主要归因于强化学习固有的探索机制，使模型能够发现超越传统工程特征的新型欺诈指标。

Conclusion: 强化学习后训练的语言模型能够有效探索电子商务交易数据中的复杂模式，发现传统方法难以捕捉的新型欺诈指标，为金融欺诈检测提供了有前景的新途径。

Abstract: E-commerce platforms and payment solution providers face increasingly sophisticated fraud schemes, ranging from identity theft and account takeovers to complex money laundering operations that exploit the speed and anonymity of digital transactions. However, despite their theoretical promise, the application of Large Language Models (LLMs) to fraud detection in real-world financial contexts remains largely unexploited, and their practical effectiveness in handling domain-specific e-commerce transaction data has yet to be empirically validated. To bridge this gap between conventional machine learning limitations and the untapped potential of LLMs in fraud detection, this paper proposes a novel approach that employs Reinforcement Learning (RL) to post-train lightweight language models specifically for fraud detection tasks using only raw transaction data. We utilize the Group Sequence Policy Optimization (GSPO) algorithm combined with a rule-based reward system to fine-tune language models of various sizes on a real-life transaction dataset provided by a Chinese global payment solution company. Through this reinforcement learning framework, the language models are encouraged to explore diverse trust and risk signals embedded within the textual transaction data, including patterns in customer information, shipping details, product descriptions, and order history. Our experimental results demonstrate the effectiveness of this approach, with post-trained language models achieving substantial F1-score improvements on held-out test data. Our findings demonstrate that the observed performance improvements are primarily attributable to the exploration mechanism inherent in reinforcement learning, which allows models to discover novel fraud indicators beyond those captured by traditional engineered features.

</details>


### [63] [Cumulative Path-Level Semantic Reasoning for Inductive Knowledge Graph Completion](https://arxiv.org/abs/2601.05629)
*Jiapu Wang,Xinghe Cheng,Zezheng Wu,Ruiqi Ma,Rui Wang,Zhichao Yan,Haoran Luo,Yuhao Jiang,Kai Sun*

Main category: cs.AI

TL;DR: CPSR框架通过查询相关掩码模块和全局语义评分模块，有效处理归纳知识图谱补全中的噪声结构和长距离依赖问题


<details>
  <summary>Details</summary>
Motivation: 传统KGC方法在处理新兴实体时效果不佳，现有归纳KGC方法虽然能处理新兴实体和关系，但面临噪声结构信息干扰和难以捕捉推理路径中长距离依赖的挑战

Method: 提出CPSR框架，包含查询相关掩码模块（自适应掩码噪声结构信息）和全局语义评分模块（评估推理路径中节点的个体贡献和集体影响）

Result: 实验结果表明CPSR实现了最先进的性能

Conclusion: CPSR通过同时捕获知识图谱的结构和语义信息，有效提升了归纳知识图谱补全任务的性能

Abstract: Conventional Knowledge Graph Completion (KGC) methods aim to infer missing information in incomplete Knowledge Graphs (KGs) by leveraging existing information, which struggle to perform effectively in scenarios involving emerging entities. Inductive KGC methods can handle the emerging entities and relations in KGs, offering greater dynamic adaptability. While existing inductive KGC methods have achieved some success, they also face challenges, such as susceptibility to noisy structural information during reasoning and difficulty in capturing long-range dependencies in reasoning paths. To address these challenges, this paper proposes the Cumulative Path-Level Semantic Reasoning for inductive knowledge graph completion (CPSR) framework, which simultaneously captures both the structural and semantic information of KGs to enhance the inductive KGC task. Specifically, the proposed CPSR employs a query-dependent masking module to adaptively mask noisy structural information while retaining important information closely related to the targets. Additionally, CPSR introduces a global semantic scoring module that evaluates both the individual contributions and the collective impact of nodes along the reasoning path within KGs. The experimental results demonstrate that CPSR achieves state-of-the-art performance.

</details>


### [64] [GenCtrl -- A Formal Controllability Toolkit for Generative Models](https://arxiv.org/abs/2601.05637)
*Emily Cheng,Carmen Amo Alonso,Federico Danieli,Arno Blaas,Luca Zappella,Pau Rodriguez,Xavier Suau*

Main category: cs.AI

TL;DR: 提出理论框架分析生成模型的可控性，通过对话场景估计可控集，提供分布无关的PAC边界，实验显示模型可控性脆弱且依赖实验设置


<details>
  <summary>Details</summary>
Motivation: 生成模型日益普及，需要细粒度控制生成过程，但现有控制方法（从提示到微调）未回答根本问题：这些模型是否真正可控？需要理论框架来形式化回答这一问题

Method: 将人机交互建模为控制过程，提出新算法估计对话场景中模型的可控集，提供形式化保证：基于样本复杂度的估计误差边界，分布无关、仅需输出有界假设、适用于任何黑盒非线性控制系统（任何生成模型）

Result: 在语言模型和文本到图像生成的不同对话控制任务上实证验证理论框架，结果显示模型可控性出奇脆弱且高度依赖实验设置

Conclusion: 需要严格的可控性分析，将重点从单纯尝试控制转向首先理解其基本限制，模型可控性具有根本性限制

Abstract: As generative models become ubiquitous, there is a critical need for fine-grained control over the generation process. Yet, while controlled generation methods from prompting to fine-tuning proliferate, a fundamental question remains unanswered: are these models truly controllable in the first place? In this work, we provide a theoretical framework to formally answer this question. Framing human-model interaction as a control process, we propose a novel algorithm to estimate the controllable sets of models in a dialogue setting. Notably, we provide formal guarantees on the estimation error as a function of sample complexity: we derive probably-approximately correct bounds for controllable set estimates that are distribution-free, employ no assumptions except for output boundedness, and work for any black-box nonlinear control system (i.e., any generative model). We empirically demonstrate the theoretical framework on different tasks in controlling dialogue processes, for both language models and text-to-image generation. Our results show that model controllability is surprisingly fragile and highly dependent on the experimental setting. This highlights the need for rigorous controllability analysis, shifting the focus from simply attempting control to first understanding its fundamental limits.

</details>


### [65] [HAG: Hierarchical Demographic Tree-based Agent Generation for Topic-Adaptive Simulation](https://arxiv.org/abs/2601.05656)
*Rongxin Chen,Tianyu Wu,Bingbing Xu,Xiucheng Xu,Huawei Shen*

Main category: cs.AI

TL;DR: HAG：一种分层智能体生成框架，通过两阶段决策过程实现主题自适应的人口生成，在宏观分布对齐和微观一致性方面显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有智能体初始化方法存在局限性：基于静态数据的检索方法无法适应未见主题，而基于LLM的生成方法缺乏宏观分布意识，导致微观个体属性与现实不一致。需要一种既能捕捉宏观联合分布又能确保微观个体理性的鲁棒框架。

Method: 提出HAG分层智能体生成框架，将人口生成形式化为两阶段决策过程：1) 使用世界知识模型推断分层条件概率构建主题自适应树，实现宏观分布对齐；2) 基于真实世界数据进行实例化和智能体增强，确保微观一致性。

Result: 实验表明HAG显著优于代表性基线方法，平均减少人口对齐误差37.7%，提升社会学一致性18.8%。建立了多领域基准和全面的PACE评估框架。

Conclusion: HAG通过分层生成方法有效解决了智能体初始化中的宏观分布对齐和微观一致性问题，为基于智能体的建模提供了高质量的人口初始化框架。

Abstract: High-fidelity agent initialization is crucial for credible Agent-Based Modeling across diverse domains. A robust framework should be Topic-Adaptive, capturing macro-level joint distributions while ensuring micro-level individual rationality. Existing approaches fall into two categories: static data-based retrieval methods that fail to adapt to unseen topics absent from the data, and LLM-based generation methods that lack macro-level distribution awareness, resulting in inconsistencies between micro-level persona attributes and reality. To address these problems, we propose HAG, a Hierarchical Agent Generation framework that formalizes population generation as a two-stage decision process. Firstly, utilizing a World Knowledge Model to infer hierarchical conditional probabilities to construct the Topic-Adaptive Tree, achieving macro-level distribution alignment. Then, grounded real-world data, instantiation and agentic augmentation are carried out to ensure micro-level consistency. Given the lack of specialized evaluation, we establish a multi-domain benchmark and a comprehensive PACE evaluation framework. Extensive experiments show that HAG significantly outperforms representative baselines, reducing population alignment errors by an average of 37.7% and enhancing sociological consistency by 18.8%.

</details>


### [66] [Circular Reasoning: Understanding Self-Reinforcing Loops in Large Reasoning Models](https://arxiv.org/abs/2601.05693)
*Zenghao Duan,Liang Pang,Zihao Wei,Wenbin Duan,Yuxin Tian,Shicheng Xu,Jingcheng Deng,Zhiyi Yin,Xueqi Cheng*

Main category: cs.AI

TL;DR: 论文提出"循环推理"这一新失效模式，通过LoopBench数据集分析数值循环和陈述循环，揭示其自强化V型注意力机制，并利用CUSUM算法实现早期预测。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在测试时缩放时常陷入重复循环，导致计算浪费和推理失败。传统模型退化理论无法解释这种自我强化的逻辑陷阱，需要系统分析这种新型失效模式。

Method: 1. 提出"循环推理"概念；2. 构建LoopBench数据集捕获数值循环和陈述循环两种类型；3. 将循环推理表征为具有明确边界的状态崩溃；4. 揭示自强化V型注意力机制驱动循环；5. 使用累积和算法捕捉循环前兆进行早期预测。

Result: 实验验证了CUSUM算法在多种大型推理模型中的预测准确性，阐明了长链推理的稳定性特征，成功识别了语义重复先于文本重复的循环前兆模式。

Conclusion: 循环推理是大型推理模型特有的自强化失效模式，通过早期检测机制可以有效避免计算浪费和推理失败，为提升模型推理稳定性提供了新视角和方法。

Abstract: Despite the success of test-time scaling, Large Reasoning Models (LRMs) frequently encounter repetitive loops that lead to computational waste and inference failure. In this paper, we identify a distinct failure mode termed Circular Reasoning. Unlike traditional model degeneration, this phenomenon manifests as a self-reinforcing trap where generated content acts as a logical premise for its own recurrence, compelling the reiteration of preceding text. To systematically analyze this phenomenon, we introduce LoopBench, a dataset designed to capture two distinct loop typologies: numerical loops and statement loops. Mechanistically, we characterize circular reasoning as a state collapse exhibiting distinct boundaries, where semantic repetition precedes textual repetition. We reveal that reasoning impasses trigger the loop onset, which subsequently persists as an inescapable cycle driven by a self-reinforcing V-shaped attention mechanism. Guided by these findings, we employ the Cumulative Sum (CUSUM) algorithm to capture these precursors for early loop prediction. Experiments across diverse LRMs validate its accuracy and elucidate the stability of long-chain reasoning.

</details>


### [67] [Logic-Parametric Neuro-Symbolic NLI: Controlling Logical Formalisms for Verifiable LLM Reasoning](https://arxiv.org/abs/2601.05705)
*Ali Farjami,Luca Redondi,Marco Valentino*

Main category: cs.AI

TL;DR: 提出一个逻辑参数化框架，将逻辑作为可控组件嵌入神经符号推理系统，支持多种经典和非经典逻辑，在规范性推理中验证逻辑内部策略优于逻辑外部策略。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定逻辑形式主义，限制了神经符号自然语言推理的鲁棒性和适应性。需要将逻辑作为可控组件而非静态背景来处理。

Method: 使用LogiKEy方法将多种经典和非经典逻辑嵌入高阶逻辑，构建逻辑参数化框架。比较逻辑外部方法（通过公理编码规范要求）和逻辑内部方法（规范模式从逻辑内置结构中产生）。

Result: 逻辑内部策略能持续提升性能并产生更高效的混合证明。逻辑有效性具有领域依赖性：一阶逻辑适合常识推理，道义逻辑和模态逻辑在伦理领域表现更优。

Conclusion: 将逻辑作为一等参数化元素纳入神经符号架构，能实现更鲁棒、模块化和适应性强的推理系统。

Abstract: Large language models (LLMs) and theorem provers (TPs) can be effectively combined for verifiable natural language inference (NLI). However, existing approaches rely on a fixed logical formalism, a feature that limits robustness and adaptability. We propose a logic-parametric framework for neuro-symbolic NLI that treats the underlying logic not as a static background, but as a controllable component. Using the LogiKEy methodology, we embed a range of classical and non-classical formalisms into higher-order logic (HOL), enabling a systematic comparison of inference quality, explanation refinement, and proof behavior. We focus on normative reasoning, where the choice of logic has significant implications. In particular, we compare logic-external approaches, where normative requirements are encoded via axioms, with logic-internal approaches, where normative patterns emerge from the logic's built-in structure. Extensive experiments demonstrate that logic-internal strategies can consistently improve performance and produce more efficient hybrid proofs for NLI. In addition, we show that the effectiveness of a logic is domain-dependent, with first-order logic favouring commonsense reasoning, while deontic and modal logics excel in ethical domains. Our results highlight the value of making logic a first-class, parametric element in neuro-symbolic architectures for more robust, modular, and adaptable reasoning.

</details>


### [68] [PII-VisBench: Evaluating Personally Identifiable Information Safety in Vision Language Models Along a Continuum of Visibility](https://arxiv.org/abs/2601.05739)
*G M Shahariar,Zabir Al Nazi,Md Olid Hasan Bhuiyan,Zhouxing Shi*

Main category: cs.AI

TL;DR: PII-VisBench：首个基于在线存在连续体的VLM隐私泄露评估基准，发现模型对高可见度主体的PII泄露率更高


<details>
  <summary>Details</summary>
Motivation: 现有VLM隐私评估将隐私视为静态提取任务，忽略了主体在线存在（数据可用量）对隐私对齐的影响，需要更全面的评估框架

Method: 构建PII-VisBench基准，包含4000个独特探针，将200个主体按在线信息程度分为高、中、低、零四个可见度类别，评估18个开源VLM（0.3B-32B）的拒绝率和条件PII泄露率

Result: 模型呈现一致模式：主体可见度降低时拒绝率增加，PII泄露减少（从高可见度的9.10%降至低可见度的5.34%）；模型更可能泄露高可见度主体的PII，存在显著的模型家族异质性和PII类型差异；改写和越狱提示暴露了攻击和模型依赖的失败

Conclusion: 需要基于可见度的安全评估和训练干预，PII泄露风险与主体在线存在程度相关，现有VLM安全评估存在盲点

Abstract: Vision Language Models (VLMs) are increasingly integrated into privacy-critical domains, yet existing evaluations of personally identifiable information (PII) leakage largely treat privacy as a static extraction task and ignore how a subject's online presence--the volume of their data available online--influences privacy alignment. We introduce PII-VisBench, a novel benchmark containing 4000 unique probes designed to evaluate VLM safety through the continuum of online presence. The benchmark stratifies 200 subjects into four visibility categories: high, medium, low, and zero--based on the extent and nature of their information available online. We evaluate 18 open-source VLMs (0.3B-32B) based on two key metrics: percentage of PII probing queries refused (Refusal Rate) and the fraction of non-refusal responses flagged for containing PII (Conditional PII Disclosure Rate). Across models, we observe a consistent pattern: refusals increase and PII disclosures decrease (9.10% high to 5.34% low) as subject visibility drops. We identify that models are more likely to disclose PII for high-visibility subjects, alongside substantial model-family heterogeneity and PII-type disparities. Finally, paraphrasing and jailbreak-style prompts expose attack and model-dependent failures, motivating visibility-aware safety evaluation and training interventions.

</details>


### [69] [DynaDebate: Breaking Homogeneity in Multi-Agent Debate with Dynamic Path Generation](https://arxiv.org/abs/2601.05746)
*Zhenghao Li,Zhi Zheng,Wei Chen,Jielun Zhao,Yong Chen,Tong Xu,Enhong Chen*

Main category: cs.AI

TL;DR: DynaDebate：一种通过动态路径生成、过程中心辩论和触发式验证来增强多智能体辩论效果的新框架，解决了现有方法中智能体采用相同推理路径导致简单多数投票的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的多智能体辩论框架存在以下问题：1）依赖无引导的初始化，导致智能体采用相同的推理路径和错误；2）辩论效果受限，最终结果往往退化为简单的多数投票。需要一种机制来增强多智能体辩论的有效性。

Method: 提出了DynaDebate框架，包含三个关键机制：1）动态路径生成与分配：使用专门的路径生成智能体生成多样化、逻辑化的解决方案路径，并自适应冗余；2）过程中心辩论：将焦点从表面结果投票转移到严格的逐步逻辑批判，确保过程正确性；3）触发式验证智能体：在出现分歧时激活，使用外部工具客观解决僵局。

Result: 大量实验表明，DynaDebate在各种基准测试中实现了优越性能，超越了现有的最先进多智能体辩论方法。

Conclusion: DynaDebate通过引入动态路径生成、过程中心辩论和触发式验证机制，有效解决了多智能体辩论中的同质化推理和简单多数投票问题，显著提升了多智能体系统的协作决策和复杂问题解决能力。

Abstract: Recent years have witnessed the rapid development of Large Language Model-based Multi-Agent Systems (MAS), which excel at collaborative decision-making and complex problem-solving. Recently, researchers have further investigated Multi-Agent Debate (MAD) frameworks, which enhance the reasoning and collaboration capabilities of MAS through information exchange and debate among multiple agents. However, existing approaches often rely on unguided initialization, causing agents to adopt identical reasoning paths that lead to the same errors. As a result, effective debate among agents is hindered, and the final outcome frequently degenerates into simple majority voting. To solve the above problem, in this paper, we introduce Dynamic Multi-Agent Debate (DynaDebate), which enhances the effectiveness of multi-agent debate through three key mechanisms: (1) Dynamic Path Generation and Allocation, which employs a dedicated Path Generation Agent to generate diverse and logical solution paths with adaptive redundancy; (2) Process-Centric Debate, which shifts the focus from surface-level outcome voting to rigorous step-by-step logic critique to ensure process correctness; (3) A Trigger-Based Verification Agent, which is activated upon disagreement and uses external tools to objectively resolve deadlocks. Extensive experiments demonstrate that DynaDebate achieves superior performance across various benchmarks, surpassing existing state-of-the-art MAD methods.

</details>


### [70] [StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management](https://arxiv.org/abs/2601.05890)
*Ruizhe Zhang,Xinke Jiang,Zhibang Yang,Zhixin Zhang,Jiaran Gao,Yuzhen Xiao,Hongbin Lai,Xu Chu,Junfeng Zhao,Yasha Wang*

Main category: cs.AI

TL;DR: StackPlanner：一种具有显式内存控制的分层多智能体框架，通过解耦高层协调与子任务执行，并利用结构化经验记忆和强化学习重用协调经验，解决长期协作中的内存管理问题。


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的集中式多智能体系统在处理复杂知识密集型任务时表现出潜力，但中心智能体由于缺乏内存管理，导致上下文膨胀、错误累积和跨任务泛化能力差，影响长期协作的稳定性。

Method: 提出StackPlanner分层多智能体框架：1）通过主动任务级内存控制解耦高层协调与子任务执行；2）使用结构化经验记忆存储协调经验；3）通过强化学习检索和利用可重用协调经验。

Result: 在多个深度搜索和智能体系统基准测试上的实验表明，该方法能够实现可靠的长期多智能体协作，有效解决了内存效率低下和协调经验重用问题。

Conclusion: StackPlanner通过显式内存控制机制，显著提升了多智能体系统在长期复杂任务中的协作稳定性和效率，为知识密集型任务的可靠多智能体协作提供了有效解决方案。

Abstract: Multi-agent systems based on large language models, particularly centralized architectures, have recently shown strong potential for complex and knowledge-intensive tasks. However, central agents often suffer from unstable long-horizon collaboration due to the lack of memory management, leading to context bloat, error accumulation, and poor cross-task generalization. To address both task-level memory inefficiency and the inability to reuse coordination experience, we propose StackPlanner, a hierarchical multi-agent framework with explicit memory control. StackPlanner addresses these challenges by decoupling high-level coordination from subtask execution with active task-level memory control, and by learning to retrieve and exploit reusable coordination experience via structured experience memory and reinforcement learning. Experiments on multiple deep-search and agent system benchmarks demonstrate the effectiveness of our approach in enabling reliable long-horizon multi-agent collaboration.

</details>


### [71] [TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents](https://arxiv.org/abs/2601.05899)
*Dawei Wang,Chengming Zhou,Di Zhao,Xinyuan Liu,Marci Chi Ma,Gary Ushaw,Richard Davison*

Main category: cs.AI

TL;DR: TowerMind：基于塔防游戏的轻量级多模态环境，用于评估LLM的长期规划和决策能力，揭示LLM与人类专家在能力和幻觉方面的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有RTS游戏环境要么计算需求高，要么缺乏文本观察支持，限制了LLM评估。需要一种轻量级、多模态的环境来评估LLM在长期规划和决策方面的核心能力。

Method: 提出TowerMind环境，基于RTS游戏的塔防子类型，保留RTS游戏评估优势，同时具有低计算需求和包含像素、文本、结构化游戏状态的多模态观察空间。支持模型幻觉评估和高可定制性。

Result: 设计了五个基准关卡评估多种LLM在不同多模态输入设置下的表现。结果显示LLM与人类专家在能力和幻觉维度存在明显性能差距。实验揭示了LLM行为的关键局限性：规划验证不足、决策缺乏多终局性、行动使用效率低。还评估了两种经典强化学习算法：Ape-X DQN和PPO。

Conclusion: TowerMind通过轻量级多模态设计补充了现有RTS游戏环境，为AI智能体领域引入了新的基准测试平台。源代码已在GitHub公开。

Abstract: Recent breakthroughs in Large Language Models (LLMs) have positioned them as a promising paradigm for agents, with long-term planning and decision-making emerging as core general-purpose capabilities for adapting to diverse scenarios and tasks. Real-time strategy (RTS) games serve as an ideal testbed for evaluating these two capabilities, as their inherent gameplay requires both macro-level strategic planning and micro-level tactical adaptation and action execution. Existing RTS game-based environments either suffer from relatively high computational demands or lack support for textual observations, which has constrained the use of RTS games for LLM evaluation. Motivated by this, we present TowerMind, a novel environment grounded in the tower defense (TD) subgenre of RTS games. TowerMind preserves the key evaluation strengths of RTS games for assessing LLMs, while featuring low computational demands and a multimodal observation space, including pixel-based, textual, and structured game-state representations. In addition, TowerMind supports the evaluation of model hallucination and provides a high degree of customizability. We design five benchmark levels to evaluate several widely used LLMs under different multimodal input settings. The results reveal a clear performance gap between LLMs and human experts across both capability and hallucination dimensions. The experiments further highlight key limitations in LLM behavior, such as inadequate planning validation, a lack of multifinality in decision-making, and inefficient action use. We also evaluate two classic reinforcement learning algorithms: Ape-X DQN and PPO. By offering a lightweight and multimodal design, TowerMind complements the existing RTS game-based environment landscape and introduces a new benchmark for the AI agent field. The source code is publicly available on GitHub(https://github.com/tb6147877/TowerMind).

</details>


### [72] [Open-Vocabulary 3D Instruction Ambiguity Detection](https://arxiv.org/abs/2601.05991)
*Jiayu Ding,Haoran Tang,Ge Li*

Main category: cs.AI

TL;DR: 提出首个开放词汇3D指令歧义检测任务，构建大规模基准数据集Ambi3D，开发两阶段框架AmbiVer解决现有3D大语言模型在歧义检测上的局限性。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域（如手术场景），语言歧义可能导致严重后果，但现有具身AI研究大多忽略此问题，假设指令清晰并专注于执行而非确认。为填补这一安全空白，需要研究3D环境中的指令歧义检测。

Method: 提出AmbiVer两阶段框架：第一阶段从多个视角收集显式视觉证据，第二阶段使用这些证据指导视觉语言模型判断指令歧义性。同时构建Ambi3D基准数据集，包含700多个多样3D场景和约22k条指令。

Result: 分析发现最先进的3D大语言模型难以可靠判断指令是否歧义。AmbiVer框架在Ambi3D数据集上表现出有效性，证明了该任务的挑战性和所提方法的优越性。

Conclusion: 首次定义了开放词汇3D指令歧义检测任务，构建了相关基准数据集，提出的AmbiVer框架为解决该问题提供了有效方案，为开发更安全、更可信的具身AI铺平了道路。

Abstract: In safety-critical domains, linguistic ambiguity can have severe consequences; a vague command like "Pass me the vial" in a surgical setting could lead to catastrophic errors. Yet, most embodied AI research overlooks this, assuming instructions are clear and focusing on execution rather than confirmation. To address this critical safety gap, we are the first to define Open-Vocabulary 3D Instruction Ambiguity Detection, a fundamental new task where a model must determine if a command has a single, unambiguous meaning within a given 3D scene. To support this research, we build Ambi3D, the large-scale benchmark for this task, featuring over 700 diverse 3D scenes and around 22k instructions. Our analysis reveals a surprising limitation: state-of-the-art 3D Large Language Models (LLMs) struggle to reliably determine if an instruction is ambiguous. To address this challenge, we propose AmbiVer, a two-stage framework that collects explicit visual evidence from multiple views and uses it to guide an vision-language model (VLM) in judging instruction ambiguity. Extensive experiments demonstrate the challenge of our task and the effectiveness of AmbiVer, paving the way for safer and more trustworthy embodied AI. Code and dataset available at https://jiayuding031020.github.io/ambi3d/.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [73] [A Favre-Averaged Shallow Water Framework for Aerated Flows with Friction Factor Decomposition](https://arxiv.org/abs/2601.05523)
*Matthias Kramer*

Main category: physics.flu-dyn

TL;DR: 本文提出了一种密度加权（Favre）平均方法，用于准确预测高弗劳德数掺气水流中的流动阻力，建立了密度一致的浅水方程框架和新的Darcy-Weisbach摩擦系数公式。


<details>
  <summary>Details</summary>
Motivation: 高弗劳德数掺气水流中的流动阻力预测具有挑战性，因为空气掺入导致混合物密度在空间上存在强烈变化，传统方法难以准确考虑这种密度变化对摩擦阻力的影响。

Method: 采用密度加权（Favre）平均方法，严格考虑空气浓度和速度的垂直分布，建立密度一致的浅水方程框架，并提出新的Darcy-Weisbach摩擦系数公式，该公式分解了均匀流、空间变化流和时间演化流的贡献，并包含了反映混合物垂直结构的动量和压力修正因子。

Result: 应用文献中的实验数据验证表明，Favre平均浅水方程框架提供了物理一致的有效摩擦量化方法，能够准确预测掺气水流中的流动阻力。

Conclusion: 该工作建立了用于高弗劳德数掺气水流阻力建模的机理化密度加权方法，为掺气在摩擦耗散中的作用提供了新的物理见解，并为未来非定常和快速变化掺气水流的建模奠定了理论基础。

Abstract: Accurate prediction of flow resistance in high-Froude-number aerated flows remains challenging due to air entrainment, which causes strong spatial variability in mixture density. In this work, we introduce a density-weighted (Favre) averaging approach to rigorously account for vertical distributions of air concentration and velocity. Favre averaging naturally captures variations in mixture density induced by air entrainment, thereby enabling a density-consistent Shallow Water Equation (SWE) formulation for aerated flows. Within this framework, we present a novel Darcy-Weisbach friction factor formulation that decomposes contributions associated with uniform flow, spatially varying flow, and temporally evolving flow, and incorporates momentum and pressure correction factors reflecting the vertical structure of the mixture. Application to experimental data from the literature demonstrates that the Favre-averaged SWE framework provides a physically consistent means of quantifying effective friction. Overall, this work establishes a mechanistic, density-weighted methodology for modelling resistance in high-Froude-number aerated flows, provides new physical insight into the role of aeration in frictional dissipation, and lays a rational foundation for future modelling of unsteady and rapidly varied aerated flows.

</details>


### [74] [Development and Experimental Validation of Novel Evaluation Criteria for Turbulent Two-Phase VOF Simulations in High-Pressure Die Casting](https://arxiv.org/abs/2601.05701)
*Mehran Shazedeh,Fabian Teichmann,Sebastian Müller*

Main category: physics.flu-dyn

TL;DR: 使用OpenFOAM中的VOF方法模拟高压压铸中可压缩湍流充型过程，评估充型速度对界面形态、型腔增压和气体卷入的影响，并通过实验验证模型对关键缺陷机制的捕捉能力。


<details>
  <summary>Details</summary>
Motivation: 高压压铸过程中模具充型时的气体卷入严重影响铸件孔隙率和整体质量，需要开发可靠的数值模拟方法来预测和优化这一过程。

Method: 采用OpenFOAM中的"compressibleInterFoam"求解器进行三维模拟，在环境初始型腔条件下，分别使用层流和k-ε湍流模型。通过变化入口速度研究自由表面动力学，并引入TIFSA、TMVF和TIVF三个评价标准来量化氧化风险、填充连续性和表面载荷。

Result: 湍流模型加速了型腔增压过程并限制了卷入气体的持久性；充型速度决定了平滑填充、湍流破碎和暴露时间之间的平衡；与实验铸造试验（包括CT孔隙率分析和摄影测量表面评估）的对比验证了模型能够捕捉关键缺陷机制。

Conclusion: 该研究证明了在OpenFOAM中应用VOF方法模拟高压压铸可压缩湍流充型过程的可行性，模型能够有效预测气体卷入机制，为工艺优化提供定量指导。

Abstract: Air entrapment during mold filling critically affects porosity and overall casting quality in High Pressure Die Casting. This study assesses the feasibility of applying the vof method within OpenFOAM to simulate compressible, turbulent mold filling in a thin-walled geometry. Three-dimensional simulations with the "compressibleInterFoam" solver were carried out under ambient initial cavity conditions, using both laminar flow and the k-e turbulence model. The free surface dynamics were examined across a range of inlet velocities to evaluate their influence on interface morphology, cavity pressurization, and gas entrapment. To quantify these effects, three evaluation criteria were introduced: the TIFSA as a measure of oxidation risk, the TMVF as an indicator of filling continuity and air entrapment, and the TIVF as a proxy for surface loading. Results show that turbulence modeling accelerates pressurization and limits the persistence of entrapped gas, with velocity governing the balance between smooth filling, turbulent breakup, and exposure duration. Comparison with experimental casting trials, including CT based porosity analysis and photogrammetric surface evaluation, validated that the model captures key defect mechanisms and provides quantitative guidance for process optimization.

</details>


### [75] [On the Reynolds analogy for high-speed rough-wall flows: implications for wall modelling](https://arxiv.org/abs/2601.05786)
*Michele Cogo,Davide Depieri,Matteo Bernardini,Francesco Picano*

Main category: physics.flu-dyn

TL;DR: 该研究验证了广义雷诺类比在可压缩湍流边界层中的有效性，发现粗糙度影响仅限于近壁粗糙度子层，上层仍保持光滑壁面相似性，并基于此提出了粗糙表面热传递预测模型。


<details>
  <summary>Details</summary>
Motivation: 研究广义雷诺类比在可压缩湍流边界层中粗糙表面上的有效性，特别是粗糙度对动量和能量耦合的影响，为粗糙表面热传递预测提供理论基础。

Method: 通过挖掘马赫数2和4的可压缩湍流边界层直接数值模拟数据，分析绝热和冷却表面条件下棱柱形粗糙度的影响，研究粗糙度子层内外的动量和能量耦合关系。

Result: 粗糙度对动量和能量耦合的直接影响仅限于粗糙度子层，在该层之上，焓和速度场恢复光滑壁面相似性，广义雷诺类比通过自然考虑粗糙度增强的壁面剪切应力和热通量而渐近有效。

Conclusion: 基于广义雷诺类比的有效性，提出了结合阻力预测物理方法的粗糙表面热传递预测壁面模型，通过可压缩性变换实现棱柱形粗糙度的热传递预测。

Abstract: We study the validity of the generalized Reynolds analogy (GRA) in compressible turbulent boundary layers over prism-shaped roughness by mining direct numerical simulation data of Mach 2 and Mach 4 compressible turbulent boundary layers with adiabatic and cooled surfaces. Although the direct influence of roughness strongly disrupts the near-wall coupling between momentum and energy, we show that this breakdown is confined to the roughness sublayer. Above this layer, the enthalpy and velocity fields recover a smooth-wall-like similarity, and the GRA becomes asymptotically valid by naturally accounting for roughness-enhanced wall shear stress and heat flux. Building on these results, we propose a GRA-based wall model for predicting heat transfer over rough surfaces, which is coupled with a drag-predictive physics-based method developed for prism-shaped roughness by means of compressibility transformations.

</details>


### [76] [Combined effects of evaporation, sedimentation and solute crystallization on the dynamics of aerosol size distributions on multiple length and time scales](https://arxiv.org/abs/2601.05876)
*Sina Zendehroud,Ole Kleinjung,Philip Loche,Lydéric Bocquet,Roland R. Netz,Erica Ipocoana,Dirk Peschka,Marita Thomas*

Main category: physics.flu-dyn

TL;DR: 该研究从三个尺度探讨气溶胶介导的空气传播病毒机制：宏观尺度分析液滴尺寸分布演化，微观尺度研究水分子界面反射系数，介观尺度建立热力学一致的扩散界面模型。


<details>
  <summary>Details</summary>
Motivation: 为了定量评估不同环境条件下的空气传播感染风险，需要深入理解气溶胶液滴蒸发的动力学机制。研究从多个尺度（宏观、微观、介观）系统分析液滴蒸发过程对病毒载量的影响。

Method: 1. 宏观尺度：使用尖锐界面模型分析非相互作用液滴集合的尺寸分布演化，考虑蒸发和沉降过程；2. 微观尺度：通过分子动力学模拟提取水分子在气-水界面的反射系数；3. 介观尺度：建立热力学一致的三维扩散界面模型，作为三相Cahn-Hilliard/Allen-Cahn系统。

Result: 1. 病毒载量对相对湿度敏感；2. 室温下水分子反射可忽略，但在高温和掠射角下显著增加；3. 扩散界面模型能重现并推广尖锐界面模型的特征。

Conclusion: 这些相互关联的研究为定量评估不同环境条件下的空气传播感染风险提供了理论基础，揭示了液滴蒸发动力学在病毒传播中的关键作用。

Abstract: We investigate three aspects of aerosol-mediated air-borne viral infection mechanisms on different length and time scales. First, we address the evolution of the size distribution of a non-interacting ensemble of droplets that are subject to evaporation and sedimentation using a sharp droplet-air interface model. From the exact solution of the evolution equation we derive the viral load in the air and show that it depends sensitively on the relative humidity. Secondly, from Molecular Dynamics simulations we extract the molecular reflection coefficient of single water molecules from the air-water interface. This parameter determines the water condensation and evaporation rate at a liquid droplet surface and therefore the evaporation rate of aqueous droplets. We find the reflection of water to be negligible at room temperature but to rise significantly at elevated temperatures and for grazing incidence angles. Thirdly, we derive a thermodynamically consistent three-dimensional diffuse-interface model for solute-containing droplets that is formulated as a three-phase Cahn-Hilliard/Allen-Cahn system. By numerically solving the coupled system of equations, we explore representative scenarios that show that this model reproduces and generalizes features of the sharp-interface model. These interconnected studies on the dynamics of aerosol droplet evaporation are relevant in order to quantitatively assess the airborne infection risk under varying environmental conditions.

</details>


### [77] [Coupled Level-Set Lattice Boltzmann Method on Adaptive Cartesian Grids](https://arxiv.org/abs/2601.05936)
*Julian Vorspohl,Yuxing Peng,Matthias Meinke,Dominik Krug,Wolfgang Schröder*

Main category: physics.flu-dyn

TL;DR: 提出了一种在自适应笛卡尔网格上耦合水平集与格子玻尔兹曼方法的新方法，用于模拟液-气多相流，能够处理尖锐界面和大密度比问题。


<details>
  <summary>Details</summary>
Motivation: 解决多相流模拟中准确建模尖锐界面和大密度比系统的固有挑战，提高模拟精度和计算效率。

Method: 采用自适应笛卡尔网格，结合格子玻尔兹曼方法和水平集技术，通过界面边界条件耦合各流体相的独立求解算法，实现界面有效追踪和网格自适应细化。

Result: 方法在多种测试案例（如不混溶分层流和上升气泡）中展示了捕捉复杂界面动力学的能力，并通过与文献数据对比验证了其准确性。

Conclusion: 提出的耦合水平集-格子玻尔兹曼方法在自适应网格上能够有效模拟液-气多相流，为处理尖锐界面和大密度比问题提供了一种准确且高效的计算框架。

Abstract: A novel coupled level-set lattice Boltzmann method on adaptive Cartesian grids for simulating liquid-gas multiphase flows is presented. The approach addresses the inherent challenges of accurately modeling multiphase systems characterized by sharp interfaces and large density ratios. By employing separate solution algorithms for each fluid phase which are coupled through boundary conditions at the interface the method is more accurate and more efficient. The study highlights the advantages of using lattice Boltzmann methods together with level-set techniques to track interfaces effectively while facilitating adaptive mesh refinement. Applications to various test cases, e.g., immiscible stratified flow and rising bubbles, demonstrate the method's capability to capture complex interfacial dynamics and validate its accuracy against literature data.

</details>
