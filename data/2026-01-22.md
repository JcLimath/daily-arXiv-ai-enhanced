<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 24]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 4]
- [cs.LG](#cs.LG) [Total: 50]
- [cs.AI](#cs.AI) [Total: 22]
- [math.CV](#math.CV) [Total: 5]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [RoboBrain 2.5: Depth in Sight, Time in Mind](https://arxiv.org/abs/2601.14352)
*Huajie Tan,Enshen Zhou,Zhiyu Li,Yijie Xu,Yuheng Ji,Xiansheng Chen,Cheng Chi,Pengwei Wang,Huizhu Jia,Yulong Ao,Mingyu Cao,Sixiang Chen,Zhe Li,Mengzhen Liu,Zixiao Wang,Shanyu Rong,Yaoxu Lyu,Zhongxia Zhao,Peterson Co,Yibo Li,Yi Han,Shaoxuan Xie,Guocai Yao,Songjing Wang,Leiduo Zhang,Xi Yang,Yance Jiao,Donghai Shi,Kunchang Xie,Shaokai Nie,Chunlei Men,Yonghua Lin,Zhongyuan Wang,Tiejun Huang,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboBrain 2.5是一个下一代具身AI基础模型，通过高质量时空监督训练，提升了通用感知、空间推理和时间建模能力，专注于复杂精细操作任务。


<details>
  <summary>Details</summary>
Motivation: 现有具身AI模型在精确3D空间推理和密集时间价值估计方面存在局限，需要更物理基础和执行感知的智能来处理复杂精细操作任务。

Method: 引入两大能力升级：1）精确3D空间推理：从2D像素相对定位转向深度感知坐标预测和绝对度量约束理解，生成完整3D操作轨迹作为有序关键点序列；2）密集时间价值估计：提供密集、步骤感知的进度预测和执行状态理解，产生稳定反馈信号。

Result: 模型实现了更物理基础和执行感知的具身智能，能够处理复杂精细操作任务，代码和检查点已公开。

Conclusion: RoboBrain 2.5通过精确3D空间推理和密集时间价值估计的升级，推进了具身AI基础模型在物理基础和执行感知方面的发展，为复杂精细操作提供了更强大的能力。

Abstract: We introduce RoboBrain 2.5, a next-generation embodied AI foundation model that advances general perception, spatial reasoning, and temporal modeling through extensive training on high-quality spatiotemporal supervision. Building upon its predecessor, RoboBrain 2.5 introduces two major capability upgrades. Specifically, it unlocks Precise 3D Spatial Reasoning by shifting from 2D pixel-relative grounding to depth-aware coordinate prediction and absolute metric constraint comprehension, generating complete 3D manipulation traces as ordered keypoint sequences under physical constraints. Complementing this spatial precision, the model establishes Dense Temporal Value Estimation that provides dense, step-aware progress prediction and execution state understanding across varying viewpoints, producing stable feedback signals for downstream learning. Together, these upgrades extend the framework toward more physically grounded and execution-aware embodied intelligence for complex, fine-grained manipulation. The code and checkpoints are available at project website: https://superrobobrain.github.io

</details>


### [2] [Agentic AI Meets Edge Computing in Autonomous UAV Swarms](https://arxiv.org/abs/2601.14437)
*Thuan Minh Nguyen,Vu Tuan Truong,Long Bao Le*

Main category: cs.RO

TL;DR: 该论文研究了将基于LLM的智能体AI与边缘计算集成到无人机集群中，以实现可扩展和弹性的自主性，特别针对野火搜救等高风险场景。


<details>
  <summary>Details</summary>
Motivation: 将具备自主推理、规划和执行能力的LLM智能体AI集成到无人机集群中，为无人机物联网带来新的操作可能性，但基础设施限制、动态环境和多智能体协调的计算需求限制了其在高风险场景（如野火和灾难响应）中的实际部署。

Method: 论文首先讨论了支持无人机集群的三种架构：独立部署、边缘赋能部署和边缘-云混合部署，每种架构针对不同的自主性和连接性水平进行优化。然后设计了一个野火搜救用例来展示边缘赋能架构的效率。

Result: 边缘赋能架构在野火搜救用例中表现出高效率，实现了更高的搜救覆盖率、更短的任务完成时间，以及相比传统方法更高水平的自主性。

Conclusion: 论文强调了将LLM与边缘计算集成到任务关键型无人机集群应用中面临的开放挑战，为未来研究提供了方向。

Abstract: The integration of agentic AI, powered by large language models (LLMs) with autonomous reasoning, planning, and execution, into unmanned aerial vehicle (UAV) swarms opens new operational possibilities and brings the vision of the Internet of Drones closer to reality. However, infrastructure constraints, dynamic environments, and the computational demands of multi-agent coordination limit real-world deployment in high-risk scenarios such as wildfires and disaster response. This paper investigates the integration of LLM-based agentic AI and edge computing to realize scalable and resilient autonomy in UAV swarms. We first discuss three architectures for supporting UAV swarms - standalone, edge-enabled, and edge-cloud hybrid deployment - each optimized for varying autonomy and connectivity levels. Then, a use case for wildfire search and rescue (SAR) is designed to demonstrate the efficiency of the edge-enabled architecture, enabling high SAR coverage, reduced mission completion times, and a higher level of autonomy compared to traditional approaches. Finally, we highlight open challenges in integrating LLMs and edge computing for mission-critical UAV-swarm applications.

</details>


### [3] [Robust Haptic Rendering Using a Nonlinear Impedance Matching Approach (NIMA) for Robotic Laparoscopic Surgery](https://arxiv.org/abs/2601.14445)
*Aiden Mazidi,Majid Roshanfar,Amir Sayadi,Javad Dargahi,Jake Barralet,Liane S. Feldman,Amir Hooshiar*

Main category: cs.RO

TL;DR: 提出非线性阻抗匹配方法(NIMA)用于机器人辅助微创手术的触觉反馈，相比传统IMA方法显著提高了力反馈精度并消除了触觉"回弹"现象


<details>
  <summary>Details</summary>
Motivation: 机器人辅助微创手术(RAMIS)中触觉反馈长期受限于力渲染精度和系统安全性问题，需要鲁棒、高保真的触觉系统来提升远程手术工具的精度和可靠性

Method: 提出非线性阻抗匹配方法(NIMA)，在先前验证的阻抗匹配方法(IMA)基础上加入非线性动力学，以准确建模和渲染工具-组织交互中的复杂力

Result: NIMA将力反馈的平均绝对误差(MAE)降低至0.01N(SD 0.02)，相比IMA减少了95%；有效消除了触觉"回弹"现象，确保用户释放手柄时触觉设备不对用户手施加力

Conclusion: NIMA能够考虑工具-组织交互中的非线性特性，在各种手术条件下提高了力保真度、响应性和精度，推动了机器人手术触觉反馈系统的发展

Abstract: Background: The integration of haptic feedback into robot-assisted minimally invasive surgery (RAMIS) has long been limited by challenges in accurately rendering forces and ensuring system safety. The need for robust, high-fidelity haptic systems is critical for enhancing the precision and reliability of teleoperated surgical tools. Methods: In this study, we present a Nonlinear Impedance Matching Approach (NIMA) designed to improve force rendering by accurately modelling complex tool-tissue interactions. Based on our previously validated Impedance Matching Approach (IMA), our novel NIMA method includes nonlinear dynamics to capture and render tool-tissue forces effectively. Results: NIMA improves force feedback accuracy with a mean absolute error (MAE) of 0.01 (SD 0.02) N, achieving a 95% reduction in MAE compared to IMA. Furthermore, NIMA effectively eliminates haptic "kickback" by ensuring no force is applied by the haptic device to the user's hand when they release the handle, enhancing both patient safety and user comfort. Conclusion: NIMA's ability to account for nonlinearities in tool-tissue interactions provides an improvement in force fidelity, responsiveness, and precision across various surgical conditions. Our findings promote the advancement of haptic feedback systems for robotic surgery, offering a realistic and reliable interface for robot-assisted surgical procedures.

</details>


### [4] [UNCLE-Grasp: Uncertainty-Aware Grasping of Leaf-Occluded Strawberries](https://arxiv.org/abs/2601.14492)
*Malak Mansour,Ali Abouzeid,Zezhou Sun,Qinbo Sun,Dezhen Song,Abdalla Swikir*

Main category: cs.RO

TL;DR: 提出了一种面向部分遮挡草莓的感知不确定性抓取方法，通过蒙特卡洛dropout生成多个形状假设，基于力闭合指标评估抓取可行性，采用保守的下置信界准则决定是否执行抓取，在严重遮挡下可靠地避免高风险尝试。


<details>
  <summary>Details</summary>
Motivation: 机器人草莓采摘在部分遮挡场景下面临几何不确定性挑战，叶片遮挡导致单次形状估计不可靠，多个可能的3D补全可能产生相互矛盾的抓取可行性判断，需要显式建模补全不确定性来做出可靠决策。

Method: 使用蒙特卡洛dropout的点云补全方法生成多个形状假设，为每个补全生成候选抓取，基于物理基础的力闭合指标评估抓取可行性，通过聚合所有补全的可行性评估并应用保守的下置信界准则来决定是否执行抓取或安全放弃。

Result: 在仿真和物理机器人实验中，该方法在合成和真实叶片遮挡的不同程度下均表现出色，能够在严重遮挡下可靠地避免高风险抓取尝试，同时在几何置信度足够时保持稳健的抓取执行，优于确定性基线方法。

Conclusion: 显式建模补全不确定性并结合保守决策准则的抓取方法，能够在部分遮挡的草莓采摘场景中实现可靠的风险规避和稳健执行，为不确定环境下的机器人操作提供了有效解决方案。

Abstract: Robotic strawberry harvesting is challenging under partial occlusion, where leaves induce significant geometric uncertainty and make grasp decisions based on a single deterministic shape estimate unreliable. From a single partial observation, multiple incompatible 3D completions may be plausible, causing grasps that appear feasible on one completion to fail on another. We propose an uncertainty-aware grasping pipeline for partially occluded strawberries that explicitly models completion uncertainty arising from both occlusion and learned shape reconstruction. Our approach uses point cloud completion with Monte Carlo dropout to sample multiple shape hypotheses, generates candidate grasps for each completion, and evaluates grasp feasibility using physically grounded force-closure-based metrics. Rather than selecting a grasp based on a single estimate, we aggregate feasibility across completions and apply a conservative lower confidence bound (LCB) criterion to decide whether a grasp should be attempted or safely abstained. We evaluate the proposed method in simulation and on a physical robot across increasing levels of synthetic and real leaf occlusion. Results show that uncertainty-aware decision making enables reliable abstention from high-risk grasp attempts under severe occlusion while maintaining robust grasp execution when geometric confidence is sufficient, outperforming deterministic baselines in both simulated and physical robot experiments.

</details>


### [5] [TacUMI: A Multi-Modal Universal Manipulation Interface for Contact-Rich Tasks](https://arxiv.org/abs/2601.14550)
*Tailai Cheng,Kejia Chen,Lingyun Chen,Liding Zhang,Yue Zhang,Yao Ling,Mahdi Hamad,Zhenshan Bing,Fan Wu,Karan Sharma,Alois Knoll*

Main category: cs.RO

TL;DR: TacUMI系统整合多种传感器于紧凑夹爪设计，实现多模态数据同步采集，并提出基于时序模型的多模态分割框架，在电缆安装任务中达到90%以上分割准确率


<details>
  <summary>Details</summary>
Motivation: 复杂长时程操作任务需要任务分解，仅依赖视觉和本体感知信息难以揭示事件转换，需要高质量多模态数据和鲁棒分割方法

Method: 基于UMI手持演示设备，集成ViTac传感器、力-力矩传感器和姿态跟踪器到紧凑机器人兼容夹爪设计中，实现多模态同步采集；提出利用时序模型检测语义事件边界的多模态分割框架

Result: 在电缆安装任务中评估显示超过90%的分割准确率，多模态融合显著提升性能，验证了TacUMI为接触丰富任务中多模态演示的可扩展采集和分割奠定基础

Conclusion: TacUMI系统建立了接触丰富任务中多模态演示可扩展采集和分割的实用基础，多模态融合显著提升分割性能

Abstract: Task decomposition is critical for understanding and learning complex long-horizon manipulation tasks. Especially for tasks involving rich physical interactions, relying solely on visual observations and robot proprioceptive information often fails to reveal the underlying event transitions. This raises the requirement for efficient collection of high-quality multi-modal data as well as robust segmentation method to decompose demonstrations into meaningful modules. Building on the idea of the handheld demonstration device Universal Manipulation Interface (UMI), we introduce TacUMI, a multi-modal data collection system that integrates additionally ViTac sensors, force-torque sensor, and pose tracker into a compact, robot-compatible gripper design, which enables synchronized acquisition of all these modalities during human demonstrations. We then propose a multi-modal segmentation framework that leverages temporal models to detect semantically meaningful event boundaries in sequential manipulations. Evaluation on a challenging cable mounting task shows more than 90 percent segmentation accuracy and highlights a remarkable improvement with more modalities, which validates that TacUMI establishes a practical foundation for both scalable collection and segmentation of multi-modal demonstrations in contact-rich tasks.

</details>


### [6] [UniCon: A Unified System for Efficient Robot Learning Transfers](https://arxiv.org/abs/2601.14617)
*Yunfeng Lin,Li Xu,Yong Yu,Jiangmiao Pang,Weinan Zhang*

Main category: cs.RO

TL;DR: UniCon是一个轻量级框架，通过标准化状态、控制流和仪器化，实现学习型控制器在异构机器人间的即插即用部署，提高推理效率并减少代码冗余。


<details>
  <summary>Details</summary>
Motivation: 异构机器人平台部署学习型控制器面临平台差异、接口不一致和中间件效率低下的挑战，需要统一的解决方案来简化跨平台部署。

Method: 将工作流分解为可重用组件的执行图，分离系统状态与控制逻辑，采用批处理和向量化数据流最小化通信开销，实现模块化、数据导向的架构。

Result: UniCon在转移工作流时减少代码冗余，相比ROS系统实现更高推理效率，已在7个制造商的12种机器人模型上成功部署并集成到实际研究项目中。

Conclusion: UniCon通过标准化和高效数据流设计，有效解决了异构机器人控制器部署的挑战，实现了无缝的仿真到现实转移，在实际应用中证明了其有效性。

Abstract: Deploying learning-based controllers across heterogeneous robots is challenging due to platform differences, inconsistent interfaces, and inefficient middleware. To address these issues, we present UniCon, a lightweight framework that standardizes states, control flow, and instrumentation across platforms. It decomposes workflows into execution graphs with reusable components, separating system states from control logic to enable plug-and-play deployment across various robot morphologies. Unlike traditional middleware, it prioritizes efficiency through batched, vectorized data flow, minimizing communication overhead and improving inference latency. This modular, data-oriented approach enables seamless sim-to-real transfer with minimal re-engineering. We demonstrate that UniCon reduces code redundancy when transferring workflows and achieves higher inference efficiency compared to ROS-based systems. Deployed on over 12 robot models from 7 manufacturers, it has been successfully integrated into ongoing research projects, proving its effectiveness in real-world scenarios.

</details>


### [7] [Probing Prompt Design for Socially Compliant Robot Navigation with Vision Language Models](https://arxiv.org/abs/2601.14622)
*Ling Xiao,Toshihiko Yamasaki*

Main category: cs.RO

TL;DR: 该研究探索了基于认知理论的社会机器人导航提示设计，发现竞争性动机框架和系统指导提示能显著提升小视觉语言模型的决策准确性，而直接微调主要改善语义理解而非动作精度。


<details>
  <summary>Details</summary>
Motivation: 当前社会机器人导航基准缺乏原则性的提示设计，而实际部署中多使用效率高但决策能力较弱的小视觉语言模型。现有研究未充分考虑如何通过有效的提示设计来弥补小模型在决策能力上的不足，特别是在社会合规行为方面。

Method: 受人类学习和动机的认知理论启发，研究从两个维度设计提示：系统指导（动作聚焦、推理导向、感知-推理提示）和动机框架（与人类竞争、与其他AI系统竞争、与自身过去表现竞争）。在两个社会合规导航数据集上进行实验，对比不同提示设计对GPT-4o（微调与非微调版本）性能的影响。

Result: 1. 对于非微调GPT-4o，与人类竞争表现最佳，与其他AI系统竞争最差。对于微调模型，与自身过去竞争表现最强，其次是与人类竞争。2. 不恰当的系统提示设计会显著降低性能，甚至不如直接微调。3. 直接微调主要提升感知、预测和推理等语义级指标，但对动作准确性改善有限；而系统提示在动作准确性上产生不成比例的大幅提升。

Conclusion: 提出的提示设计主要作为决策级约束而非表征增强，能有效提升小视觉语言模型在社会机器人导航中的动作准确性。竞争性动机框架与适当的系统指导提示相结合，可以弥补小模型在决策能力上的不足，为社会合规导航提供有效的提示设计策略。

Abstract: Language models are increasingly used for social robot navigation, yet existing benchmarks largely overlook principled prompt design for socially compliant behavior. This limitation is particularly relevant in practice, as many systems rely on small vision language models (VLMs) for efficiency. Compared to large language models, small VLMs exhibit weaker decision-making capabilities, making effective prompt design critical for accurate navigation. Inspired by cognitive theories of human learning and motivation, we study prompt design along two dimensions: system guidance (action-focused, reasoning-oriented, and perception-reasoning prompts) and motivational framing, where models compete against humans, other AI systems, or their past selves. Experiments on two socially compliant navigation datasets reveal three key findings. First, for non-finetuned GPT-4o, competition against humans achieves the best performance, while competition against other AI systems performs worst. For finetuned models, competition against the model's past self yields the strongest results, followed by competition against humans, with performance further influenced by coupling effects among prompt design, model choice, and dataset characteristics. Second, inappropriate system prompt design can significantly degrade performance, even compared to direct finetuning. Third, while direct finetuning substantially improves semantic-level metrics such as perception, prediction, and reasoning, it yields limited gains in action accuracy. In contrast, our system prompts produce a disproportionately larger improvement in action accuracy, indicating that the proposed prompt design primarily acts as a decision-level constraint rather than a representational enhancement.

</details>


### [8] [A Brain-inspired Embodied Intelligence for Fluid and Fast Reflexive Robotics Control](https://arxiv.org/abs/2601.14628)
*Weiyu Guo,He Zhang,Pengteng Li,Tiefu Cai,Ziyang Chen,Yandong Guo,Xiao He,Yongkui Yang,Ying Sun,Hui Xiong*

Main category: cs.RO

TL;DR: NeuroVLA是一个受生物神经系统启发的神经形态视觉-语言-动作框架，首次在物理机器人上部署，实现了最先进的性能，并展现出生物运动特性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人策略难以复制生物运动的动态稳定性、反射响应性和时间记忆能力，而生物系统能从稀疏经验中快速获取技能。需要开发能模拟生物神经系统结构的框架来克服这些限制。

Method: 采用系统级生物启发设计：高层模型规划目标，自适应小脑模块利用高频传感器反馈稳定运动，生物启发的脊髓层执行快速动作生成。这是首个在物理机器人上部署的神经形态VLA框架。

Result: 实现了最先进的性能，在没有额外数据或特殊指导的情况下涌现出生物运动特性：消除机械臂抖动、显著节能（神经形态处理器仅0.4w）、展现时间记忆能力、在20毫秒内触发安全反射。

Conclusion: NeuroVLA框架成功模拟了生物神经系统的结构组织，在物理机器人上实现了生物运动特性，为机器人控制提供了新的生物启发方法。

Abstract: Recent advances in embodied intelligence have leveraged massive scaling of data and model parameters to master natural-language command following and multi-task control. In contrast, biological systems demonstrate an innate ability to acquire skills rapidly from sparse experience. Crucially, current robotic policies struggle to replicate the dynamic stability, reflexive responsiveness, and temporal memory inherent in biological motion. Here we present Neuromorphic Vision-Language-Action (NeuroVLA), a framework that mimics the structural organization of the bio-nervous system between the cortex, cerebellum, and spinal cord. We adopt a system-level bio-inspired design: a high-level model plans goals, an adaptive cerebellum module stabilizes motion using high-frequency sensors feedback, and a bio-inspired spinal layer executes lightning-fast actions generation. NeuroVLA represents the first deployment of a neuromorphic VLA on physical robotics, achieving state-of-the-art performance. We observe the emergence of biological motor characteristics without additional data or special guidance: it stops the shaking in robotic arms, saves significant energy(only 0.4w on Neuromorphic Processor), shows temporal memory ability and triggers safety reflexes in less than 20 milliseconds.

</details>


### [9] [Landing-Induced Viscoelastic Changes in an Anthropomimetic Foot Joint Structure are Modulated by Foot Structure and Posture](https://arxiv.org/abs/2601.14634)
*Satoru Hashimoto,Yinlai Jiang,Hiroshi Yokoi,Shunta Togo*

Main category: cs.RO

TL;DR: 开发仿人足部关节结构研究骨骼架构对落地冲击衰减的影响，发现多关节拱形结构比简化平足具有更高阻尼比，且踝背屈和趾伸展可调节衰减与回弹的权衡。


<details>
  <summary>Details</summary>
Motivation: 尸体研究难以重复探测落地冲击后的姿势依赖性粘弹性响应，导致骨骼架构对落地动力学的贡献不完全清楚。需要开发仿人足部结构来研究骨骼结构和姿势如何调节冲击后的粘弹性响应。

Method: 开发了仿人足部关节结构，复制人类足部骨骼几何形态。使用垂直下落装置模拟落地，结合粘弹性系统识别模型，研究骨骼结构和姿势如何调节冲击后的表观粘弹性响应。

Result: 多关节仿人结构比简化的平足和刚性足表现出更高的阻尼比。踝背屈和趾伸展系统地改变了识别参数，在测试条件下降低了阻尼比。拱形多关节骨骼架构可以增强仿人机械足的冲击衰减，形态和被动姿势可以调节衰减与回弹的权衡。

Conclusion: 骨骼架构可能部分解释了人类落地策略的调节。解剖学启发的骨骼复制具有工程优势，可以通过姿势调整实现类人的表观粘弹性行为。这些发现表明被动骨骼结构在冲击衰减中的重要作用。

Abstract: Cadaveric studies have provided important insights into the mechanics of the human foot arch and plantar fascia. However, repeatedly probing posture-dependent viscoelastic responses immediately after landing impact is difficult in biological specimens, leaving the contribution of skeletal architecture to landing dynamics incompletely understood. In this study, we developed an anthropomimetic foot joint structure aimed at replicating the skeletal geometry of the human foot. Using a vertical drop apparatus that simulates landing and a viscoelastic system-identification model, we investigated how skeletal structure and posture modulate the apparent post-impact viscoelastic response. The results show that the multi-jointed anthropomimetic structure exhibited a higher damping ratio than simplified flat and rigid feet. Moreover, ankle dorsiflexion and toe extension systematically shifted the identified parameters, reducing the damping ratio under the tested conditions. Taken together, these findings indicate that an arch-like, multi-jointed skeletal architecture can enhance impact attenuation in an anthropomimetic mechanical foot, and that morphology and passive posture alone can tune the trade-off between attenuation and rebound. The observed posture-dependent trends are qualitatively consistent with reported differences in human landing strategies, suggesting that skeletal architecture may partly account for the modulation. Furthermore, these results highlight the engineering advantage of anatomically informed skeletal replication for achieving human-like apparent viscoelastic behavior through postural adjustment during landing.

</details>


### [10] [FARE: Fast-Slow Agentic Robotic Exploration](https://arxiv.org/abs/2601.14681)
*Shuhao Liao,Xuxin Lv,Jeric Lew,Shizhe Zhang,Jingsong Liang,Peizhuo Li,Yuhong Cao,Wenjun Wu,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: FARE：一种分层自主探索框架，将LLM的全局语义推理与RL的局部控制相结合，通过快慢思维范式提升机器人探索效率


<details>
  <summary>Details</summary>
Motivation: 现有自主探索方法通常在几何层面进行决策，缺乏对环境的语义理解和高层次推理能力，限制了在复杂未知环境中的探索效率

Method: 采用分层架构：1）慢思维LLM模块解析环境文本描述，生成探索策略并通过拓扑图转化为全局路径点；2）快思维RL模块基于局部观测执行探索，同时受全局路径点引导；3）引入模块化剪枝机制减少冗余图结构；4）奖励函数鼓励遵循全局路径点

Result: 在仿真环境中，FARE相比最先进基线方法显著提升了探索效率；在硬件部署中，成功验证了在200m×130m大型建筑环境中的有效性

Conclusion: FARE通过将语义推理与几何决策解耦，使各模块在适当的时空尺度上运行，实现了高效、鲁棒的自主探索，为机器人智能探索提供了新范式

Abstract: This work advances autonomous robot exploration by integrating agent-level semantic reasoning with fast local control. We introduce FARE, a hierarchical autonomous exploration framework that integrates a large language model (LLM) for global reasoning with a reinforcement learning (RL) policy for local decision making. FARE follows a fast-slow thinking paradigm. The slow-thinking LLM module interprets a concise textual description of the unknown environment and synthesizes an agent-level exploration strategy, which is then grounded into a sequence of global waypoints through a topological graph. To further improve reasoning efficiency, this module employs a modularity-based pruning mechanism that reduces redundant graph structures. The fast-thinking RL module executes exploration by reacting to local observations while being guided by the LLM-generated global waypoints. The RL policy is additionally shaped by a reward term that encourages adherence to the global waypoints, enabling coherent and robust closed-loop behavior. This architecture decouples semantic reasoning from geometric decision, allowing each module to operate in its appropriate temporal and spatial scale. In challenging simulated environments, our results show that FARE achieves substantial improvements in exploration efficiency over state-of-the-art baselines. We further deploy FARE on hardware and validate it in complex, large scale $200m\times130m$ building environment.

</details>


### [11] [Stochastic Decision-Making Framework for Human-Robot Collaboration in Industrial Applications](https://arxiv.org/abs/2601.14809)
*Muhammad Adel Yusuf,Ali Nasir,Zeeshan Hameed Khan*

Main category: cs.RO

TL;DR: 提出一种基于随机建模的人机协作决策方法，通过概率模型和控制策略预测人类行为和情绪，使协作机器人能相应调整行为


<details>
  <summary>Details</summary>
Motivation: 随着协作机器人在工业和服务领域的广泛应用，需要机器人能够基于人类因素（如动机水平和攻击性水平）进行推理，以实现有效的人机协作。目前大多数研究集中于检测人类合作者的意图，但需要更全面的决策方法

Method: 采用随机建模方法，利用概率模型和控制策略来预测人类行为和情绪，使协作机器人能够相应地调整其行为

Result: 论文讨论了理论框架、实施策略、仿真结果以及双边协作方法在协作机器人安全和效率方面的潜在应用

Conclusion: 提出的基于随机建模的决策方法能够使协作机器人更好地适应人类行为和情绪，提高人机协作的安全性和效率，为协作机器人领域提供了新的理论框架和实施策略

Abstract: Collaborative robots, or cobots, are increasingly integrated into various industrial and service settings to work efficiently and safely alongside humans. However, for effective human-robot collaboration, robots must reason based on human factors such as motivation level and aggression level. This paper proposes an approach for decision-making in human-robot collaborative (HRC) environments utilizing stochastic modeling. By leveraging probabilistic models and control strategies, the proposed method aims to anticipate human actions and emotions, enabling cobots to adapt their behavior accordingly. So far, most of the research has been done to detect the intentions of human co-workers. This paper discusses the theoretical framework, implementation strategies, simulation results, and potential applications of the bilateral collaboration approach for safety and efficiency in collaborative robotics.

</details>


### [12] [Moving Beyond Compliance in Soft-Robotic Catheters Through Modularity for Precision Therapies](https://arxiv.org/abs/2601.14837)
*B. Calmé,N. J. Greenidge,A. Metcalf,A. Bacchetti,G. Loza,D. Kpeglo,P. Lloyd,V. Pensabene,J. H. Chandler,P. Valdastri*

Main category: cs.RO

TL;DR: 研究人员开发了一种直径1.47毫米的模块化软体机器人导管，集成了传感、驱动和治疗功能，能够在腔内导航中实现半自主部署和精准操作，特别针对胰腺导管等难以进入的区域。


<details>
  <summary>Details</summary>
Motivation: 软体机器人器械在脆弱、曲折的解剖结构中导航比刚性工具更安全，但临床应用受到限制，主要因为尖端功能化不足和缺乏实时组织界面反馈。现有传感和治疗模块不够紧凑、鲁棒和适应性强，难以在腔内手术中测量并响应细微的生理信号。

Method: 开发了一种直径1.47毫米的模块化软体机器人导管架构，支持最多四个独立控制的功能单元，可定制化组合锚定、操作、传感和靶向给药功能。系统结合了学习模型、磁驱动、板载形状传感和视觉标记跟踪，形成闭环自主/共享控制系统。

Result: 在活体猪模型中，成功演示了半自主部署到胰腺导管内，并在其中进行了7.5厘米的内窥镜导航，这是目前标准导管无法进入的区域。闭环控制系统进一步提高了插管准确性。该系统在多个体内环境中得到验证，特别强调了在内窥镜逆行胰胆管造影（ERCP）中的应用。

Conclusion: 该研究建立了一个可扩展的多功能软体机器人导管平台，为复杂的腔内介入提供了新范式，具有减少辐射暴露、缩短培训时间、加速软体机器人技术临床转化的潜力。

Abstract: Soft robotic instruments could navigate delicate, tortuous anatomy more safely than rigid tools, but clinical adoption is limited by insufficient tip functionalization and real-time feedback at the tissue interface. Few sensing and therapeutic modules are compact, robust, and adaptable enough to measure, and respond to, subtle physiological cues during intraluminal procedures. We present a 1.47 mm diameter modular soft robotic catheter that integrates sensing, actuation, and therapy while retaining the compliance needed for safe endoluminal navigation. Validated across multiple in vivo settings, we emphasize its utility in endoscopic retrograde cholangiopancreatography (ERCP), a highly technical procedure and a key access route to the pancreas, an organ that is fragile, difficult to instrument, and central to diseases such as pancreatic cancer. Our architecture supports up to four independently controlled functional units, allowing customizable combinations of anchoring, manipulation, sensing, and targeted drug delivery. In a live porcine model, we demonstrate semi-autonomous deployment into the pancreatic duct and 7.5 cm of endoscopic navigation within it, a region currently inaccessible with standard catheters. A closed-loop autonomous/shared-control system that combines a learned model, magnetic actuation, onboard shape sensing, and visual marker tracking further improves cannulation accuracy. Together, these results establish a scalable platform for multifunctional soft robotic catheters and a new paradigm for complex endoluminal interventions, with potential to reduce radiation exposure, shorten training, and accelerate clinical translation of soft robotic technologies.

</details>


### [13] [On-the-fly hand-eye calibration for the da Vinci surgical robot](https://arxiv.org/abs/2601.14871)
*Zejian Cui,Ferdinando Rodriguez y Baena*

Main category: cs.RO

TL;DR: 提出用于达芬奇手术机器人的在线手眼标定框架，通过特征关联和标定算法减少工具定位误差，无需预训练，适应多种手术场景。


<details>
  <summary>Details</summary>
Motivation: 在机器人辅助微创手术中，电缆驱动机器人（如达芬奇机器人）的编码器读数误差导致工具定位不准确，影响患者安全和手术成功，需要解决这一挑战。

Method: 提出包含两个相互关联算法的标定框架：特征关联模块（为单目图像检测的关键点提供鲁棒对应关系，无需预训练）和手眼标定模块（采用多种滤波方法适应不同手术场景），在线计算手眼变换矩阵。

Result: 在公开视频数据集上的测试显示，该框架显著降低了工具定位误差，精度与最先进方法相当，同时具有更高的时间效率。

Conclusion: 提出的在线手眼标定框架能有效提高电缆驱动手术机器人的工具定位精度，适应不同手术条件和环境变化，具有实际应用价值。

Abstract: In Robot-Assisted Minimally Invasive Surgery (RMIS), accurate tool localization is crucial to ensure patient safety and successful task execution. However, this remains challenging for cable-driven robots, such as the da Vinci robot, because erroneous encoder readings lead to pose estimation errors. In this study, we propose a calibration framework to produce accurate tool localization results through computing the hand-eye transformation matrix on-the-fly. The framework consists of two interrelated algorithms: the feature association block and the hand-eye calibration block, which provide robust correspondences for key points detected on monocular images without pre-training, and offer the versatility to accommodate various surgical scenarios by adopting an array of filter approaches, respectively. To validate its efficacy, we test the framework extensively on publicly available video datasets that feature multiple surgical instruments conducting tasks in both in vitro and ex vivo scenarios, under varying illumination conditions and with different levels of key point measurement accuracy. The results show a significant reduction in tool localization errors under the proposed calibration framework, with accuracies comparable to other state-of-the-art methods while being more time-efficient.

</details>


### [14] [HumanoidVLM: Vision-Language-Guided Impedance Control for Contact-Rich Humanoid Manipulation](https://arxiv.org/abs/2601.14874)
*Yara Mahmoud,Yasheerah Yaqoot,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: HumanoidVLM框架通过视觉语言模型和检索增强生成技术，使Unitree G1人形机器人能够根据第一人称RGB图像自动选择任务相关的笛卡尔阻抗参数和夹爪配置，实现自适应操作。


<details>
  <summary>Details</summary>
Motivation: 人形机器人需要适应不同物体和任务的接触行为，但现有控制器大多依赖固定、手动调整的阻抗增益和夹爪设置，缺乏自适应能力。

Method: 提出HumanoidVLM框架：1) 使用视觉语言模型进行语义任务推理；2) 基于FAISS的检索增强生成模块从两个定制数据库中检索实验验证的刚度-阻尼对和物体特定抓取角度；3) 通过任务空间阻抗控制器执行检索到的参数进行顺应性操作。

Result: 在14个视觉场景中达到93%的检索准确率。真实世界实验显示稳定的交互动力学：z轴跟踪误差通常在1-3.5厘米内，虚拟力与任务相关阻抗设置一致。

Conclusion: 该研究证明了将语义感知与基于检索的控制相结合是可行的，为自适应人形机器人操作提供了一条可解释的路径。

Abstract: Humanoid robots must adapt their contact behavior to diverse objects and tasks, yet most controllers rely on fixed, hand-tuned impedance gains and gripper settings. This paper introduces HumanoidVLM, a vision-language driven retrieval framework that enables the Unitree G1 humanoid to select task-appropriate Cartesian impedance parameters and gripper configurations directly from an egocentric RGB image. The system couples a vision-language model for semantic task inference with a FAISS-based Retrieval-Augmented Generation (RAG) module that retrieves experimentally validated stiffness-damping pairs and object-specific grasp angles from two custom databases, and executes them through a task-space impedance controller for compliant manipulation. We evaluate HumanoidVLM on 14 visual scenarios and achieve a retrieval accuracy of 93%. Real-world experiments show stable interaction dynamics, with z-axis tracking errors typically within 1-3.5 cm and virtual forces consistent with task-dependent impedance settings. These results demonstrate the feasibility of linking semantic perception with retrieval-based control as an interpretable path toward adaptive humanoid manipulation.

</details>


### [15] [Vision-Language Models on the Edge for Real-Time Robotic Perception](https://arxiv.org/abs/2601.14921)
*Sarat Ahmad,Maryam Hafeez,Syed Ali Raza Zaidi*

Main category: cs.RO

TL;DR: 该论文研究了在6G边缘智能（ORAN/MEC）基础设施上部署视觉语言模型（VLMs），以解决机器人系统中云计算的延迟、资源限制和隐私问题，通过Unitree G1人形机器人测试了边缘部署与云部署的性能差异。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在机器人感知和交互中具有重要作用，但其实际部署面临延迟、有限板载资源和云卸载隐私风险等挑战。6G边缘智能（特别是Open RAN和MEC）通过将计算靠近数据源，为解决这些挑战提供了途径。

Method: 使用Unitree G1人形机器人作为实体测试平台，设计基于WebRTC的流水线将多模态数据流传输到边缘节点。在实时条件下评估了LLaMA-3.2-11B-Vision-Instruct在边缘部署与云部署的性能，并进一步评估了针对资源受限环境优化的紧凑模型Qwen2-VL-2B-Instruct。

Result: 边缘部署在保持接近云端精度的同时，将端到端延迟降低了5%。Qwen2-VL-2B-Instruct实现了亚秒级响应，将延迟减少了一半以上，但以牺牲准确性为代价。

Conclusion: 边缘智能基础设施为机器人系统中视觉语言模型的部署提供了可行的解决方案，能够在保持合理精度的同时显著降低延迟，特别是对于资源受限环境，紧凑模型提供了延迟与准确性之间的权衡选择。

Abstract: Vision-Language Models (VLMs) enable multimodal reasoning for robotic perception and interaction, but their deployment in real-world systems remains constrained by latency, limited onboard resources, and privacy risks of cloud offloading. Edge intelligence within 6G, particularly Open RAN and Multi-access Edge Computing (MEC), offers a pathway to address these challenges by bringing computation closer to the data source. This work investigates the deployment of VLMs on ORAN/MEC infrastructure using the Unitree G1 humanoid robot as an embodied testbed. We design a WebRTC-based pipeline that streams multimodal data to an edge node and evaluate LLaMA-3.2-11B-Vision-Instruct deployed at the edge versus in the cloud under real-time conditions. Our results show that edge deployment preserves near-cloud accuracy while reducing end-to-end latency by 5\%. We further evaluate Qwen2-VL-2B-Instruct, a compact model optimized for resource-constrained environments, which achieves sub-second responsiveness, cutting latency by more than half but at the cost of accuracy.

</details>


### [16] [TIDAL: Temporally Interleaved Diffusion and Action Loop for High-Frequency VLA Control](https://arxiv.org/abs/2601.14945)
*Yuteng Sun,Haoran Wang,Ruofei Bai,Zhengguo Li,Jun Li,Meng Yee,Chuah,Wei Yun Yau*

Main category: cs.RO

TL;DR: TIDAL是一个层次化框架，通过解耦语义推理与高频执行来解决VLA模型推理延迟问题，实现约9Hz控制更新


<details>
  <summary>Details</summary>
Motivation: 大规模视觉-语言-动作模型存在高推理延迟问题，导致在动态环境中执行盲点，目标在开环执行窗口内移动时容易失败

Method: 采用双频率架构：低频宏意图循环缓存语义嵌入，高频微控制循环交错单步流集成与执行；引入时间错位训练策略和差分运动预测器

Result: 在边缘硬件上实现约9Hz控制更新（基线约2.4Hz），动态拦截任务性能提升2倍，反馈频率提高4倍

Conclusion: TIDAL通过架构级优化有效解决了VLA模型的延迟问题，在动态环境中保持鲁棒性，同时扩展了语义嵌入的有效范围

Abstract: Large-scale Vision-Language-Action (VLA) models offer semantic generalization but suffer from high inference latency, limiting them to low-frequency batch-and-execute paradigm. This frequency mismatch creates an execution blind spot, causing failures in dynamic environments where targets move during the open-loop execution window. We propose TIDAL (Temporally Interleaved Diffusion and Action Loop), a hierarchical framework that decouples semantic reasoning from high-frequency actuation. TIDAL operates as a backbone-agnostic module for diffusion-based VLAs, using a dual-frequency architecture to redistribute the computational budget. Specifically, a low-frequency macro-intent loop caches semantic embeddings, while a high-frequency micro-control loop interleaves single-step flow integration with execution. This design enables approximately 9 Hz control updates on edge hardware (vs. approximately 2.4 Hz baselines) without increasing marginal overhead. To handle the resulting latency shift, we introduce a temporally misaligned training strategy where the policy learns predictive compensation using stale semantic intent alongside real-time proprioception. Additionally, we address the insensitivity of static vision encoders to velocity by incorporating a differential motion predictor. TIDAL is architectural, making it orthogonal to system-level optimizations. Experiments show a 2x performance gain over open-loop baselines in dynamic interception tasks. Despite a marginal regression in static success rates, our approach yields a 4x increase in feedback frequency and extends the effective horizon of semantic embeddings beyond the native action chunk size. Under non-paused inference protocols, TIDAL remains robust where standard baselines fail due to latency.

</details>


### [17] [HumanDiffusion: A Vision-Based Diffusion Trajectory Planner with Human-Conditioned Goals for Search and Rescue UAV](https://arxiv.org/abs/2601.14973)
*Faryal Batool,Iana Zhura,Valerii Serpiva,Roohan Ahmed Khan,Ivan Valuev,Issatay Tokmurziyev,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: HumanDiffusion：基于RGB图像的轻量级扩散规划器，用于无人机在紧急场景中实现人类感知的自主导航，结合YOLO-11人体检测和扩散轨迹生成，无需先验地图或复杂规划管道。


<details>
  <summary>Details</summary>
Motivation: 紧急场景下可靠的人机协作需要能够检测人类、推断导航目标并在动态环境中安全操作的自主系统。传统方法依赖先验地图或计算密集型规划管道，限制了在时间关键援助场景中的实用性。

Method: 提出HumanDiffusion系统：1) 使用YOLO-11进行人体检测；2) 基于RGB图像条件的扩散模型直接在像素空间生成人类感知的导航轨迹；3) 确保平滑运动和围绕人类的安全边界；4) 无需先验地图或复杂规划管道。

Result: 在300个样本测试集上，模型在像素空间轨迹重建中达到0.02的均方误差。真实世界室内模拟灾难场景实验中，在事故响应和搜索定位任务（含部分遮挡）中总体任务成功率达到80%。

Conclusion: 人类条件扩散规划为时间关键援助场景中的人类感知无人机导航提供了实用且鲁棒的解决方案，能够直接处理RGB图像并生成安全轨迹，适用于紧急医疗援助等应用。

Abstract: Reliable human--robot collaboration in emergency scenarios requires autonomous systems that can detect humans, infer navigation goals, and operate safely in dynamic environments. This paper presents HumanDiffusion, a lightweight image-conditioned diffusion planner that generates human-aware navigation trajectories directly from RGB imagery. The system combines YOLO-11--based human detection with diffusion-driven trajectory generation, enabling a quadrotor to approach a target person and deliver medical assistance without relying on prior maps or computationally intensive planning pipelines. Trajectories are predicted in pixel space, ensuring smooth motion and a consistent safety margin around humans. We evaluate HumanDiffusion in simulation and real-world indoor mock-disaster scenarios. On a 300-sample test set, the model achieves a mean squared error of 0.02 in pixel-space trajectory reconstruction. Real-world experiments demonstrate an overall mission success rate of 80% across accident-response and search-and-locate tasks with partial occlusions. These results indicate that human-conditioned diffusion planning offers a practical and robust solution for human-aware UAV navigation in time-critical assistance settings.

</details>


### [18] [Graph-Based Adaptive Planning for Coordinated Dual-Arm Robotic Disassembly of Electronic Devices (eGRAP)](https://arxiv.org/abs/2601.14998)
*Adip Ranjan Das,Maria Koskinopoulou*

Main category: cs.RO

TL;DR: 提出eGRAP系统，通过视觉、动态规划和双机械臂执行实现电子设备的自主拆解，在硬盘驱动器上验证了高效拆解能力


<details>
  <summary>Details</summary>
Motivation: 电子废弃物快速增长而回收率低，需要自动化拆解解决方案来提高回收效率和安全性

Method: 基于图的适应性规划(eGRAP)系统：视觉识别部件位姿，有向图编码拆解顺序，调度器使用拓扑排序选择有效下一步并分配给双机械臂并行执行，支持在线更新

Result: 在3.5英寸硬盘驱动器上成功演示，实现完整拆解，具有高成功率和高效循环时间，展示了实时自适应协调双机械臂任务的能力

Conclusion: eGRAP系统能够有效协调双机械臂进行实时自适应拆解，为电子废弃物自动化回收提供了可行解决方案

Abstract: E-waste is growing rapidly while recycling rates remain low. We propose an electronic-device Graph-based Adaptive Planning (eGRAP) that integrates vision, dynamic planning, and dual-arm execution for autonomous disassembly. A camera-equipped arm identifies parts and estimates their poses, and a directed graph encodes which parts must be removed first. A scheduler uses topological ordering of this graph to select valid next steps and assign them to two robot arms, allowing independent tasks to run in parallel. One arm carries a screwdriver (with an eye-in-hand depth camera) and the other holds or handles components. We demonstrate eGRAP on 3.5in hard drives: as parts are unscrewed and removed, the system updates its graph and plan online. Experiments show consistent full disassembly of each HDD, with high success rates and efficient cycle times, illustrating the method's ability to adaptively coordinate dual-arm tasks in real time.

</details>


### [19] [DWPP: Dynamic Window Pure Pursuit Considering Velocity and Acceleration Constraints](https://arxiv.org/abs/2601.15006)
*Fumiya Ohnishi,Masaki Takahashi*

Main category: cs.RO

TL;DR: DWPP（动态窗口纯追踪）是一种改进的路径跟踪方法，通过在速度空间（v-ω平面）中考虑速度和加速度约束来避免传统纯追踪方法的速度指令违反约束问题，从而提高跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 传统纯追踪方法及其变体虽然简单且计算效率高，但通常没有明确考虑速度和加速度约束，导致指令速度与实际速度之间存在差异，从而引起超调和跟踪性能下降。

Method: DWPP从根本上重新设计了指令速度计算过程，在速度空间（v-ω平面）中制定指令速度计算，并在动态窗口内选择最接近ω=κv直线的点作为指令速度，从而明确纳入速度和加速度约束。

Result: 实验结果表明，DWPP能够避免违反约束的指令，相比传统纯追踪方法实现了更优的路径跟踪精度。该方法已集成到官方Nav2仓库并公开可用。

Conclusion: DWPP通过将速度和加速度约束明确纳入指令速度计算过程，有效解决了传统纯追踪方法的速度指令违反约束问题，显著提升了移动机器人的路径跟踪性能。

Abstract: Pure pursuit and its variants are widely used for mobile robot path tracking owing to their simplicity and computational efficiency. However, many conventional approaches do not explicitly account for velocity and acceleration constraints, resulting in discrepancies between commanded and actual velocities that result in overshoot and degraded tracking performance. To address this problem, this paper proposes dynamic window pure pursuit (DWPP), which fundamentally reformulates the command velocity computation process to explicitly incorporate velocity and acceleration constraints. Specifically, DWPP formulates command velocity computation in the velocity space (the $v$-$ω$ plane) and selects the command velocity as the point within the dynamic window that is closest to the line $ω= κv$. Experimental results demonstrate that DWPP avoids constraint-violating commands and achieves superior path-tracking accuracy compared with conventional pure pursuit methods. The proposed method has been integrated into the official Nav2 repository and is publicly available (https://github.com/ros-navigation/navigation2).

</details>


### [20] [Risk Estimation for Automated Driving](https://arxiv.org/abs/2601.15018)
*Leon Tolksdorf,Arturo Tejada,Jonas Bauernfeind,Christian Birkner,Nathan van de Wouw*

Main category: cs.RO

TL;DR: 提出一种结合碰撞概率估计与碰撞严重性概念的通用风险估计方法，用于自动驾驶车辆运动规划


<details>
  <summary>Details</summary>
Motivation: 现有风险评估方法要么依赖经验模型，要么采用严重近似，缺乏通用性和准确性。自动驾驶风险评估对运动规划和安全评估至关重要，需要同时考虑状态估计不确定性和碰撞严重性两个维度。

Method: 结合碰撞概率估计的最新进展与碰撞严重性概念，开发通用风险估计方法。允许为不同碰撞类型（如正面碰撞、侧面碰撞）分配个体严重性函数，并实现计算高效性。

Result: 提出的方法能够准确估计风险，计算效率高，适用于实时运动规划应用。提供了高斯不确定性下的示例实现代码。

Conclusion: 该方法为自动驾驶风险评估提供了通用且准确的解决方案，能够处理不同碰撞类型的严重性差异，并满足实时计算需求。

Abstract: Safety is a central requirement for automated vehicles. As such, the assessment of risk in automated driving is key in supporting both motion planning technologies and safety evaluation. In automated driving, risk is characterized by two aspects. The first aspect is the uncertainty on the state estimates of other road participants by an automated vehicle. The second aspect is the severity of a collision event with said traffic participants. Here, the uncertainty aspect typically causes the risk to be non-zero for near-collision events. This makes risk particularly useful for automated vehicle motion planning. Namely, constraining or minimizing risk naturally navigates the automated vehicle around traffic participants while keeping a safety distance based on the level of uncertainty and the potential severity of the impending collision. Existing approaches to calculate the risk either resort to empirical modeling or severe approximations, and, hence, lack generalizability and accuracy. In this paper, we combine recent advances in collision probability estimation with the concept of collision severity to develop a general method for accurate risk estimation. The proposed method allows us to assign individual severity functions for different collision constellations, such as, e.g., frontal or side collisions. Furthermore, we show that the proposed approach is computationally efficient, which is beneficial, e.g., in real-time motion planning applications. The programming code for an exemplary implementation of Gaussian uncertainties is also provided.

</details>


### [21] [CADGrasp: Learning Contact and Collision Aware General Dexterous Grasping in Cluttered Scenes](https://arxiv.org/abs/2601.15039)
*Jiyao Zhang,Zhiyuan Ma,Tianhao Wu,Zeyuan Chen,Hao Dong*

Main category: cs.RO

TL;DR: CADGrasp：一种两阶段算法，使用单视角点云输入进行通用灵巧抓取，通过预测稀疏IBS表示并优化生成高质量抓取姿态


<details>
  <summary>Details</summary>
Motivation: 解决杂乱环境中灵巧抓取的挑战，包括灵巧手的高自由度、遮挡问题、物体几何形状多样性和复杂布局导致的潜在碰撞

Method: 两阶段方法：第一阶段预测稀疏IBS（场景解耦、接触感知和碰撞感知表示）作为优化目标，使用具有体素级条件引导和力闭合分数过滤的占用扩散模型；第二阶段基于稀疏IBS开发能量函数和排序策略进行优化

Result: 在模拟和真实世界环境中进行广泛实验验证了方法的有效性，能够减少碰撞同时在不同物体和复杂场景中保持高抓取成功率

Conclusion: CADGrasp通过创新的稀疏IBS表示和两阶段优化框架，有效解决了杂乱环境中的灵巧抓取问题，在碰撞避免和抓取成功率方面表现出色

Abstract: Dexterous grasping in cluttered environments presents substantial challenges due to the high degrees of freedom of dexterous hands, occlusion, and potential collisions arising from diverse object geometries and complex layouts. To address these challenges, we propose CADGrasp, a two-stage algorithm for general dexterous grasping using single-view point cloud inputs. In the first stage, we predict sparse IBS, a scene-decoupled, contact- and collision-aware representation, as the optimization target. Sparse IBS compactly encodes the geometric and contact relationships between the dexterous hand and the scene, enabling stable and collision-free dexterous grasp pose optimization. To enhance the prediction of this high-dimensional representation, we introduce an occupancy-diffusion model with voxel-level conditional guidance and force closure score filtering. In the second stage, we develop several energy functions and ranking strategies for optimization based on sparse IBS to generate high-quality dexterous grasp poses. Extensive experiments in both simulated and real-world settings validate the effectiveness of our approach, demonstrating its capability to mitigate collisions while maintaining a high grasp success rate across diverse objects and complex scenes.

</details>


### [22] [Systematic Evaluation of Hip Exoskeleton Assistance Parameters for Enhancing Gait Stability During Ground Slip Perturbations](https://arxiv.org/abs/2601.15056)
*Maria T. Tagliaferri,Inseung Kang*

Main category: cs.RO

TL;DR: 研究系统调节髋关节外骨骼力矩大小和持续时间对滑倒扰动时稳定性的影响，发现时间参数决定辅助效果，稳定性优化参数比能量优化参数减少25.7%的全身角动量范围


<details>
  <summary>Details</summary>
Motivation: 跌倒是老年人伤害相关住院和死亡的主要原因，现有外骨骼控制器主要优化行走能量消耗而非稳定性，特定参数（如辅助大小和持续时间）对稳定性的影响尚不明确

Method: 在8名健康成年人中进行双侧髋关节外骨骼实验，系统调节力矩大小和持续时间，在滑倒扰动时使用全身角动量(WBAM)量化稳定性，并与现有能量优化控制器比较

Result: 辅助大小和持续时间存在显著交互作用，持续时间决定外骨骼辅助是稳定还是不稳定；稳定性优化参数比能量优化参数平均减少25.7%的WBAM范围；观察到显著的受试者间变异性

Conclusion: 仅优化能量消耗不足以改善步态扰动时的反应稳定性，稳定性导向的外骨骼控制应优先考虑时间参数并包含用户个性化，为个性化稳定性导向控制迈出重要一步

Abstract: Falls are the leading cause of injury related hospitalization and mortality among older adults. Consequently, mitigating age-related declines in gait stability and reducing fall risk during walking is a critical goal for assistive devices. Lower-limb exoskeletons have the potential to support users in maintaining stability during walking. However, most exoskeleton controllers are optimized to reduce the energetic cost of walking rather than to improve stability. While some studies report stability benefits with assistance, the effects of specific parameters, such as assistance magnitude and duration, remain unexplored. To address this gap, we systematically modulated the magnitude and duration of torque provided by a bilateral hip exoskeleton during slip perturbations in eight healthy adults, quantifying stability using whole-body angular momentum (WBAM). WBAM responses were governed by a significant interaction between assistance magnitude and duration, with duration determining whether exoskeleton assistance was stabilizing or destabilizing relative to not wearing the exoskeleton device. Compared to an existing energy-optimized controller, experimentally identified stability-optimal parameters reduced WBAM range by 25.7% on average. Notably, substantial inter-subject variability was observed in the parameter combinations that minimized WBAM during perturbations. We found that optimizing exoskeleton assistance for energetic outcomes alone is insufficient for improving reactive stability during gait perturbations. Stability-focused exoskeleton control should prioritize temporal assistance parameters and include user-specific personalization. This study represents an important step toward personalized, stability-focused exoskeleton control, with direct implications for improving stability and reducing fall risk in older adults.

</details>


### [23] [Influence of Operator Expertise on Robot Supervision and Intervention](https://arxiv.org/abs/2601.15069)
*Yanran Jiang,Pavan Sikka,Leimin Tian,Dana Kuliic,Cecile Paris*

Main category: cs.RO

TL;DR: 研究探索不同专业水平的用户如何监督自主机器人，分析新手、中级和专家用户在干预时机和决策策略上的差异


<details>
  <summary>Details</summary>
Motivation: 随着机器人自主性提高，监督机器人的用户群体日益多样化，需要理解不同专业水平的用户如何执行监督任务，以及这对人机团队绩效的影响

Method: 进行用户研究（N=27），参与者在模拟器中监督自主探索四个未知隧道环境的机器人，当认为机器人遇到困难时通过提供航点进行干预；通过分析交互数据和问卷回答来识别不同用户群体的模式

Result: 识别了新手、中级和专家用户在干预时机和决策策略上的不同模式

Conclusion: 用户专业水平显著影响监督机器人的方式，这对设计适应不同用户群体的机器人系统具有重要意义

Abstract: With increasing levels of robot autonomy, robots are increasingly being supervised by users with varying levels of robotics expertise. As the diversity of the user population increases, it is important to understand how users with different expertise levels approach the supervision task and how this impacts performance of the human-robot team. This exploratory study investigates how operators with varying expertise levels perceive information and make intervention decisions when supervising a remote robot. We conducted a user study (N=27) where participants supervised a robot autonomously exploring four unknown tunnel environments in a simulator, and provided waypoints to intervene when they believed the robot had encountered difficulties. By analyzing the interaction data and questionnaire responses, we identify differing patterns in intervention timing and decision-making strategies across novice, intermediate, and expert users.

</details>


### [24] [V-CAGE: Context-Aware Generation and Verification for Scalable Long-Horizon Embodied Tasks](https://arxiv.org/abs/2601.15164)
*Yaru Liu,Ao-bo Wang,Nanyang Ye*

Main category: cs.RO

TL;DR: V-CAGE是一个闭环框架，用于生成大规模、鲁棒且语义对齐的机器人操作数据集，通过上下文感知实例化、分层指令分解和VLM验证循环解决合成数据中的物理不可行性和语义不一致问题。


<details>
  <summary>Details</summary>
Motivation: 当前从合成数据学习长时程具身行为面临三个主要挑战：1）生成场景物理上不可行；2）语言驱动程序经常"成功"但未满足任务语义；3）高层指令需要接地到可执行动作序列。这些限制导致下游策略性能不佳。

Method: V-CAGE采用三层方法：1）上下文感知实例化机制，通过动态维护禁止空间区域地图确保几何一致性，防止物体穿透并保证可达配置；2）分层指令分解模块，将高层目标分解为组合动作基元；3）VLM验证循环，作为视觉批评者执行严格拒绝采样，过滤"静默失败"。

Result: 实验表明V-CAGE生成的数据集具有优越的物理和语义保真度，与非验证基线相比，显著提升了下游策略的成功率和泛化能力。

Conclusion: V-CAGE通过结合几何约束、分层规划和语义验证，有效解决了合成数据生成中的关键挑战，为大规模机器人操作学习提供了高质量的数据生成框架。

Abstract: Learning long-horizon embodied behaviors from synthetic data remains challenging because generated scenes are often physically implausible, language-driven programs frequently "succeed" without satisfying task semantics, and high-level instructions require grounding into executable action sequences. To address these limitations, we introduce V-CAGE, a closed-loop framework for generating robust, semantically aligned manipulation datasets at scale. First, we propose a context-aware instantiation mechanism that enforces geometric consistency during scene synthesis. By dynamically maintaining a map of prohibited spatial areas as objects are placed, our system prevents interpenetration and ensures reachable, conflict-free configurations in cluttered environments. Second, to bridge the gap between abstract intent and low-level control, we employ a hierarchical instruction decomposition module. This decomposes high-level goals (e.g., "get ready for work") into compositional action primitives, facilitating coherent long-horizon planning. Crucially, we enforce semantic correctness through a VLM-based verification loop. Acting as a visual critic, the VLM performs rigorous rejection sampling after each subtask, filtering out "silent failures" where code executes but fails to achieve the visual goal. Experiments demonstrate that V-CAGE yields datasets with superior physical and semantic fidelity, significantly boosting the success rate and generalization of downstream policies compared to non-verified baselines.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [25] [From Columns to Heaps: Dimensionless Similarity with PSD-Distributed Damköhler Numbers and Dual-Porosity Flow](https://arxiv.org/abs/2601.14529)
*Juan J. Segura*

Main category: physics.flu-dyn

TL;DR: 该研究建立了一个统一的无量纲框架，用于比较几何相似的化学反应多孔流动系统，重点针对颗粒尺寸分布和内部孔隙结构不同的湿法冶金堆浸过程。


<details>
  <summary>Details</summary>
Motivation: 湿法冶金堆浸过程中，颗粒尺寸分布和内部孔隙结构的差异会破坏微观相似性，影响从实验室柱实验到工业堆浸的尺度放大。需要建立一个统一的框架来理解这些差异如何影响反应转化率。

Method: 采用收缩核模型，推导了颗粒尺寸分布到颗粒尺度Damköhler数的显式变换关系，涵盖外部膜控制、内部扩散控制和混合控制三种情况。将双孔隙水文模型与反应动力学耦合，引入描述孔隙间交换的无量纲参数组。

Result: 建立了颗粒尺寸分布到Damköhler数分布的映射关系，揭示了扩散控制浸出对颗粒尺寸分布尾部和双孔隙结构比膜控制浸出更为敏感。确定了确保实验室柱与工业堆相似性所需匹配的无量纲参数组。

Conclusion: 该框架为湿法冶金柱试验解释提供了实用工作流程，结合示踪剂停留时间分布校准和考虑颗粒尺寸分布的动力学拟合，明确了确保实验室与工业尺度相似性的关键无量纲参数。

Abstract: This work develops a unified, dimensionless framework for comparing geometrically similar reacting porous-flow systems across scale, with emphasis on hydrometallurgical heap leaching, when particle size distribution (PSD) and intraparticle pore structure differ. Under dynamic similarity, the dimensionless liquid residence-time distribution (RTD) is identical, but differences in PSD and internal porosity break microscopic similarity. Using the shrinking-core model (SCM), the analysis shows how a PSD in particle diameter maps to a distribution of particle-scale Damköhler numbers that governs heap-averaged conversion.
  Explicit PSD to Damköhler transformations are derived for (i) external film control, (ii) intraparticle diffusion control, and (iii) mixed control via additive rates. Dual-porosity hydrology relevant to sedimentary or strongly stratified ores is then incorporated by coupling SCM kinetics to mobile and immobile liquid domains, introducing additional dimensionless groups that describe interporosity exchange. Two numerical examples map a lognormal PSD into film- and diffusion-controlled Damköhler distributions and compare column/heap conversion for different PSDs. A practical workflow is outlined for hydrometallurgical column-test interpretation, combining tracer RTD calibration with PSD-aware kinetic fitting in dimensionless time. The framework clarifies why diffusion-controlled leaching is far more sensitive to PSD tails and dual-porosity structure than film-controlled leaching, and it identifies the compact set of dimensionless groups that must be matched to ensure similarity between laboratory columns and industrial heaps.

</details>


### [26] [Model-Driven Conditional Fourier Neural Operator for Spectrum-Consistent Synthetic Turbulence Generation](https://arxiv.org/abs/2601.14745)
*Hongyuan Lin,Shizhao Wang*

Main category: physics.flu-dyn

TL;DR: 提出MD-CFNO模型用于合成湍流生成，结合模型驱动数据构建、条件随机生成和复合损失函数，在宽参数范围内生成谱一致的湍流场。


<details>
  <summary>Details</summary>
Motivation: 谱一致的合成湍流对计算流体力学入流边界构造和宽频气动噪声预测至关重要。现有数据驱动方法依赖昂贵数据集、泛化能力有限，且在空间域训练易出现回归到均值问题。

Method: 提出MD-CFNO模型，包含三个组件：1) 模型驱动数据构建策略提高可解释性和泛化参数范围；2) 将条件随机生成集成到傅里叶神经算子架构中减轻回归到均值效应；3) 引入复合损失函数加速收敛并增强谱保真度。

Result: MD-CFNO能够生成谱一致的合成湍流，在插值和分布外外推条件下均表现出鲁棒性能，验证了傅里叶神经算子在条件生成中的优势。

Conclusion: 该研究为合成湍流提供了模型驱动视角，展示了傅里叶神经算子在条件生成中的优势，为宽参数范围内的湍流生成提供了有效解决方案。

Abstract: This short note proposes a model-driven conditional Fourier neural operator (MD-CFNO) for synthetic turbulence generation. Spectrum-consistent synthetic turbulence is essential for inflow boundary construction in computational fluid dynamics and for broadband aeroacoustic noise prediction. Data-driven turbulence synthesis with neural networks has emerged as a promising direction. However, generating flow fields that match prescribed energy spectra across wide physical regimes remains challenging. Existing data-driven methods typically rely on expensive reliable datasets with limited generalization and are prone to regression-to-the-mean when trained in the spatial domain. To address these issues, the MD-CFNO is proposed with three components: a model-driven data construction strategy is adopted to improve interpretability and broaden the generalizable parameter regime; conditional stochastic generation is integrated into the Fourier neural operator architecture to alleviate regression-to-the-mean effects; and a composite loss is introduced to accelerate convergence and enhance spectral fidelity. Results show that the proposed MD-CFNO generates spectrum-consistent synthetic turbulence and achieves robust performance under both interpolation and out-of-distribution extrapolation conditions. This study provides a model-driven perspective on synthetic turbulence, showing the advantages of Fourier neural operators for conditional generation.

</details>


### [27] [On the testing of grain shape corrections to bedload transport equations with grain-resolved numerical simulations](https://arxiv.org/abs/2601.14892)
*Yulan Chen,Orencio Durán,Thomas Pähtz*

Main category: physics.flu-dyn

TL;DR: 本文指出Zhang等人(2025)验证颗粒形状修正床载输运方程的方法存在缺陷：他们通过将无滑移边界条件从实际颗粒表面移到内部虚拟表面来近似Navier滑移条件，但这种近似仅在边界层厚度远大于滑移长度时才成立，而作者模拟中并非如此。


<details>
  <summary>Details</summary>
Motivation: 质疑Zhang等人(2025)验证颗粒形状修正床载输运方程方法的有效性。作者认为Zhang等人通过改变颗粒表面边界条件来独立变化沉降阻力系数的方法存在根本性缺陷，无法正确模拟Navier滑移条件，因此其验证结果不可靠。

Method: 1) 理论分析：指出Zhang等人的近似方法仅在边界层厚度远大于滑移长度时才成立；2) 独立DNS-DEM模拟：使用相同水动力条件进行颗粒沉降模拟，直接比较Navier滑移球体的沉降阻力系数；3) 替代模型：提出基于虚拟颗粒尺寸而非实际颗粒尺寸的零假设模型，无需颗粒形状修正即可解释Zhang等人的全部数值数据。

Result: 1) 理论分析表明Zhang等人的近似条件在其模拟中不满足；2) DNS-DEM沉降模拟显示Zhang等人的方法显著高估了Navier滑移球体的沉降阻力系数；3) 提出的零假设模型能够解释Zhang等人的全部数值数据，表明其颗粒形状修正可能是不必要的。

Conclusion: Zhang等人验证颗粒形状修正床载输运方程的方法存在根本缺陷：其边界条件近似不适用于模拟的物理条件，导致沉降阻力系数被高估。因此，他们的模拟结果不能支持颗粒形状修正的有效性，其数据可以用更简单的零假设模型解释，无需引入颗粒形状修正。

Abstract: Using grain-resolved LES-DEM simulations, Zhang et al. (J. Geophys. Res. Earth Surf. 130, e2024JF007937, 2025) aimed to validate a grain-shape-corrected bedload transport equation proposed earlier by the same group. It states that grain shape effects are captured through a modified Shields number that depends, among others, on the drag coefficient, $C_{D_\mathrm{settle}}$, determined from the force balance for a grain settling in a fluid at rest. To independently vary $C_{D_\mathrm{settle}}$ in their simulations, the authors changed the boundary conditions on the grains' surfaces: By artificially shifting the locations of the no-slip conditions from the actual grain surface to a virtual surface a distance $l$ into the grain interior, they hoped to well approximate Navier-slip conditions with a slip length $l$. Here, we argue that this approximation is appropriate only if the thickness of the boundary layer that forms around the virtual surface is much larger than $l$, which we demonstrate was not the case for the authors' simulations. In particular, using independent DNS-DEM grain settling simulations for the same hydrodynamic conditions, we directly show that this approximation substantially overestimates the value of $C_{D_\mathrm{settle}}$ of a Navier-slip sphere. This implies that the conditions created with their artificial method do not correspond to physically realistic scenarios and therefore do not support the authors' grain shape correction. To support this conclusion, we demonstrate that their entire numerical data can be alternatively explained by a simple null hypothesis model, without grain shape correction, based on the virtual-grain rather than the actual-grain size.

</details>


### [28] [Maximal spreading of impacting viscoelastic droplets](https://arxiv.org/abs/2601.15246)
*Orr Avni,Dongyue Wang,Mithun Ravisankar,Roberto Zenit*

Main category: physics.flu-dyn

TL;DR: 研究粘弹性液滴撞击固体表面时的最大铺展直径，发现当德博拉数接近1时，粘弹性显著降低最大铺展直径达40%，提出包含粘弹性修正因子的理论模型。


<details>
  <summary>Details</summary>
Motivation: 牛顿流体在固体表面的撞击和铺展行为已有充分研究，但粘弹性如何单独影响最大铺展直径尚不清楚。需要揭示粘弹性液滴铺展动力学的物理机制。

Method: 提出简化的理论模型，并通过撞击实验验证。实验使用粘度、表面张力相近但松弛时间不同的流体，测量不同德博拉数下的最大铺展直径。

Result: 粘弹性液滴遵循与牛顿流体相似的渐近标度律，但当德博拉数接近1时，最大铺展直径明显偏离牛顿行为，最大可降低40%。模型成功预测了最大铺展的减小以及粘弹性效应最显著的位置和大小。

Conclusion: 通过引入单一修正因子扩展经典能量平衡方程，模型能准确捕捉粘弹性对最大铺展的影响，为超越纯牛顿流体的撞击模型提供了理论基础。

Abstract: Droplet impact and spreading on solid substrates are well understood for Newtonian fluids, yet how viscoelasticity alone modifies the maximal spreading remains unclear. To discern the physical mechanisms governing the spreading dynamics, we present a simplified theoretical model, validated by impact experiments, to quantify how fluid elasticity modifies the maximal spreading of impacting droplets. Experiments were performed using fluids within a narrow range of viscosity and surface tension, but varying relaxation time. While following similar asymptotic scalings as Newtonian droplets, the maximum diameter for viscoelastic droplets exhibits a clear deviation from Newtonian behaviour only when the Deborah number is of order unity. The maximum spread diameter is reduced by as much as 40% from the expected value for Newtonian fluid. These results support the central prediction of our model: an extension of classical energy balance that incorporates viscoelastic effects through a single correction factor. The model captures the observed reduction in maximal spreading and predicts both the location and magnitude of the most substantial viscoelastic effects, providing a basis for extending impact models beyond purely Newtonian fluids.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [29] [GCG Attack On A Diffusion LLM](https://arxiv.org/abs/2601.14266)
*Ruben Neyroud,Sam Corley*

Main category: cs.LG

TL;DR: 探索GCG风格对抗提示攻击在扩散语言模型LLaDA上的适用性，评估多种攻击变体，为扩散语言模型的鲁棒性研究提供初步见解


<details>
  <summary>Details</summary>
Motivation: 虽然大多数LLM是自回归的，但基于扩散的LLM最近成为替代生成方法。GCG攻击在自回归模型上已被证明有效，但其在扩散语言模型上的适用性尚未充分探索

Method: 对开源扩散LLM LLaDA进行GCG风格对抗提示攻击的探索性研究，评估包括前缀扰动和后缀对抗生成在内的多种攻击变体，使用AdvBench数据集中的有害提示进行评估

Result: 研究提供了关于扩散语言模型鲁棒性和攻击面的初步见解，揭示了GCG攻击在扩散模型上的适用性情况

Conclusion: 研究结果推动了在该场景下开发替代优化和评估策略的需求，为扩散语言模型的对抗分析提供了基础

Abstract: While most LLMs are autoregressive, diffusion-based LLMs have recently emerged as an alternative method for generation. Greedy Coordinate Gradient (GCG) attacks have proven effective against autoregressive models, but their applicability to diffusion language models remains largely unexplored. In this work, we present an exploratory study of GCG-style adversarial prompt attacks on LLaDA (Large Language Diffusion with mAsking), an open-source diffusion LLM. We evaluate multiple attack variants, including prefix perturbations and suffix-based adversarial generation, on harmful prompts drawn from the AdvBench dataset. Our study provides initial insights into the robustness and attack surface of diffusion language models and motivates the development of alternative optimization and evaluation strategies for adversarial analysis in this setting.

</details>


### [30] [Divide and Refine: Enhancing Multimodal Representation and Explainability for Emotion Recognition in Conversation](https://arxiv.org/abs/2601.14274)
*Anh-Tuan Mai,Cam-Van Thi Nguyen,Duc-Trong Le*

Main category: cs.LG

TL;DR: 提出DnR（Divide and Refine）两阶段框架，通过显式分解模态为独特性、冗余性和协同性，并针对性优化，提升多模态对话情感识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态情感识别方法在整合模态信号时面临挑战，需要同时利用模态特异性信息、跨模态共享信息和模态组合产生的交互作用。现有对比学习和增强方法往往忽视数据准备对保留这些信息成分的影响，直接对原始输入或融合嵌入应用增强会模糊模态独特信号与跨模态信号的边界。

Method: 提出两阶段框架DnR：1) Divide阶段：将每个模态显式分解为独特性（unique）、成对冗余性（pairwise redundancy）和协同性（synergy）三个成分；2) Refine阶段：设计针对性目标函数增强这些成分的信息量，同时保持其不同作用。精炼后的表示可与多种多模态管道即插即用兼容。

Result: 在IEMOCAP和MELD数据集上的大量实验表明，DnR框架在多个MERC骨干模型上均带来一致性能提升，证明了显式分解、精炼和重组多模态表示作为情感识别原则性策略的有效性。

Conclusion: 通过显式分解模态为独特性、冗余性和协同性成分，并针对性优化这些成分，DnR框架能够更有效地整合多模态信号，为多模态对话情感识别提供了一种原则性策略，在多个基准数据集和骨干模型上均取得显著改进。

Abstract: Multimodal emotion recognition in conversation (MERC) requires representations that effectively integrate signals from multiple modalities. These signals include modality-specific cues, information shared across modalities, and interactions that emerge only when modalities are combined. In information-theoretic terms, these correspond to \emph{unique}, \emph{redundant}, and \emph{synergistic} contributions. An ideal representation should leverage all three, yet achieving such balance remains challenging. Recent advances in contrastive learning and augmentation-based methods have made progress, but they often overlook the role of data preparation in preserving these components. In particular, applying augmentations directly to raw inputs or fused embeddings can blur the boundaries between modality-unique and cross-modal signals. To address this challenge, we propose a two-phase framework \emph{\textbf{D}ivide and \textbf{R}efine} (\textbf{DnR}). In the \textbf{Divide} phase, each modality is explicitly decomposed into uniqueness, pairwise redundancy, and synergy. In the \textbf{Refine} phase, tailored objectives enhance the informativeness of these components while maintaining their distinct roles. The refined representations are plug-and-play compatible with diverse multimodal pipelines. Extensive experiments on IEMOCAP and MELD demonstrate consistent improvements across multiple MERC backbones. These results highlight the effectiveness of explicitly dividing, refining, and recombining multimodal representations as a principled strategy for advancing emotion recognition. Our implementation is available at https://github.com/mattam301/DnR-WACV2026

</details>


### [31] [Quality or Quantity? Error-Informed Selective Online Learning with Gaussian Processes in Multi-Agent Systems: Extended Version](https://arxiv.org/abs/2601.14275)
*Zewen Yang,Xiaobing Dai,Jiajun Cheng,Yulong Huang,Peng Shi*

Main category: cs.LG

TL;DR: 该论文提出了首个分布式高斯过程回归的选择性在线学习框架EIGP，通过评估邻居模型质量进行选择性合作，强调质量优于数量，并开发了加速预测的gEIGP和提高精度的aEIGP算法。


<details>
  <summary>Details</summary>
Motivation: 在多智能体分布式学习中，揭示无差别包含所有模型进行联合预测的非理性，强调在合作学习中质量优于数量的重要性，需要开发能够选择性整合高质量模型的框架。

Method: 提出分布式误差感知高斯过程（EIGP）框架，包含选择函数评估邻居模型质量，选择预测误差较小的高质量GP模型；嵌入贪婪算法gEIGP加速预测和自适应算法aEIGP提高精度；结合误差感知量化项迭代和数据删除策略实现实时学习操作。

Result: 数值模拟验证了所提方法的有效性，展示了其在不同基准测试中优于现有最先进的分布式GP方法，实现了更高效和准确的预测性能。

Conclusion: 该研究证明了在分布式高斯过程回归中实施选择性合作策略的重要性，EIGP框架通过质量优先的选择机制显著提升了学习效率和预测性能，为多智能体系统提供了有效的在线学习解决方案。

Abstract: Effective cooperation is pivotal in distributed learning for multi-agent systems, where the interplay between the quantity and quality of the machine learning models is crucial. This paper reveals the irrationality of indiscriminate inclusion of all models on agents for joint prediction, highlighting the imperative to prioritize quality over quantity in cooperative learning. Specifically, we present the first selective online learning framework for distributed Gaussian process (GP) regression, namely distributed error-informed GP (EIGP), that enables each agent to assess its neighboring collaborators, using the proposed selection function to choose the higher quality GP models with less prediction errors. Moreover, algorithmic enhancements are embedded within the EIGP, including a greedy algorithm (gEIGP) for accelerating prediction and an adaptive algorithm (aEIGP) for improving prediction accuracy. In addition, approaches for fast prediction and model update are introduced in conjunction with the error-informed quantification term iteration and a data deletion strategy to achieve real-time learning operations. Numerical simulations are performed to demonstrate the effectiveness of the developed methodology, showcasing its superiority over the state-of-the-art distributed GP methods with different benchmarks.

</details>


### [32] [Which Quantization Should I Use? A Unified Evaluation of llama.cpp Quantization on Llama-3.1-8B-Instruct](https://arxiv.org/abs/2601.14277)
*Uygar Kurt*

Main category: cs.LG

TL;DR: 对llama.cpp量化格式的统一实证研究，评估Llama-3.1-8B-Instruct模型在3-8位K-quant和传统格式下的性能表现，为实际应用提供量化方案选择指南


<details>
  <summary>Details</summary>
Motivation: 量化技术能降低大语言模型的部署难度，减少内存使用并提高在受限硬件上的运行可行性，但现有量化格式评估不一致，难以在实际应用中选择合适的量化方案

Method: 对Llama-3.1-8B-Instruct模型（FP16，GGUF格式）进行统一的实证研究，覆盖3-8位K-quant和传统量化格式，评估下游任务性能（推理、知识、指令跟随、真实性基准），同时测量困惑度、CPU吞吐量（预填充/解码）、模型大小、压缩率和量化时间

Result: 提供了全面的量化格式性能评估数据，包括不同位宽下的任务表现、计算效率和存储效率指标，揭示了量化方案在精度与效率之间的权衡关系

Conclusion: 本研究为选择llama.cpp量化方案提供了实用的指导，帮助用户根据预期用途和资源预算做出明智的、上下文感知的决策

Abstract: Quantization is a practical technique for making large language models easier to deploy by reducing the precision used to store and operate on model weights. This can lower memory use and improve runtime feasibility on constrained hardware, which is especially relevant for users running models locally. Quantization in llama.cpp enables large language models to run on commodity hardware, but available formats are often evaluated inconsistently, making it hard to choose among schemes. We present a unified empirical study of the llama.cpp quantization on a single modern model, Llama-3.1-8B-Instruct (FP16, GGUF), covering 3-8 bit K-quant and legacy formats. We evaluate downstream task performance across standard reasoning, knowledge, instruction-following, and truthfulness benchmarks, and also measure perplexity and CPU throughput (prefill/decoding) alongside model size, compression, and quantization time. Ultimately, this work is a practical guide for choosing a llama.cpp quantization scheme, helping readers make informed, context-aware decisions for their intended use and resource budget.

</details>


### [33] [On the Limits of Learned Importance Scoring for KV Cache Compression](https://arxiv.org/abs/2601.14279)
*Brady Steele*

Main category: cs.LG

TL;DR: SIP（推测重要性预测）是一种1.7M参数的KV缓存压缩方法，但未能超越简单基线（如随机选择、位置启发式），表明KV表示中用于重要性预测的边际信息有限。


<details>
  <summary>Details</summary>
Motivation: 研究通过学习方法来压缩KV缓存，以提升推理效率，探索KV表示中是否包含足够信息来预测token重要性。

Method: 提出Speculative Importance Prediction（SIP），一个1.7M参数的非查询感知评分器，仅从KV表示预测token重要性，采用多视野前瞻和交叉注意力等复杂架构。

Result: SIP在5个种子、4个保留级别、3个任务上均未超越简单基线（包括随机选择）。位置启发式（保留前4+最后N个token）和预填充注意力表现相当或更好。

Conclusion: KV表示中除了位置和预填充注意力信息外，用于重要性预测的边际信息有限；未来查询与生成轨迹的循环依赖增加了学习难度；简单启发式方法已足够有效。

Abstract: We investigate learned KV cache compression through Speculative Importance Prediction (SIP), a 1.7M parameter non-query-aware scorer that predicts token importance from KV representations alone. Despite architectural sophistication (multi-horizon lookahead, cross-attention), SIP does not outperform simple baselines, including random selection, across 5 seeds, 4 retention levels, and 3 tasks. Key findings: (1) position-based heuristics (keep first 4 + last N tokens) match or exceed learned approaches; (2) prefill attention provides equivalent signal to complex learned scorers; (3) marginal information in KV representations beyond position and prefill attention appears limited for importance prediction. We hypothesize that circular dependence between future queries and generation trajectories contributes to this difficulty.

</details>


### [34] [Beyond Affinity: A Benchmark of 1D, 2D, and 3D Methods Reveals Critical Trade-offs in Structure-Based Drug Design](https://arxiv.org/abs/2601.14283)
*Kangyu Zheng,Kai Zhang,Jiale Tan,Xuehan Chen,Yingzhou Lu,Zaixi Zhang,Lichao Sun,Marinka Zitnik,Tianfan Fu,Zhiding Liang*

Main category: cs.LG

TL;DR: 建立跨算法基准评估15个SBDD模型，发现3D结构模型在结合亲和力上表现最佳但化学有效性不足，1D模型化学指标可靠但结合亲和力有限，2D模型提供平衡性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于结构的药物设计领域存在搜索算法、深度生成模型和强化学习三类主要算法，但缺乏跨算法类别的系统性比较。现有研究通常只比较同一算法类别内的模型，需要建立基准来评估不同算法基础模型的性能差异。

Method: 建立基准评估框架，对15个跨算法类别的模型进行系统性评估。评估指标包括生成分子的药物特性、与指定靶蛋白的对接亲和力以及对接构象。特别强调将对接函数作为黑盒预言机，将1D/2D配体中心方法应用于SBDD。

Result: 评估揭示了不同模型类别的明显模式：3D结构模型在结合亲和力方面表现优异，但在化学有效性和构象质量方面存在不一致性；1D模型在标准分子指标上表现可靠，但很少达到最佳结合亲和力；2D模型提供平衡性能，保持高化学有效性的同时获得中等结合分数。

Conclusion: 通过跨多个蛋白靶点的详细分析，识别了各模型类别的关键改进领域，为研究人员结合不同方法的优势同时解决其局限性提供了见解。强调1D/2D配体中心方法可通过对接黑盒应用于SBDD，为未来SBDD模型设计提供建议。

Abstract: Currently, the field of structure-based drug design is dominated by three main types of algorithms: search-based algorithms, deep generative models, and reinforcement learning. While existing works have typically focused on comparing models within a single algorithmic category, cross-algorithm comparisons remain scarce. In this paper, to fill the gap, we establish a benchmark to evaluate the performance of fifteen models across these different algorithmic foundations by assessing the pharmaceutical properties of the generated molecules and their docking affinities and poses with specified target proteins. We highlight the unique advantages of each algorithmic approach and offer recommendations for the design of future SBDD models. We emphasize that 1D/2D ligand-centric drug design methods can be used in SBDD by treating the docking function as a black-box oracle, which is typically neglected. Our evaluation reveals distinct patterns across model categories. 3D structure-based models excel in binding affinities but show inconsistencies in chemical validity and pose quality. 1D models demonstrate reliable performance in standard molecular metrics but rarely achieve optimal binding affinities. 2D models offer balanced performance, maintaining high chemical validity while achieving moderate binding scores. Through detailed analysis across multiple protein targets, we identify key improvement areas for each model category, providing insights for researchers to combine strengths of different approaches while addressing their limitations. All the code that are used for benchmarking is available in https://github.com/zkysfls/2025-sbdd-benchmark

</details>


### [35] [A Comparison of Polynomial-Based Tree Clustering Methods](https://arxiv.org/abs/2601.14285)
*Pengyu Liu,Mariel Vázquez,Nataša Jonoska*

Main category: cs.LG

TL;DR: 比较基于树多项式的不同距离度量在树聚类中的性能，并实现两种基本的自编码器模型用于树聚类


<details>
  <summary>Details</summary>
Motivation: 生命科学中树结构数据日益增多（如系统发育、RNA二级结构），需要新的树结构数据分析方法。树多项式提供了一种计算高效、可解释且全面的树结构编码方式，但需要评估不同距离度量在聚类中的性能

Method: 1) 比较基于树多项式的不同距离度量在树聚类方法中的性能；2) 实现两种基本的自编码器模型用于树聚类；3) 使用树区分多项式作为基础表示

Result: 基于条目级归一化距离的距离方法在所有比较方法中具有最高的聚类准确率

Conclusion: 树多项式结合适当的距离度量（特别是条目级归一化距离）为树结构数据分析提供了有效的聚类方法，在生命科学树结构分析中具有应用价值

Abstract: Tree structures appear in many fields of the life sciences, including phylogenetics, developmental biology and nucleic acid structures. Trees can be used to represent RNA secondary structures, which directly relate to the function of non-coding RNAs. Recent developments in sequencing technology and artificial intelligence have yielded numerous biological data that can be represented with tree structures. This requires novel methods for tree structure data analytics. Tree polynomials provide a computationally efficient, interpretable and comprehensive way to encode tree structures as matrices, which are compatible with most data analytics tools. Machine learning methods based on the Canberra distance between tree polynomials have been introduced to analyze phylogenies and nucleic acid structures. In this paper, we compare the performance of different distances in tree clustering methods based on a tree distinguishing polynomial. We also implement two basic autoencoder models for clustering trees using the polynomial. We find that the distance based methods with entry-level normalized distances have the highest clustering accuracy among the compared methods.

</details>


### [36] [Gradient Structure Estimation under Label-Only Oracles via Spectral Sensitivity](https://arxiv.org/abs/2601.14300)
*Jun Liu,Leo Yu Zhang,Fengpeng Li,Isao Echizen,Jiantao Zhou*

Main category: cs.LG

TL;DR: 该论文提出了一种新的硬标签黑盒攻击框架，通过零查询频域初始化和模式驱动优化策略，显著提高了攻击成功率和查询效率，并在多种数据集和防御机制上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 硬标签黑盒设置（仅能观测到top-1预测标签）是理解模型行为的重要反馈模型，但面临从离散响应中恢复梯度信息的核心挑战。现有攻击方法缺乏统一的理论解释，需要从第一性原理出发重新理解硬标签攻击的本质。

Method: 提出统一理论视角，将现有符号翻转硬标签攻击解释为隐式近似真实损失梯度符号。基于此提出新攻击框架：1）零查询频域初始化，在温和假设下获得比随机基线更高的期望余弦相似度；2）模式驱动优化策略，比现有结构化搜索方法获得更低的查询复杂度。

Result: 在CIFAR-10、ImageNet、ObjectNet数据集上验证，涵盖标准模型、对抗训练模型、商业API和CLIP模型。方法在攻击成功率和查询效率上均超越SOTA硬标签攻击，尤其在低查询区域表现突出。还能有效泛化到损坏数据、生物医学数据集和密集预测任务，并能完全规避Blacklight防御（0%检测率）。

Conclusion: 通过统一理论视角重新解释硬标签攻击为梯度符号恢复问题，提出的新攻击框架在理论和实证上都优于现有方法，为硬标签黑盒设置下的模型理解和安全评估提供了更有效的工具。

Abstract: Hard-label black-box settings, where only top-1 predicted labels are observable, pose a fundamentally constrained yet practically important feedback model for understanding model behavior. A central challenge in this regime is whether meaningful gradient information can be recovered from such discrete responses. In this work, we develop a unified theoretical perspective showing that a wide range of existing sign-flipping hard-label attacks can be interpreted as implicitly approximating the sign of the true loss gradient. This observation reframes hard-label attacks from heuristic search procedures into instances of gradient sign recovery under extremely limited feedback. Motivated by this first-principles understanding, we propose a new attack framework that combines a zero-query frequency-domain initialization with a Pattern-Driven Optimization (PDO) strategy. We establish theoretical guarantees demonstrating that, under mild assumptions, our initialization achieves higher expected cosine similarity to the true gradient sign compared to random baselines, while the proposed PDO procedure attains substantially lower query complexity than existing structured search approaches. We empirically validate our framework through extensive experiments on CIFAR-10, ImageNet, and ObjectNet, covering standard and adversarially trained models, commercial APIs, and CLIP-based models. The results show that our method consistently surpasses SOTA hard-label attacks in both attack success rate and query efficiency, particularly in low-query regimes. Beyond image classification, our approach generalizes effectively to corrupted data, biomedical datasets, and dense prediction tasks. Notably, it also successfully circumvents Blacklight, a SOTA stateful defense, resulting in a $0\%$ detection rate. Our code will be released publicly soon at https://github.com/csjunjun/DPAttack.git.

</details>


### [37] [Layer-adaptive Expert Pruning for Pre-Training of Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2601.14327)
*YuanLab. ai,Shawn Wu,Jiangang Luo,Tong Yu,Darcy Chen,Sean Wang,Xudong Zhao,Louie Li,Claire Wang,Hunter He,Carol Wang,Allen Wang*

Main category: cs.LG

TL;DR: 提出LAEP算法，在MoE LLM预训练阶段自适应剪枝未充分利用的专家并重新组织专家分布，显著提升训练效率并减少参数


<details>
  <summary>Details</summary>
Motivation: MoE LLMs虽然通过减少激活参数获得优越精度，但其预训练阶段存在专家利用不足和训练效率有限的计算瓶颈

Method: 提出层自适应专家剪枝(LAEP)算法，在预训练阶段根据token分布统计选择性剪枝未充分利用的专家，并跨计算设备重新组织专家分布

Result: LAEP有效减少模型大小并显著提升预训练效率。在从头预训练1010B Base模型时，训练效率提升48.3%，参数减少33.3%，同时在多个领域保持优异性能

Conclusion: LAEP算法成功解决了MoE LLM预训练中的计算瓶颈问题，通过自适应专家剪枝实现了训练效率的大幅提升和参数的有效减少

Abstract: Although Mixture-of-Experts (MoE) Large Language Models (LLMs) deliver superior accuracy with a reduced number of active parameters, their pre-training represents a significant computationally bottleneck due to underutilized experts and limited training efficiency. This work introduces a Layer-Adaptive Expert Pruning (LAEP) algorithm designed for the pre-training stage of MoE LLMs. In contrast to previous expert pruning approaches that operate primarily in the post-training phase, the proposed algorithm enhances training efficiency by selectively pruning underutilized experts and reorganizing experts across computing devices according to token distribution statistics. Comprehensive experiments demonstrate that LAEP effectively reduces model size and substantially improves pre-training efficiency. In particular, when pre-training the 1010B Base model from scratch, LAEP achieves a 48.3\% improvement in training efficiency alongside a 33.3% parameter reduction, while still delivering excellent performance across multiple domains.

</details>


### [38] [Hierarchical Contextual Uplift Bandits for Catalog Personalization](https://arxiv.org/abs/2601.14333)
*Anupam Agrawal,Rajesh Mohanty,Shamik Bhattacharjee,Abhimanyu Mittal*

Main category: cs.LG

TL;DR: 论文提出了一种分层上下文提升赌博机框架，用于解决幻想体育平台中动态环境下的个性化推荐问题，通过动态调整上下文粒度并结合提升建模，显著提高了推荐质量和收入。


<details>
  <summary>Details</summary>
Motivation: 传统上下文赌博机算法在幻想体育等动态环境中表现不佳，用户行为快速变化和外部因素导致的奖励分布剧烈波动需要频繁重新训练。需要一种能够适应动态环境、缓解冷启动问题并提升推荐效果的解决方案。

Method: 提出分层上下文提升赌博机框架：1）动态调整上下文粒度，从广泛的系统级洞察到详细的用户特定上下文；2）利用上下文相似性促进有效的策略迁移；3）整合提升建模原则以优化推荐效果。

Result: 在Dream11幻想体育平台进行大规模A/B测试显示：1）推荐质量显著提升；2）获得0.4%的收入改善；3）用户满意度指标优于当前生产系统。2025年5月部署为默认目录个性化系统后，进一步观察到0.5%的收入提升。

Conclusion: 分层上下文提升赌博机框架有效解决了动态环境中的个性化推荐挑战，通过动态上下文粒度调整和提升建模的结合，显著改善了推荐效果和商业指标，已成功部署到生产环境。

Abstract: Contextual Bandit (CB) algorithms are widely adopted for personalized recommendations but often struggle in dynamic environments typical of fantasy sports, where rapid changes in user behavior and dramatic shifts in reward distributions due to external influences necessitate frequent retraining. To address these challenges, we propose a Hierarchical Contextual Uplift Bandit framework. Our framework dynamically adjusts contextual granularity from broad, system-wide insights to detailed, user-specific contexts, using contextual similarity to facilitate effective policy transfer and mitigate cold-start issues. Additionally, we integrate uplift modeling principles into our approach. Results from large-scale A/B testing on the Dream11 fantasy sports platform show that our method significantly enhances recommendation quality, achieving a 0.4% revenue improvement while also improving user satisfaction metrics compared to the current production system. We subsequently deployed this system to production as the default catalog personalization system in May 2025 and observed a further 0.5% revenue improvement.

</details>


### [39] [VJEPA: Variational Joint Embedding Predictive Architectures as Probabilistic World Models](https://arxiv.org/abs/2601.14354)
*Yongchao Huang*

Main category: cs.LG

TL;DR: VJEPA是JEPA的概率化扩展，通过变分目标学习未来潜在状态的预测分布，统一了表示学习与预测状态表示和贝叶斯滤波，为高维噪声环境中的可扩展、鲁棒、不确定性感知规划提供了基础框架。


<details>
  <summary>Details</summary>
Motivation: 现有JEPA采用确定性回归目标，掩盖了概率语义，限制了其在随机控制中的应用。需要一种概率化扩展来支持不确定性估计和鲁棒规划。

Method: 提出变分JEPA(VJEPA)，通过变分目标学习未来潜在状态的预测分布；进一步提出贝叶斯JEPA(BJEPA)，将预测信念分解为学习到的动态专家和模块化先验专家，通过专家乘积实现零样本任务迁移和约束满足。

Result: 理论证明VJEPA表示可作为最优控制的充分信息状态，无需像素重建，并提供避免崩溃的形式保证。实验表明VJEPA和BJEPA能成功过滤高方差干扰，而生成基线会出现表示崩溃。

Conclusion: VJEPA为高维噪声环境中的可扩展、鲁棒、不确定性感知规划提供了基础框架，统一了表示学习与预测状态表示和贝叶斯滤波，同时保持对观测的似然无关性。

Abstract: Joint Embedding Predictive Architectures (JEPA) offer a scalable paradigm for self-supervised learning by predicting latent representations rather than reconstructing high-entropy observations. However, existing formulations rely on \textit{deterministic} regression objectives, which mask probabilistic semantics and limit its applicability in stochastic control. In this work, we introduce \emph{Variational JEPA (VJEPA)}, a \textit{probabilistic} generalization that learns a predictive distribution over future latent states via a variational objective. We show that VJEPA unifies representation learning with Predictive State Representations (PSRs) and Bayesian filtering, establishing that sequential modeling does not require autoregressive observation likelihoods. Theoretically, we prove that VJEPA representations can serve as sufficient information states for optimal control without pixel reconstruction, while providing formal guarantees for collapse avoidance. We further propose \emph{Bayesian JEPA (BJEPA)}, an extension that factorizes the predictive belief into a learned dynamics expert and a modular prior expert, enabling zero-shot task transfer and constraint (e.g. goal, physics) satisfaction via a Product of Experts. Empirically, through a noisy environment experiment, we demonstrate that VJEPA and BJEPA successfully filter out high-variance nuisance distractors that cause representation collapse in generative baselines. By enabling principled uncertainty estimation (e.g. constructing credible intervals via sampling) while remaining likelihood-free regarding observations, VJEPA provides a foundational framework for scalable, robust, uncertainty-aware planning in high-dimensional, noisy environments.

</details>


### [40] [Adaptive KDE for Real-Time Thresholding: Prioritized Queues for Financial Crime Investigation](https://arxiv.org/abs/2601.14473)
*Danny Butvinik,Nana Boateng,Achi Hackmon*

Main category: cs.LG

TL;DR: 提出一种基于在线自适应核密度估计的风险评分流队列分配方法，通过尾部质量曲线满足容量约束，利用跨带宽检测的密度谷值稳定阈值，实现无标签、多队列、实时处理


<details>
  <summary>Details</summary>
Motivation: 传统基于top-K或手动调优阈值的方法在风险评分流队列分配中存在局限性，需要一种能够适应动态变化、满足容量约束且减少阈值抖动的自动化方法

Method: 1) 对评分流拟合在线自适应核密度估计；2) 将密度转换为尾部质量曲线以满足容量约束；3) 检测跨带宽的持久密度谷值作为稳定阈值；4) 支持滑动窗口或指数遗忘的实时处理

Result: 在合成、漂移、多模态数据流上，该方法在保持容量依从性的同时显著减少了阈值抖动，每个事件更新成本为O(G)，每个活动使用常数内存

Conclusion: 该方法提供了一种无标签、自适应、稳定的风险评分流队列分配方案，能够有效处理动态变化的数据流并满足实际容量约束

Abstract: We study the problem of converting a stream of risk scores into one or more review queues under explicit intake constraints[cite: 6]. Instead of top-$K$ or manually tuned cutoffs, we fit an online adaptive kernel density to the score stream, transform the density into a tail-mass curve to meet capacity, and ``snap'' the resulting cut to a persistent density valley detected across bandwidths[cite: 7]. The procedure is label-free, supports multi-queue routing, and operates in real time with sliding windows or exponential forgetting[cite: 8]. On synthetic, drifting, multimodal streams, the method achieves competitive capacity adherence while reducing threshold jitter[cite: 9]. Updates cost $O(G)$ per event with constant memory per activity

</details>


### [41] [GPU-accelerated simulated annealing based on p-bits with real-world device-variability modeling](https://arxiv.org/abs/2601.14476)
*Naoya Onizawa,Takahiro Hanyu*

Main category: cs.LG

TL;DR: 该论文提出了一种基于概率比特(p-bit)的GPU加速模拟退火框架，发现器件变异性不仅会降低计算性能，还能通过利用时序变异性来增强算法性能。


<details>
  <summary>Details</summary>
Motivation: 概率计算使用概率比特(p-bit)为复杂问题求解提供了一种高效替代传统CMOS逻辑的方法。然而，使用磁隧道结(MTJ)等新兴器件实现p-bit会引入器件变异性，传统观点认为这会负面影响计算性能。本研究旨在探索器件变异性对算法性能的实际影响，并开发一个能够准确建模真实器件行为的仿真框架。

Method: 开发了一个基于CUDA的GPU加速开源模拟退火框架，该框架能够建模三种关键的器件变异性因素：时序变异性、强度变异性和偏移变异性。该框架使用概率比特(p-bit)作为计算单元，通过GPU并行计算实现了比CPU实现快两个数量级的加速。

Result: 在MAX-CUT基准测试中，对于800到20,000个节点的问题规模，该框架实现了比CPU实现快两个数量级的加速。研究还发现了一个意外结果：器件变异性（特别是时序变异性）不仅会降低计算性能，在某些情况下还能增强算法性能。

Conclusion: 该研究提供了一个可扩展且易于使用的概率计算仿真框架，能够准确建模真实器件的变异性行为。研究发现器件变异性具有双重作用，既可能降低性能，也可能通过时序变异性增强算法性能。该框架旨在推动概率计算研究，为优化问题在多个领域的应用提供支持。

Abstract: Probabilistic computing using probabilistic bits (p-bits) presents an efficient alternative to traditional CMOS logic for complex problem-solving, including simulated annealing and machine learning. Realizing p-bits with emerging devices such as magnetic tunnel junctions (MTJs) introduces device variability, which was expected to negatively impact computational performance. However, this study reveals an unexpected finding: device variability can not only degrade but also enhance algorithm performance, particularly by leveraging timing variability. This paper introduces a GPU-accelerated, open-source simulated annealing framework based on p-bits that models key device variability factors -timing, intensity, and offset- to reflect real-world device behavior. Through CUDA-based simulations, our approach achieves a two-order magnitude speedup over CPU implementations on the MAX-CUT benchmark with problem sizes ranging from 800 to 20,000 nodes. By providing a scalable and accessible tool, this framework aims to advance research in probabilistic computing, enabling optimization applications in diverse fields.

</details>


### [42] [Stabilizing autoregressive forecasts in chaotic systems via multi-rate latent recurrence](https://arxiv.org/abs/2601.14487)
*Mrigank Dhingra,Omer San*

Main category: cs.LG

TL;DR: MSR-HINE是一种分层隐式预测器，通过多尺度潜在先验和多速率循环模块增强，有效缓解混沌动力系统中长期自回归预测的误差累积问题。


<details>
  <summary>Details</summary>
Motivation: 混沌动力系统的长期自回归预测面临挑战：小的一步误差会迅速放大并导致物理不一致的推演和大尺度统计特性崩溃。现有方法难以同时维持长期慢流形上下文和快速尺度变异性。

Method: 提出MSR-HINE（多尺度递归隐式神经编码器），采用分层隐式预测架构：1）多速率循环模块在不同时间尺度运行；2）粗到细循环状态生成潜在先验；3）隐式一步预测器通过多尺度潜在注入细化状态；4）门控融合与后验潜在强制尺度一致更新；5）轻量级隐藏状态校正对齐循环记忆与融合潜在。

Result: 在两个基准测试中显著优于U-Net自回归基线：在Kuramoto-Sivashinsky系统中，H=400时端到端RMSE降低62.8%，ACC从-0.155提升至0.828，ACC≥0.5的可预测性时间从241步延长至400步；在Lorenz-96系统中，H=100时RMSE降低27.0%，ACC从0.144提升至0.545，ACC≥0.5时间从58步延长至100步。

Conclusion: MSR-HINE通过分层多尺度架构有效缓解混沌系统中的误差累积，同时保持长期慢流形上下文和快速尺度变异性，显著延长了混沌动力系统的可预测性时间范围。

Abstract: Long-horizon autoregressive forecasting of chaotic dynamical systems remains challenging due to rapid error amplification and distribution shift: small one-step inaccuracies compound into physically inconsistent rollouts and collapse of large-scale statistics. We introduce MSR-HINE, a hierarchical implicit forecaster that augments multiscale latent priors with multi-rate recurrent modules operating at distinct temporal scales. At each step, coarse-to-fine recurrent states generate latent priors, an implicit one-step predictor refines the state with multiscale latent injections, and a gated fusion with posterior latents enforces scale-consistent updates; a lightweight hidden-state correction further aligns recurrent memories with fused latents. The resulting architecture maintains long-term context on slow manifolds while preserving fast-scale variability, mitigating error accumulation in chaotic rollouts. Across two canonical benchmarks, MSR-HINE yields substantial gains over a U-Net autoregressive baseline: on Kuramoto-Sivashinsky it reduces end-horizon RMSE by 62.8% at H=400 and improves end-horizon ACC by +0.983 (from -0.155 to 0.828), extending the ACC >= 0.5 predictability horizon from 241 to 400 steps; on Lorenz-96 it reduces RMSE by 27.0% at H=100 and improves end horizon ACC by +0.402 (from 0.144 to 0.545), extending the ACC >= 0.5 horizon from 58 to 100 steps.

</details>


### [43] [On the Runway Cascade of Transformers for Language Modeling](https://arxiv.org/abs/2601.14522)
*Hunjae Lee,Corey Clark*

Main category: cs.LG

TL;DR: 提出"跑道感知重连"机制，通过显式整合间接路径信息来改善因果Transformer的信息传播，提升语言建模、信息检索和外推能力


<details>
  <summary>Details</summary>
Motivation: 因果Transformer中直接路径注意力与间接路径（跑道）之间的信息传播模式不匹配，导致冗余和无关信息在token表示中传播，造成某些故障模式

Method: 提出跑道感知重连机制，基于每个token的跑道景观摘要重新连接注意力模式，使直接路径注意力能够感知累积的表示影响，实现更平衡的信息传播

Result: 重连Transformer在通用语言建模上获得稳定改进，在信息检索和外推能力上相比标准Transformer有明显提升

Conclusion: 跑道感知重连机制通过显式整合间接路径信息，有效解决了因果Transformer中信息传播模式不匹配的问题，提升了模型性能且无需额外参数

Abstract: In decoder-only (causal) transformers, the computation graph created by causal masking routes information through both direct-path attention and indirect paths formed by intermediate tokens. We denote these indirect paths between token pairs as their runways. We argue that certain failure modes of causal transformers as observed by a growing body of recent works are likely exacerbated by a misalignment between these two information propagation modes. We formalize runway cascade as a phenomenon whereby this misalignment results in redundancies and irrelevant information cascading to token representations despite adequately learned attention patterns. As a solution, we propose runway-aware rewiring as a more explicit way of incorporating runway context directly into each token's direct-path attention. This mechanism re-wires the attention pattern for each token based on a summary of its runway landscape, enabling awareness of accumulating representational influences and allowing for more balanced information propagation. Our proposed methodology introduces no additional parameters and can seamlessly be integrated into standard attention mechanism. Empirically, our rewired transformer results in steady improvements in general language modeling as well as noticeably stronger information retrieval and extrapolation abilities compared to standard transformers.

</details>


### [44] [Search over Self-Edit Strategies for LLM Adaptation](https://arxiv.org/abs/2601.14532)
*Alistair Cheong,Haolin Cong,Tyler Yang,Dustin Miao*

Main category: cs.LG

TL;DR: 该研究探索了LLM能否利用任务反馈自主决定如何更新权重，在SEAL框架中放宽固定模板限制，让模型生成自编辑模板来控制训练数据和超参数


<details>
  <summary>Details</summary>
Motivation: 现有LLM搜索系统通常冻结基础模型，可能限制长期进展。虽然已有研究探索在测试时更新提议模型，但更新策略仍需人工指定。本研究旨在探究LLM能否利用任务反馈自主决定权重更新方式

Method: 在SEAL框架中放宽固定人类模板约束，允许模型生成自编辑模板，从而控制训练数据和NTP超参数。研究了两种变体：无存档版本和基于轻量级历史模板存档的条件生成版本。在SQuAD数据集上使用Qwen3-8B模型进行实验

Result: 无存档变体表现与较弱的"Implications"基线相当，存档变体优于"Implications"并接近最强的人工设计"Rewrite"基线但未超越。分析发现朴素存档能提供短期鲁棒性，但也会加速同质化，可能需要显式新颖性压力来超越人工优化策略

Conclusion: LLM能够利用任务反馈自主决定权重更新，但需要更精细的探索策略设计。朴素存档虽能提供短期好处，但可能导致同质化，未来需要结合新颖性压力来持续超越人工优化策略

Abstract: Many LLM-based open-ended search systems freeze the foundation model that proposes improvements to existing solutions, which may bottleneck long-run progress. Recent work has explored updating the proposal model at test time [arXiv:2511.23473], but the update strategy is still typically hand-specified. Therefore, this study investigated whether an LLM can use task feedback to decide how it should update its weights. For tractability, we focused on the simpler case where there is only one round of self-improvement, and restricted the update operator to self-supervised next token prediction (NTP), leaving the model freedom in choosing its training data and key NTP hyperparameters. Using the Self-Adapting Language Models (SEAL) [arXiv:2506.10943] framework as a testbed, we relaxed its fixed human template constraint and allowed the model to generate its own self-edit templates, thereby giving it more control over its training data and hyperparameters. Two variants were studied, differing in whether template generation was conditioned on a lightweight archive of past templates. In SEAL's Single-Passage Knowledge Incorporation setting with Qwen3-8B on SQuAD [arXiv:1606.05250], the no-archive variant performed comparably to the weaker "Implications" baseline, while the archive variant outperformed "Implications" and approached the strongest human-designed "Rewrite" baseline without surpassing it. Further analysis of collapse in the model's exploration revealed that a naive archive can confer some short-term robustness but can also accelerate homogenization, suggesting that explicit novelty pressure may be required to consistently advance beyond carefully optimized human strategies. Our code is available at https://github.com/cheongalc/search-self-edit-strategies .

</details>


### [45] [QMC: Efficient SLM Edge Inference via Outlier-Aware Quantization and Emergent Memories Co-Design](https://arxiv.org/abs/2601.14549)
*Nilesh Prasad Pandey,Jangseon Park,Onat Gungor,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: QMC提出了一种无需重新训练的量化方法，结合异构内存架构，将SLM中的内点权重存储在紧凑的ReRAM中，关键离群值保存在高精度MRAM中，显著提升了边缘设备上语言模型推理的效率。


<details>
  <summary>Details</summary>
Motivation: 在边缘平台上部署小型语言模型面临内存、延迟和能耗限制。传统量化方法受新兴非易失性存储器设备噪声影响，而传统内存层次结构（SRAM密度低、DRAM带宽竞争、Flash推理时闲置）限制了效率，需要针对LLM推理的混合内存组织。

Method: 提出QMC（Outlier-aware Quantization with Memory Co-design）：1）识别SLM中的内点和离群权重；2）将内点权重存储在紧凑的多级ReRAM中；3）将关键离群值保存在高精度片上MRAM中；4）无需重新训练的量化方法，结合异构内存架构缓解噪声引起的性能下降。

Result: 在语言建模和推理基准测试中，QMC优于或匹配使用高级算法和混合数据格式的最先进量化方法，在算法评估和实际部署场景下实现更高压缩。相比FP16，内存使用减少6.3-7.3倍，外部数据传输减少7.6倍，能耗降低11.7倍，延迟降低12.5倍。

Conclusion: QMC作为一种可扩展、可部署的协同设计，为高效设备端推理提供了解决方案，通过离群值感知量化和异构内存架构，在边缘AI平台上显著提升了小型语言模型的部署效率。

Abstract: Deploying Small Language Models (SLMs) on edge platforms is critical for real-time, privacy-sensitive generative AI, yet constrained by memory, latency, and energy budgets. Quantization reduces model size and cost but suffers from device noise in emerging non-volatile memories, while conventional memory hierarchies further limit efficiency. SRAM provides fast access but has low density, DRAM must simultaneously accommodate static weights and dynamic KV caches, which creates bandwidth contention, and Flash, although dense, is primarily used for initialization and remains inactive during inference. These limitations highlight the need for hybrid memory organizations tailored to LLM inference. We propose Outlier-aware Quantization with Memory Co-design (QMC), a retraining-free quantization with a novel heterogeneous memory architecture. QMC identifies inlier and outlier weights in SLMs, storing inlier weights in compact multi-level Resistive-RAM (ReRAM) while preserving critical outliers in high-precision on-chip Magnetoresistive-RAM (MRAM), mitigating noise-induced degradation. On language modeling and reasoning benchmarks, QMC outperforms and matches state-of-the-art quantization methods using advanced algorithms and hybrid data formats, while achieving greater compression under both algorithm-only evaluation and realistic deployment settings. Specifically, compared against SoTA quantization methods on the latest edge AI platform, QMC reduces memory usage by 6.3x-7.3x, external data transfers by 7.6x, energy by 11.7x, and latency by 12.5x when compared to FP16, establishing QMC as a scalable, deployment-ready co-design for efficient on-device inference.

</details>


### [46] [From Observation to Prediction: LSTM for Vehicle Lane Change Forecasting on Highway On/Off-Ramps](https://arxiv.org/abs/2601.14848)
*Mohamed Abouras,Catherine M. Elias*

Main category: cs.LG

TL;DR: 该研究使用多层LSTM架构，基于ExiD无人机数据集，预测高速公路匝道区域的车辆行为，在4秒预测范围内取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 高速公路匝道区域是研究不足的路段，这些区域引入了更高水平的交通交互变化。预测这些区域的车辆行为可以减少不确定性影响并提高道路安全性。

Method: 使用多层LSTM架构训练匝道区域模型，基于ExiD无人机数据集。研究了不同预测时间范围和不同模型工作流程，比较了匝道区域与直线高速公路路段的差异。

Result: 在4秒预测范围内表现出良好前景，匝道区域最大预测准确率约76%，一般高速公路场景最大预测准确率达94%。

Conclusion: 研究表明LSTM架构在预测高速公路匝道区域车辆行为方面具有潜力，特别是在4秒预测范围内，为匝道区域的安全研究提供了新方法。

Abstract: On and off-ramps are understudied road sections even though they introduce a higher level of variation in highway interactions. Predicting vehicles' behavior in these areas can decrease the impact of uncertainty and increase road safety. In this paper, the difference between this Area of Interest (AoI) and a straight highway section is studied. Multi-layered LSTM architecture to train the AoI model with ExiD drone dataset is utilized. In the process, different prediction horizons and different models' workflow are tested. The results show great promise on horizons up to 4 seconds with prediction accuracy starting from about 76% for the AoI and 94% for the general highway scenarios on the maximum horizon.

</details>


### [47] [Counterfactual Modeling with Fine-Tuned LLMs for Health Intervention Design and Sensor Data Augmentation](https://arxiv.org/abs/2601.14590)
*Shovito Barua Soumma,Asiful Arefeen,Stephanie M. Carpenter,Melanie Hingle,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: 该研究评估了使用大语言模型（GPT-4、BioMistral-7B、LLaMA-3.1-8B）生成反事实解释的效果，在临床数据集上验证了其在干预质量和数据增强方面的有效性，相比传统优化方法更具临床可操作性和语义连贯性。


<details>
  <summary>Details</summary>
Motivation: 反事实解释通过识别最小可操作变化来改变模型预测，可用于异常预防干预和增强数据训练鲁棒模型。研究旨在全面评估LLM生成反事实解释的能力，探索其在数字健康领域的应用潜力。

Method: 使用多模态AI-READI临床数据集，评估GPT-4（零样本和少样本）、BioMistral-7B和LLaMA-3.1-8B（预训练和微调配置）生成反事实解释。从干预质量、特征多样性和增强效果三个维度评估，并与DiCE、CFNOW、NICE等优化基线方法比较。

Result: 微调LLM（特别是LLaMA-3.1-8B）生成的反事实具有高合理性（高达99%）、强有效性（高达0.99）和现实可行为修改的特征调整。在标签稀缺设置下用于数据增强时，LLM生成的反事实显著恢复分类器性能，在三种稀缺场景中平均F1恢复20%。相比优化基线，LLM提供更灵活、模型无关的方法，生成更具临床可操作性和语义连贯的反事实。

Conclusion: 该工作展示了LLM驱动的反事实解释在可解释干预设计和传感器数字健康中数据高效模型训练的前景。SenseCF框架通过微调LLM生成有效、有代表性的反事实解释，补充不平衡数据集中的少数类，改善模型训练并提升模型鲁棒性和预测性能。

Abstract: Counterfactual explanations (CFEs) provide human-centric interpretability by identifying the minimal, actionable changes required to alter a machine learning model's prediction. Therefore, CFs can be used as (i) interventions for abnormality prevention and (ii) augmented data for training robust models. We conduct a comprehensive evaluation of CF generation using large language models (LLMs), including GPT-4 (zero-shot and few-shot) and two open-source models-BioMistral-7B and LLaMA-3.1-8B, in both pretrained and fine-tuned configurations. Using the multimodal AI-READI clinical dataset, we assess CFs across three dimensions: intervention quality, feature diversity, and augmentation effectiveness. Fine-tuned LLMs, particularly LLaMA-3.1-8B, produce CFs with high plausibility (up to 99%), strong validity (up to 0.99), and realistic, behaviorally modifiable feature adjustments. When used for data augmentation under controlled label-scarcity settings, LLM-generated CFs substantially restore classifier performance, yielding an average 20% F1 recovery across three scarcity scenarios. Compared with optimization-based baselines such as DiCE, CFNOW, and NICE, LLMs offer a flexible, model-agnostic approach that generates more clinically actionable and semantically coherent counterfactuals. Overall, this work demonstrates the promise of LLM-driven counterfactuals for both interpretable intervention design and data-efficient model training in sensor-based digital health.
  Impact: SenseCF fine-tunes an LLM to generate valid, representative counterfactual explanations and supplement minority class in an imbalanced dataset for improving model training and boosting model robustness and predictive performance

</details>


### [48] [Rethinking Reinforcement fine-tuning of LLMs: A Multi-armed Bandit Learning Perspective](https://arxiv.org/abs/2601.14599)
*Xiao Hu,Hong Xie,Tao Tan,Defu Lian,Jianyu Han*

Main category: cs.LG

TL;DR: 该论文通过自下而上的实验流程，系统分析了强化学习微调LLM中各种优化选择的作用和瓶颈，揭示了设计选择的新理解


<details>
  <summary>Details</summary>
Motivation: 当前LLM强化学习微调领域存在大量启发式方法但缺乏系统理解，两个基本问题尚未明确：1）每个优化选择的作用是什么？2）哪些是瓶颈？需要解决微调过程中多个混杂因素纠缠的挑战

Method: 提出自下而上的实验流程：底层采用极简配置（单一训练数据、每轮一次rollout、奖励直接作为学习信号无优势函数设计），连接具有极大离散动作空间的多臂赌博机学习理论；上层逐步扩展极简配置，逐层检验每个设计选择的作用

Result: 在三个LLM和两个推理数据集上的实验不仅揭示了设计选择的新理解，还为该领域提供了重要的洞察

Conclusion: 通过系统分析强化学习微调LLM中的优化选择，明确了各设计选择的作用和瓶颈，为该领域提供了理论支持和实践指导

Abstract: A large number of heuristics have been proposed to optimize the reinforcement fine-tuning of LLMs. However, inconsistent claims are made from time to time, making this area elusive. Reflecting on this situation, two fundamental questions still lack a clear understanding: 1) what is the role of each optimizing choice? 2) which ones are the bottlenecks? This paper aims to shed light on them, and it faces the challenge of several entangled confounding factors in the fine-tuning process. To tackle this challenge, we propose a bottom-up experiment pipeline. The bottom layer is composed of a minimalist configuration: one training data, one rollout per round and the reward directly serve as the learning signal without advantage function design. This minimalist configuration connects to multi-armed bandit learning with extremely large discrete action space, which offers theories to corroborate the experiment findings. The up procedure of the experiment pipeline expanding the minimalist configuration layer by layer, examining the role of each design choice. Experimental results on three LLMs and two reasoning datasets not only reveal new understanding of the design choice but also yield essential insights to shape the area.

</details>


### [49] [Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum](https://arxiv.org/abs/2601.14603)
*Jingru Li,Yibo Fan,Huan Li*

Main category: cs.LG

TL;DR: Muon-NSR和Muon-VS通过方差自适应归一化和正交动量更新加速LLM预训练，相比AdamW和Muon基准减少1.36倍迭代次数


<details>
  <summary>Details</summary>
Motivation: LLM预训练计算成本高昂，优化器效率成为重要实际考量。现有Adam优化器可视为方差自适应符号更新算法，但仍有改进空间以加速收敛

Method: 提出Muon-NSR和Muon-VS两种变体：在正交化前对动量应用方差自适应归一化。Muon-NSR使用噪声信号比调制，Muon-VS进行基于方差的缩放而不引入额外超参数

Result: 在GPT-2和LLaMA预训练实验中，提出的方法加速收敛并持续获得比AdamW和Muon基线更低的验证损失。在LLaMA-1.2B模型上，Muon-NSR和Muon-VS将达到目标验证损失所需的迭代次数减少1.36倍

Conclusion: 通过方差自适应归一化结合正交动量更新，Muon-NSR和Muon-VS显著加速LLM预训练收敛，为大规模语言模型训练提供了更高效的优化器选择

Abstract: Large Language Models (LLMs) achieve competitive performance across diverse natural language processing (NLP) tasks, yet pretraining is computationally demanding, making optimizer efficiency an important practical consideration. Muon accelerates LLM pretraining via orthogonal momentum updates that serve as a matrix analogue of the element-wise sign operator. Motivated by the recent perspective that Adam is a variance-adaptive sign update algorithm, we propose two variants of Muon, Muon-NSR and Muon-VS, which apply variance-adaptive normalization to momentum before orthogonalization. Muon-NSR applies noise-to-signal ratio (NSR) modulation, while Muon-VS performs variance-based scaling without introducing additional hyperparameters. Experiments on GPT-2 and LLaMA pretraining demonstrate that our proposed methods accelerate convergence and consistently achieve lower validation loss than both competitive, well-tuned AdamW and Muon baselines. For example, on the LLaMA-1.2B model, Muon-NSR and Muon-VS reduce the iterations required to reach the target validation loss by $1.36\times$ relative to the well-tuned Muon following the recent benchmark.

</details>


### [50] [Efficient Imputation for Patch-based Missing Single-cell Data via Cluster-regularized Optimal Transport](https://arxiv.org/abs/2601.14653)
*Yuyu Liu,Jiannan Yang,Ziyang Yu,Weishen Pan,Fei Wang,Tengfei Ma*

Main category: cs.LG

TL;DR: CROT是一种基于最优传输的插补算法，专门处理表格数据中的块状缺失数据，在保持高精度的同时显著减少运行时间，适用于大规模单细胞测序数据集。


<details>
  <summary>Details</summary>
Motivation: 单细胞测序数据中的缺失数据对提取生物学见解构成重大挑战。现有插补方法通常假设数据均匀且完整，难以处理大规模块状缺失数据的情况。

Method: 提出CROT算法，基于最优传输理论设计，专门处理表格格式中的块状缺失数据，能够有效捕捉存在显著缺失情况下的底层数据结构。

Result: CROT实现了优异的插补精度，同时显著减少了运行时间，证明了其在大规模数据集上的可扩展性和效率。

Conclusion: 该工作为异构、高维且存在结构化数据缺失的数据集提供了稳健的插补解决方案，解决了生物和临床数据分析中的关键挑战。

Abstract: Missing data in single-cell sequencing datasets poses significant challenges for extracting meaningful biological insights. However, existing imputation approaches, which often assume uniformity and data completeness, struggle to address cases with large patches of missing data. In this paper, we present CROT, an optimal transport-based imputation algorithm designed to handle patch-based missing data in tabular formats. Our approach effectively captures the underlying data structure in the presence of significant missingness. Notably, it achieves superior imputation accuracy while significantly reducing runtime, demonstrating its scalability and efficiency for large-scale datasets. This work introduces a robust solution for imputation in heterogeneous, high-dimensional datasets with structured data absence, addressing critical challenges in both biological and clinical data analysis. Our code is available at Anomalous Github.

</details>


### [51] [Beyond Denial-of-Service: The Puppeteer's Attack for Fine-Grained Control in Ranking-Based Federated Learning](https://arxiv.org/abs/2601.14687)
*Zhihao Chen,Zirui Gong,Jianting Ning,Yanjun Zhang,Leo Yu Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种针对联邦排序学习（FRL）的新型细粒度控制攻击——边缘控制攻击（ECA），该攻击能够精确控制目标模型的准确率，同时保持正常的收敛轨迹以避免检测。


<details>
  <summary>Details</summary>
Motivation: 联邦排序学习（FRL）因其基于离散排序的更新机制被认为对模型投毒攻击具有鲁棒性，但作者发现FRL仍然容易受到新型细粒度控制攻击的威胁，需要揭示这种安全漏洞。

Method: 提出边缘控制攻击（ECA），分为两个阶段：1）识别并操纵升序和降序边缘，使全局模型与目标模型对齐；2）扩大选择边界间隙，使全局模型稳定在目标准确率水平。

Result: 在7个基准数据集和9种拜占庭鲁棒聚合规则上的实验表明，ECA实现了细粒度准确率控制，平均误差仅为0.224%，比基线方法提升高达17倍。

Conclusion: 尽管FRL减少了攻击面，但仍易受细粒度控制攻击，ECA攻击能够精确控制模型准确率而不被检测，这凸显了需要针对高级投毒攻击开发更强防御机制的必要性。

Abstract: Federated Rank Learning (FRL) is a promising Federated Learning (FL) paradigm designed to be resilient against model poisoning attacks due to its discrete, ranking-based update mechanism. Unlike traditional FL methods that rely on model updates, FRL leverages discrete rankings as a communication parameter between clients and the server. This approach significantly reduces communication costs and limits an adversary's ability to scale or optimize malicious updates in the continuous space, thereby enhancing its robustness. This makes FRL particularly appealing for applications where system security and data privacy are crucial, such as web-based auction and bidding platforms. While FRL substantially reduces the attack surface, we demonstrate that it remains vulnerable to a new class of local model poisoning attack, i.e., fine-grained control attacks. We introduce the Edge Control Attack (ECA), the first fine-grained control attack tailored to ranking-based FL frameworks. Unlike conventional denial-of-service (DoS) attacks that cause conspicuous disruptions, ECA enables an adversary to precisely degrade a competitor's accuracy to any target level while maintaining a normal-looking convergence trajectory, thereby avoiding detection. ECA operates in two stages: (i) identifying and manipulating Ascending and Descending Edges to align the global model with the target model, and (ii) widening the selection boundary gap to stabilize the global model at the target accuracy. Extensive experiments across seven benchmark datasets and nine Byzantine-robust aggregation rules (AGRs) show that ECA achieves fine-grained accuracy control with an average error of only 0.224%, outperforming the baseline by up to 17x. Our findings highlight the need for stronger defenses against advanced poisoning attacks. Our code is available at: https://github.com/Chenzh0205/ECA

</details>


### [52] [CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation](https://arxiv.org/abs/2601.14695)
*Yutong Chen,Jiandong Gao,Ji Wu*

Main category: cs.LG

TL;DR: 提出CoScale-RL方法，通过扩大解决方案数量和增强rollout计算来提升大型推理模型的训练稳定性和效率


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在困难问题或弱基础模型上的训练不稳定且不可预测，现有后训练扩展策略仍有改进空间

Method: CoScale-RL包含三个核心组件：1) 扩展解决方案 - 为每个问题收集多个解决方案而非简单扩大数据集；2) 扩展rollout计算 - 稳定强化学习训练；3) 使用Re-distillation模型合并技术维持计算效率

Result: 在四个基准测试上平均获得3.76倍准确率提升，显著改善数据和计算效率，无需大量监督微调数据集即可提升LRM能力边界

Conclusion: CoScale-RL为改进大型推理模型的推理能力提供了新的扩展方向，具有更好的数据和计算效率

Abstract: Training Large Reasoning Model (LRM) is usually unstable and unpredictable, especially on hard problems or weak foundation models. We found that the current post-training scaling strategy can still improve on these cases. We propose CoScale-RL, a novel scaling strategy with better data and computational efficiency. We first scale up solutions to make problems solvable. The core idea is to collect multiple solutions for each problem, rather than simply enlarging the dataset. Then, we scale up rollout computation to stabilize Reinforcement Learning. We further leverage a model merge technique called Re-distillation to sustain or even improve computational efficiency when scaling up. Our method significantly improves data and computational efficiency, with an average 3.76$\times$ accuracy improvement on four benchmarks. CoScale-RL is able to improve an LRM's ability boundary without an extensive SFT dataset. Our method provides a new scaling direction to further improve LRM's reasoning ability.

</details>


### [53] [Case-Guided Sequential Assay Planning in Drug Discovery](https://arxiv.org/abs/2601.14710)
*Tianchi Chen,Jan Bima,Sean L. Wu,Otto Ritter,Bingjia Yang,Xiang Yu*

Main category: cs.LG

TL;DR: 提出IBMDP框架，用于无模拟器的药物发现实验序列优化，通过非参数贝叶斯建模和集成MCTS规划，在资源受限下实现高效决策


<details>
  <summary>Details</summary>
Motivation: 药物发现中的实验序列优化面临严重不确定性和资源约束，标准强化学习缺乏环境模拟器或转移数据，需要仅基于静态历史数据库进行规划

Method: 引入隐式贝叶斯马尔可夫决策过程(IBMDP)框架，通过相似历史结果构建非参数信念分布作为隐式转移模型，采用贝叶斯信念更新和集成MCTS规划

Result: 在真实CNS药物发现任务中，相比现有启发式方法减少92%资源消耗；在合成环境中，与确定性值迭代相比，与最优策略对齐度显著更高

Conclusion: IBMDP为数据丰富但模拟器缺乏的领域提供了实用的序列实验设计解决方案，通过隐式贝叶斯建模和集成规划实现资源效率与决策质量的平衡

Abstract: Optimally sequencing experimental assays in drug discovery is a high-stakes planning problem under severe uncertainty and resource constraints. A primary obstacle for standard reinforcement learning (RL) is the absence of an explicit environment simulator or transition data $(s, a, s')$; planning must rely solely on a static database of historical outcomes. We introduce the Implicit Bayesian Markov Decision Process (IBMDP), a model-based RL framework designed for such simulator-free settings. IBMDP constructs a case-guided implicit model of transition dynamics by forming a nonparametric belief distribution using similar historical outcomes. This mechanism enables Bayesian belief updating as evidence accumulates and employs ensemble MCTS planning to generate stable policies that balance information gain toward desired outcomes with resource efficiency. We validate IBMDP through comprehensive experiments. On a real-world central nervous system (CNS) drug discovery task, IBMDP reduced resource consumption by up to 92\% compared to established heuristics while maintaining decision confidence. To rigorously assess decision quality, we also benchmarked IBMDP in a synthetic environment with a computable optimal policy. Our framework achieves significantly higher alignment with this optimal policy than a deterministic value iteration alternative that uses the same similarity-based model, demonstrating the superiority of our ensemble planner. IBMDP offers a practical solution for sequential experimental design in data-rich but simulator-poor domains.

</details>


### [54] [PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning](https://arxiv.org/abs/2601.14716)
*Yao Lu,Dengdong Fan,Jianzheng Nie,Fan Xu,Jie Chen,Bin Zhou,Yonghong Tian*

Main category: cs.LG

TL;DR: PCL-Reasoner-V1.5是基于Qwen2.5-32B构建的320亿参数数学推理大语言模型，采用监督微调+强化学习训练，创新性地使用离线RL方法提升训练稳定性和效率，在AIME数学竞赛上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个专门用于数学推理的高性能大语言模型，探索比标准在线RL方法更稳定高效的训练范式，提升LLM在复杂数学问题上的推理能力。

Method: 基于Qwen2.5-32B架构，采用两阶段训练：1) 监督微调(SFT)；2) 强化学习(RL)，其中创新性地提出了离线RL方法替代传统的在线RL方法如GRPO，在华为Ascend 910C NPU上进行实验。

Result: 在Qwen2.5-32B后训练模型中达到最先进性能：AIME 2024平均准确率90.9%，AIME 2025平均准确率85.6%。离线RL方法相比在线RL方法展现出更好的训练稳定性和效率。

Conclusion: 离线RL是一种稳定高效的训练范式，能够有效提升LLM的数学推理能力。PCL-Reasoner-V1.5在数学竞赛基准测试中表现出色，为LLM推理能力提升提供了新方法。

Abstract: We present PCL-Reasoner-V1.5, a 32-billion-parameter large language model (LLM) for mathematical reasoning. The model is built upon Qwen2.5-32B and refined via supervised fine-tuning (SFT) followed by reinforcement learning (RL). A central innovation is our proposed offline RL method, which provides superior training stability and efficiency over standard online RL methods such as GRPO. Our model achieves state-of-the-art performance among models post-trained on Qwen2.5-32B, attaining average accuracies of 90.9% on AIME 2024 and 85.6% on AIME 2025. Our work demonstrates offline RL as a stable and efficient paradigm for advancing reasoning in LLMs. All experiments were conducted on Huawei Ascend 910C NPUs.

</details>


### [55] [Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models](https://arxiv.org/abs/2601.14758)
*Injin Kong,Hyoungjoon Lee,Yohan Jo*

Main category: cs.LG

TL;DR: 该研究通过比较分析发现，从自回归模型后训练为掩码扩散模型会引发计算机制的转变，而非简单参数适应，使模型获得全局规划能力。


<details>
  <summary>Details</summary>
Motivation: 探索自回归模型后训练为掩码扩散模型时内部算法转换的本质，确定这种转换是否真正赋予模型双向推理能力，还是仅仅重新包装自回归启发式方法。

Method: 采用比较电路分析方法，对比分析自回归模型及其对应的掩码扩散模型，从结构和语义两个维度考察机制转变。

Result: 发现系统性的"机制转变"：结构上，对于局部因果依赖任务，MDMs保留自回归电路；对于全局规划任务，MDMs放弃初始化路径，表现出早期层处理增强的重新布线。语义上，从ARMs的尖锐局部专业化转变为MDMs的分布式集成。

Conclusion: 扩散后训练不仅适应模型参数，而且从根本上重组内部计算以支持非顺序的全局规划，实现了计算机制的实质性转变。

Abstract: Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic "mechanism shift" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning.

</details>


### [56] [Anytime Optimal Decision Tree Learning with Continuous Features](https://arxiv.org/abs/2601.14765)
*Harold Kiossou,Pierre Schaus,Siegfried Nijssen*

Main category: cs.LG

TL;DR: 提出了一种基于有限差异搜索的决策树学习算法，解决现有方法在连续特征上深度受限和任意时间性能差的问题


<details>
  <summary>Details</summary>
Motivation: 现有最优决策树学习方法主要针对二元特征，扩展到连续特征时计算复杂度急剧增加。最近提出的连续特征最优决策树算法虽然优雅，但计算时间随深度快速增加，且采用深度优先搜索策略导致任意时间性能差——提前中断时找到的树往往高度不平衡且次优

Method: 提出了一种基于有限差异搜索（limited discrepancy search）的任意时间但完备的方法，将计算努力更均匀地分配到整个树结构中，确保在任何中断点都能获得高质量的决策树

Result: 实验结果表明，该方法在任意时间性能方面优于现有方法

Conclusion: 通过有限差异搜索策略，实现了在连续特征上学习最优决策树的任意时间算法，显著改善了现有方法的任意时间性能

Abstract: In recent years, significant progress has been made on algorithms for learning optimal decision trees, primarily in the context of binary features. Extending these methods to continuous features remains substantially more challenging due to the large number of potential splits for each feature. Recently, an elegant exact algorithm was proposed for learning optimal decision trees with continuous features; however, the rapidly increasing computational time limits its practical applicability to shallow depths (typically 3 or 4). It relies on a depth-first search optimization strategy that fully optimizes the left subtree of each split before exploring the corresponding right subtree. While effective in finding optimal solutions given sufficient time, this strategy can lead to poor anytime behavior: when interrupted early, the best-found tree is often highly unbalanced and suboptimal. In such cases, purely greedy methods such as C4.5 may, paradoxically, yield better solutions. To address this limitation, we propose an anytime, yet complete approach leveraging limited discrepancy search, distributing the computational effort more evenly across the entire tree structure, and thus ensuring that a high-quality decision tree is available at any interruption point. Experimental results show that our approach outperforms the existing one in terms of anytime performance.

</details>


### [57] [Reflecting in the Reflection: Integrating a Socratic Questioning Framework into Automated AI-Based Question Generation](https://arxiv.org/abs/2601.14798)
*Ondřej Holub,Essi Ryymin,Rodrigo Alves*

Main category: cs.LG

TL;DR: 提出"反思中的反思"框架，利用双智能体对话自动生成反思问题，通过学生-教师和教师-教育者的Socratic对话迭代优化问题质量


<details>
  <summary>Details</summary>
Motivation: 设计高质量的反思问题对教学很重要，但教师需要花费大量时间且支持不均衡。现有方法难以自动生成符合教学需求的优质反思问题。

Method: 采用双智能体框架：学生-教师提出候选问题及理由，教师-教育者从清晰度、深度、相关性、参与度和概念关联性五个维度评估，通过Socratic多轮对话迭代优化。使用GPT-4o-mini作为基础模型，GPT-4级模型作为外部评估器进行成对比较。

Result: 动态停止机制结合上下文信息优于固定5步或10步迭代；双智能体协议生成的问题在相关性、深度和整体质量上显著优于单次生成基线；过长对话容易导致问题漂移或过度复杂化。

Conclusion: 反思中的反思框架能有效生成高质量的反思问题，动态停止机制和上下文信息是关键因素，为教师提供了实用的自动化反思问题生成工具。

Abstract: Designing good reflection questions is pedagogically important but time-consuming and unevenly supported across teachers. This paper introduces a reflection-in-reflection framework for automated generation of reflection questions with large language models (LLMs). Our approach coordinates two role-specialized agents, a Student-Teacher and a Teacher-Educator, that engage in a Socratic multi-turn dialogue to iteratively refine a single question given a teacher-specified topic, key concepts, student level, and optional instructional materials. The Student-Teacher proposes candidate questions with brief rationales, while the Teacher-Educator evaluates them along clarity, depth, relevance, engagement, and conceptual interconnections, responding only with targeted coaching questions or a fixed signal to stop the dialogue. We evaluate the framework in an authentic lower-secondary ICT setting on the topic, using GPT-4o-mini as the backbone model and a stronger GPT- 4-class LLM as an external evaluator in pairwise comparisons of clarity, relevance, depth, and overall quality. First, we study how interaction design and context (dynamic vs.fixed iteration counts; presence or absence of student level and materials) affect question quality. Dynamic stopping combined with contextual information consistently outperforms fixed 5- or 10-step refinement, with very long dialogues prone to drift or over-complication. Second, we show that our two-agent protocol produces questions that are judged substantially more relevant and deeper, and better overall, than a one-shot baseline using the same backbone model.

</details>


### [58] [Statistical Learning Theory for Distributional Classification](https://arxiv.org/abs/2601.14818)
*Christian Fiedler*

Main category: cs.LG

TL;DR: 该论文研究了两阶段采样设置中分布输入的监督学习问题，特别关注使用支持向量机（SVM）进行分布输入分类的理论分析，建立了新的oracle不等式、一致性和学习率结果。


<details>
  <summary>Details</summary>
Motivation: 在基于学习的医学筛查或因果学习等应用中，输入是概率分布，但在学习阶段只能获得这些分布的样本。现有方法使用核均值嵌入（KME）将分布嵌入希尔伯特空间，然后应用SVM等标准核方法，但缺乏对这种方法理论分析的深入研究。

Method: 采用核均值嵌入（KME）将分布或样本嵌入希尔伯特空间，然后应用支持向量机（SVM）进行分类。建立了新的oracle不等式，推导了一致性和学习率结果。特别针对使用铰链损失和高斯核的SVM，提出了噪声假设的新变体。

Result: 建立了新的oracle不等式，证明了该方法的一致性和学习率。对于使用铰链损失和高斯核的SVM，在提出的噪声假设下获得了学习率。开发的技术工具（如高斯核在希尔伯特空间上的新特征空间）具有独立价值。

Conclusion: 该工作为两阶段采样设置中分布输入的SVM分类提供了理论分析框架，建立了理论保证，提出的噪声假设和技术工具对核方法理论有重要贡献。

Abstract: In supervised learning with distributional inputs in the two-stage sampling setup, relevant to applications like learning-based medical screening or causal learning, the inputs (which are probability distributions) are not accessible in the learning phase, but only samples thereof. This problem is particularly amenable to kernel-based learning methods, where the distributions or samples are first embedded into a Hilbert space, often using kernel mean embeddings (KMEs), and then a standard kernel method like Support Vector Machines (SVMs) is applied, using a kernel defined on the embedding Hilbert space. In this work, we contribute to the theoretical analysis of this latter approach, with a particular focus on classification with distributional inputs using SVMs. We establish a new oracle inequality and derive consistency and learning rate results. Furthermore, for SVMs using the hinge loss and Gaussian kernels, we formulate a novel variant of an established noise assumption from the binary classification literature, under which we can establish learning rates. Finally, some of our technical tools like a new feature space for Gaussian kernels on Hilbert spaces are of independent interest.

</details>


### [59] [Adaptive Exponential Integration for Stable Gaussian Mixture Black-Box Variational Inference](https://arxiv.org/abs/2601.14855)
*Baojun Che,Yifan Chen,Daniel Zhengyu Huang,Xinying Mao,Weijie Wang*

Main category: cs.LG

TL;DR: 提出了一种稳定高效的BBVI框架，结合自然梯度、指数积分器和自适应步长，用于高斯混合族近似复杂后验分布


<details>
  <summary>Details</summary>
Motivation: 传统的黑盒变分推断（BBVI）使用高斯混合族时，标准数值优化方法存在不稳定和效率低的问题，需要更稳定高效的优化框架

Method: 结合三个关键组件：1) 通过自然梯度公式的仿射不变预处理；2) 无条件保持协方差矩阵正定性的指数积分器；3) 确保稳定性并适应预热和收敛阶段的自适应步长策略

Result: 对于高斯后验，证明了在无噪声情况下的指数收敛性和蒙特卡洛估计下的几乎必然收敛，数值实验在多模态分布、Neal多尺度漏斗和基于PDE的Darcy流贝叶斯反问题上展示了方法的有效性

Conclusion: 提出的框架为BBVI提供了一种稳定高效的优化方法，具有与流形优化和镜像下降的自然联系，自适应步长策略在理论分析和实际应用中都被证明是必要的

Abstract: Black-box variational inference (BBVI) with Gaussian mixture families offers a flexible approach for approximating complex posterior distributions without requiring gradients of the target density. However, standard numerical optimization methods often suffer from instability and inefficiency. We develop a stable and efficient framework that combines three key components: (1) affine-invariant preconditioning via natural gradient formulations, (2) an exponential integrator that unconditionally preserves the positive definiteness of covariance matrices, and (3) adaptive time stepping to ensure stability and to accommodate distinct warm-up and convergence phases. The proposed approach has natural connections to manifold optimization and mirror descent. For Gaussian posteriors, we prove exponential convergence in the noise-free setting and almost-sure convergence under Monte Carlo estimation, rigorously justifying the necessity of adaptive time stepping. Numerical experiments on multimodal distributions, Neal's multiscale funnel, and a PDE-based Bayesian inverse problem for Darcy flow demonstrate the effectiveness of the proposed method.

</details>


### [60] [Strategic Doctrine Language Models (sdLM): A Learning-System Framework for Doctrinal Consistency and Geopolitical Forecasting](https://arxiv.org/abs/2601.14862)
*Olaf Yunus Laitinen Imanov,Taner Yilmaz,Derya Umut Kulali*

Main category: cs.LG

TL;DR: sdLM框架通过多文档注意力、时间编码和教义一致性层，在战略推理中实现教义一致性约束和校准不确定性，提升长期预测和计划可信度。


<details>
  <summary>Details</summary>
Motivation: 解决多文档战略推理中的教义一致性约束和不确定性校准问题，提高长期战略预测的准确性和计划的可信度。

Method: 结合多文档注意力机制、时间编码和教义一致性层，构建战略教义语言模型框架，确保战略推理符合教义约束。

Result: 在战略场景专家评分、336份教义出版物一致性评估和127个历史反事实预测中，sdLM表现优于通用LLM基线，在长期判断上与人类专家竞争力相当。

Conclusion: sdLM框架显著提升战略推理质量，减少严重教义违规，为战略规划提供可靠工具，并通过消融研究和扩展趋势分析验证了各组件的重要性。

Abstract: We introduce Strategic Doctrine Language Models (sdLM), a learning-system framework for multi-document strategic reasoning with doctrinal consistency constraints and calibrated uncertainty. The approach combines multi-document attention, temporal encoding, and a doctrine-consistency layer to improve long-horizon forecasting and plan plausibility while reducing severe doctrinal violations. We evaluate sdLM using (i) expert-panel scoring of strategic scenarios (N=47), (ii) doctrine consistency on 336 doctrine publications (12,847 statements), and (iii) geopolitical forecasting on 127 historical counterfactuals (1945-2020) across 12-60 month horizons. Across these benchmarks, sdLM achieves higher strategic quality and better calibration than strong general-purpose LLM baselines, and remains competitive with human experts on long-horizon judgments. We further report ablations, scaling trends, and deployment-oriented performance/latency characteristics to clarify which components drive improvements and how they translate to operational settings.

</details>


### [61] [What Makes Low-Bit Quantization-Aware Training Work for Reasoning LLMs? A Systematic Study](https://arxiv.org/abs/2601.14888)
*Keyu Lv,Manyi Zhang,Xiaobo Xia,Jingchen Ni,Shannan Yan,Xianzhi Yu,Lu Hou,Chun Yuan,Haoli Bai*

Main category: cs.LG

TL;DR: 该研究系统分析了推理模型的量化感知训练，提出了优化的Reasoning-QAT工作流，在低比特量化下显著提升推理模型性能


<details>
  <summary>Details</summary>
Motivation: 推理模型在复杂任务上表现出色，但其推理速度慢且token效率低。后训练量化通常导致精度大幅下降，尤其是在低比特设置下的推理任务。需要探索量化感知训练在推理模型上的应用。

Method: 系统实证研究推理模型的量化感知训练，包括：1) 知识蒸馏作为监督微调和强化学习的鲁棒目标；2) 使用PTQ作为QAT的强初始化；3) 探索量化模型的强化学习可行性；4) 对齐PTQ校准域与QAT训练域。整合这些发现形成优化的Reasoning-QAT工作流。

Result: Reasoning-QAT在多个LLM骨干和推理数据集上一致优于最先进的PTQ方法。例如，在Qwen3-0.6B上，比GPTQ在MATH-500上提升44.53%，并在2比特量化下持续恢复性能。

Conclusion: 量化感知训练是提升推理模型效率的有效方法，通过系统优化的工作流可以在低比特量化下显著恢复和提升模型性能，为推理模型的部署提供了实用的量化解决方案。

Abstract: Reasoning models excel at complex tasks such as coding and mathematics, yet their inference is often slow and token-inefficient. To improve the inference efficiency, post-training quantization (PTQ) usually comes with the cost of large accuracy drops, especially for reasoning tasks under low-bit settings. In this study, we present a systematic empirical study of quantization-aware training (QAT) for reasoning models. Our key findings include: (1) Knowledge distillation is a robust objective for reasoning models trained via either supervised fine-tuning or reinforcement learning; (2) PTQ provides a strong initialization for QAT, improving accuracy while reducing training cost; (3) Reinforcement learning remains feasible for quantized models given a viable cold start and yields additional gains; and (4) Aligning the PTQ calibration domain with the QAT training domain accelerates convergence and often improves the final accuracy. Finally, we consolidate these findings into an optimized workflow (Reasoning-QAT), and show that it consistently outperforms state-of-the-art PTQ methods across multiple LLM backbones and reasoning datasets. For instance, on Qwen3-0.6B, it surpasses GPTQ by 44.53% on MATH-500 and consistently recovers performance in the 2-bit regime.

</details>


### [62] [Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models](https://arxiv.org/abs/2601.14917)
*Giorgia Rigamonti,Mirko Paolo Barbato,Davide Marelli,Paolo Napoletano*

Main category: cs.LG

TL;DR: 该论文提出了一种基于深度学习的个性化血糖预测方法，通过患者特异性数据提高预测准确性，支持实时糖尿病管理决策。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴血糖监测设备和移动健康应用的普及，准确的血糖预测对于增强自动化胰岛素输送和决策支持系统至关重要。传统通用模型无法充分处理个体差异性，需要开发能够适应患者特异性动态的个性化预测方法。

Method: 采用深度学习框架进行个性化血糖预测，比较留一受试者交叉验证与微调策略的建模能力。实验对比多模态患者特异性方法与传统的仅使用连续血糖监测数据的方法，并通过消融研究分析不同训练数据规模对模型性能的影响，确定有效个性化所需的最小数据量。

Result: 个性化模型显著提高了不良事件的预测准确性，能够实现更精确和及时的干预。多模态患者特异性方法优于传统CGM-only方法。消融研究确定了有效个性化所需的最小数据量，这对于实际应用中数据收集受限的情况具有重要意义。

Conclusion: 自适应、个性化的血糖预测模型在推进下一代糖尿病管理方面具有巨大潜力，特别是在可穿戴和移动健康平台中，能够增强面向消费者的糖尿病护理解决方案。

Abstract: Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions.

</details>


### [63] [Communication-Efficient Multi-Modal Edge Inference via Uncertainty-Aware Distributed Learning](https://arxiv.org/abs/2601.14942)
*Hang Zhao,Hongru Li,Dongfang Xu,Shenghui Song,Khaled B. Letaief*

Main category: cs.LG

TL;DR: 提出三阶段通信感知分布式学习框架，解决多模态边缘推理中的通信开销和鲁棒性问题


<details>
  <summary>Details</summary>
Motivation: 多模态边缘推理面临两大挑战：1) 带宽受限无线链路上的分布式学习通信开销巨大；2) 在变化信道和噪声多模态输入下鲁棒性有限。需要通信高效的训练和鲁棒推理方案。

Method: 三阶段框架：阶段I - 设备本地多模态自监督学习，获得共享和模态特定编码器，无需设备-服务器交换；阶段II - 分布式微调与集中式证据融合，校准每模态不确定性并可靠聚合噪声或信道衰落扭曲的特征；阶段III - 不确定性引导反馈机制，为不确定样本选择性请求额外特征，优化通信-精度权衡。

Result: 在RGB-深度室内场景分类实验中，该框架以更少的训练通信轮次获得更高精度，对模态退化或信道变化保持鲁棒，优于现有自监督和全监督基线方法。

Conclusion: 提出的三阶段通信感知分布式学习框架有效解决了多模态边缘推理中的通信效率和鲁棒性问题，通过本地自监督学习、证据融合和不确定性反馈机制实现了通信高效的训练和鲁棒推理。

Abstract: Semantic communication is emerging as a key enabler for distributed edge intelligence due to its capability to convey task-relevant meaning. However, achieving communication-efficient training and robust inference over wireless links remains challenging. This challenge is further exacerbated for multi-modal edge inference (MMEI) by two factors: 1) prohibitive communication overhead for distributed learning over bandwidth-limited wireless links, due to the \emph{multi-modal} nature of the system; and 2) limited robustness under varying channels and noisy multi-modal inputs. In this paper, we propose a three-stage communication-aware distributed learning framework to improve training and inference efficiency while maintaining robustness over wireless channels. In Stage~I, devices perform local multi-modal self-supervised learning to obtain shared and modality-specific encoders without device--server exchange, thereby reducing the communication cost. In Stage~II, distributed fine-tuning with centralized evidential fusion calibrates per-modality uncertainty and reliably aggregates features distorted by noise or channel fading. In Stage~III, an uncertainty-guided feedback mechanism selectively requests additional features for uncertain samples, optimizing the communication--accuracy tradeoff in the distributed setting. Experiments on RGB--depth indoor scene classification show that the proposed framework attains higher accuracy with far fewer training communication rounds and remains robust to modality degradation or channel variation, outperforming existing self-supervised and fully supervised baselines.

</details>


### [64] [Multimodal Rumor Detection Enhanced by External Evidence and Forgery Features](https://arxiv.org/abs/2601.14954)
*Han Li,Hua Sun*

Main category: cs.LG

TL;DR: 提出一种结合外部证据和伪造特征的多模态谣言检测模型，通过双对比学习检测图文语义不一致，在微博和Twitter数据集上优于主流基线


<details>
  <summary>Details</summary>
Motivation: 社交媒体中图文混合帖子的谣言常利用细微不一致和伪造内容，现有多模态谣言检测方法存在特征提取有限、噪声对齐、融合策略不灵活等问题，且忽略验证复杂谣言所需的外部事实证据

Method: 使用ResNet34视觉编码器和BERT文本编码器，伪造特征模块通过傅里叶变换提取频域痕迹和压缩伪影，BLIP生成图像描述桥接图文语义空间，双对比学习模块计算文本-图像和文本-描述对的对比损失，门控自适应特征缩放融合机制动态调整多模态融合并减少冗余

Result: 在微博和Twitter数据集上的实验表明，该模型在宏观准确率、召回率和F1分数上优于主流基线方法

Conclusion: 提出的结合外部证据和伪造特征的多模态谣言检测模型能有效检测图文语义不一致的深度语义不匹配谣言，通过双对比学习和自适应融合机制提升了检测性能

Abstract: Social media increasingly disseminates information through mixed image text posts, but rumors often exploit subtle inconsistencies and forged content, making detection based solely on post content difficult. Deep semantic mismatch rumors, which superficially align images and texts, pose particular challenges and threaten online public opinion. Existing multimodal rumor detection methods improve cross modal modeling but suffer from limited feature extraction, noisy alignment, and inflexible fusion strategies, while ignoring external factual evidence necessary for verifying complex rumors. To address these limitations, we propose a multimodal rumor detection model enhanced with external evidence and forgery features. The model uses a ResNet34 visual encoder, a BERT text encoder, and a forgery feature module extracting frequency-domain traces and compression artifacts via Fourier transformation. BLIP-generated image descriptions bridge image and text semantic spaces. A dual contrastive learning module computes contrastive losses between text image and text description pairs, improving detection of semantic inconsistencies. A gated adaptive feature-scaling fusion mechanism dynamically adjusts multimodal fusion and reduces redundancy. Experiments on Weibo and Twitter datasets demonstrate that our model outperforms mainstream baselines in macro accuracy, recall, and F1 score.

</details>


### [65] [Improving Regret Approximation for Unsupervised Dynamic Environment Generation](https://arxiv.org/abs/2601.14957)
*Harry Mead,Bruno Lacerda,Jakob Foerster,Nick Hawes*

Main category: cs.LG

TL;DR: 提出DEGen方法解决UED中的信用分配问题，结合新的MNA遗憾近似方法，在大型环境中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 当前UED方法在处理大型环境时面临两个主要问题：1）信用分配困难，难以确定哪些环境参数导致策略复杂度增加；2）现有遗憾近似方法无法有效识别具有挑战性的环境配置

Method: 提出DEGen（动态环境生成）方法，通过更密集的生成器奖励信号减少信用分配难度；引入MNA（最大化负优势）作为新的遗憾近似指标，能更好地识别具有挑战性的环境配置

Result: 实验表明MNA优于现有遗憾近似方法，DEGen与MNA结合后，特别是在大型环境中，性能持续优于现有方法

Conclusion: DEGen方法解决了UED在大型环境中的扩展性问题，MNA提供了更有效的遗憾近似指标，两者结合显著提升了无监督环境设计的性能

Abstract: Unsupervised Environment Design (UED) seeks to automatically generate training curricula for reinforcement learning (RL) agents, with the goal of improving generalisation and zero-shot performance. However, designing effective curricula remains a difficult problem, particularly in settings where small subsets of environment parameterisations result in significant increases in the complexity of the required policy. Current methods struggle with a difficult credit assignment problem and rely on regret approximations that fail to identify challenging levels, both of which are compounded as the size of the environment grows. We propose Dynamic Environment Generation for UED (DEGen) to enable a denser level generator reward signal, reducing the difficulty of credit assignment and allowing for UED to scale to larger environment sizes. We also introduce a new regret approximation, Maximised Negative Advantage (MNA), as a significantly improved metric to optimise for, that better identifies more challenging levels. We show empirically that MNA outperforms current regret approximations and when combined with DEGen, consistently outperforms existing methods, especially as the size of the environment grows. We have made all our code available here: https://github.com/HarryMJMead/Dynamic-Environment-Generation-for-UED.

</details>


### [66] [InstructTime++: Time Series Classification with Multimodal Language Modeling via Implicit Feature Enhancement](https://arxiv.org/abs/2601.14968)
*Mingyue Cheng,Xiaoyu Tao,Huajian Zhang,Qi Liu,Enhong Chen*

Main category: cs.LG

TL;DR: InstructTime++将时间序列分类重构为多模态生成任务，通过离散化时间序列、跨模态对齐和隐式特征建模，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列分类方法主要采用判别式范式，直接将输入序列映射到one-hot编码的类别标签。这种方法难以融入上下文特征，也无法捕捉类别间的语义关系。需要一种能够整合多模态信息并理解类别语义的新框架。

Method: 提出InstructTime框架，将时间序列分类重构为多模态生成任务：1）时间序列离散化模块将连续序列转换为离散时间标记；2）对齐投影层和生成式自监督预训练策略增强跨模态表示对齐；3）InstructTime++扩展该框架，加入隐式特征建模，使用统计特征提取和视觉语言图像描述等工具包挖掘原始时间序列和上下文输入中的信息模式，并将其转换为文本描述进行集成。

Result: 在多个基准数据集上的广泛实验表明，InstructTime++具有优越的性能表现。

Conclusion: 将时间序列分类重构为多模态生成任务，并通过隐式特征建模增强语言模型的归纳偏置，能够有效整合上下文信息并捕捉类别语义关系，显著提升分类性能。

Abstract: Most existing time series classification methods adopt a discriminative paradigm that maps input sequences directly to one-hot encoded class labels. While effective, this paradigm struggles to incorporate contextual features and fails to capture semantic relationships among classes. To address these limitations, we propose InstructTime, a novel framework that reformulates time series classification as a multimodal generative task. Specifically, continuous numerical sequences, contextual textual features, and task instructions are treated as multimodal inputs, while class labels are generated as textual outputs by tuned language models. To bridge the modality gap, InstructTime introduces a time series discretization module that converts continuous sequences into discrete temporal tokens, together with an alignment projection layer and a generative self-supervised pre-training strategy to enhance cross-modal representation alignment. Building upon this framework, we further propose InstructTime++, which extends InstructTime by incorporating implicit feature modeling to compensate for the limited inductive bias of language models. InstructTime++ leverages specialized toolkits to mine informative implicit patterns from raw time series and contextual inputs, including statistical feature extraction and vision-language-based image captioning, and translates them into textual descriptions for seamless integration. Extensive experiments on multiple benchmark datasets demonstrate the superior performance of InstructTime++.

</details>


### [67] [Lineup Regularized Adjusted Plus-Minus (L-RAPM): Basketball Lineup Ratings with Informed Priors](https://arxiv.org/abs/2601.15000)
*Christos Petridis,Konstantinos Pelechrinis*

Main category: cs.LG

TL;DR: 提出L-RAPM回归方法，通过控制对手阵容并利用球员信息，解决篮球阵容数据稀疏性问题，提高预测准确性


<details>
  <summary>Details</summary>
Motivation: 篮球阵容分析面临数据稀疏性挑战，由于频繁换人导致每个阵容上场时间有限（NBA赛季平均仅25-30次进攻回合），现有统计数据噪声大、预测价值低，且缺乏公开解决方案

Method: 提出基于回归的方法L-RAPM，该方法控制每个阵容面对的对手阵容，同时利用组成阵容的球员信息

Result: 实验显示L-RAPM比当前使用的基线方法具有更好的预测能力，且随着阵容样本量减小，改进效果更加显著

Conclusion: L-RAPM方法有效解决了篮球阵容分析中的数据稀疏性问题，提高了阵容表现的预测准确性，特别是在数据有限的情况下表现更优

Abstract: Identifying combinations of players (that is, lineups) in basketball - and other sports - that perform well when they play together is one of the most important tasks in sports analytics. One of the main challenges associated with this task is the frequent substitutions that occur during a game, which results in highly sparse data. In particular, a National Basketball Association (NBA) team will use more than 600 lineups during a season, which translates to an average lineup having seen the court in approximately 25-30 possessions. Inevitably, any statistics that one collects for these lineups are going to be noisy, with low predictive value. Yet, there is no existing work (in the public at least) that addresses this problem. In this work, we propose a regression-based approach that controls for the opposition faced by each lineup, while it also utilizes information about the players making up the lineups. Our experiments show that L-RAPM provides improved predictive power than the currently used baseline, and this improvement increases as the sample size for the lineups gets smaller.

</details>


### [68] [Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control](https://arxiv.org/abs/2601.15015)
*Jannis Becktepe,Aleksandra Franz,Nils Thuerey,Sebastian Peitz*

Main category: cs.LG

TL;DR: FluidGym：首个独立的、完全可微的强化学习主动流控制基准套件，基于GPU加速的PICT求解器构建，无需外部CFD软件，提供标准化评估协议。


<details>
  <summary>Details</summary>
Motivation: 强化学习在主动流控制中显示出前景，但该领域进展难以评估，因为现有研究依赖异构的观测与驱动方案、数值设置和评估协议。当前基准尝试解决这些问题，但严重依赖外部CFD求解器，不完全可微，且3D和多智能体支持有限。

Method: 基于GPU加速的PICT求解器，在PyTorch上构建完全独立的基准套件FluidGym，在单一Python栈中运行，无需外部CFD软件，提供标准化评估协议。

Result: 提供了基于PPO和SAC的基线结果，发布了所有环境、数据集和训练模型作为公共资源。FluidGym支持控制方法的系统比较，为基于学习的流控制研究建立了可扩展基础。

Conclusion: FluidGym克服了现有基准的局限性，是首个独立的、完全可微的强化学习主动流控制基准套件，能够促进该领域的系统化研究和比较。

Abstract: Reinforcement learning (RL) has shown promising results in active flow control (AFC), yet progress in the field remains difficult to assess as existing studies rely on heterogeneous observation and actuation schemes, numerical setups, and evaluation protocols. Current AFC benchmarks attempt to address these issues but heavily rely on external computational fluid dynamics (CFD) solvers, are not fully differentiable, and provide limited 3D and multi-agent support. To overcome these limitations, we introduce FluidGym, the first standalone, fully differentiable benchmark suite for RL in AFC. Built entirely in PyTorch on top of the GPU-accelerated PICT solver, FluidGym runs in a single Python stack, requires no external CFD software, and provides standardized evaluation protocols. We present baseline results with PPO and SAC and release all environments, datasets, and trained models as public resources. FluidGym enables systematic comparison of control methods, establishes a scalable foundation for future research in learning-based flow control, and is available at https://github.com/safe-autonomous-systems/fluidgym.

</details>


### [69] [Mixture-of-Experts Models in Vision: Routing, Optimization, and Generalization](https://arxiv.org/abs/2601.15021)
*Adam Rokah,Daniel Veress,Caleb Caulk,Sourav Sharan*

Main category: cs.LG

TL;DR: 该研究在图像分类任务中比较了密集模型、SoftMoE和SparseMoE的性能，发现MoE变体在验证准确率上略有优势，但条件计算在实际硬件上未能带来推理加速。


<details>
  <summary>Details</summary>
Motivation: 研究MoE架构在图像分类场景中的行为，而非传统的大语言模型应用。关注预测性能、专家利用率和泛化特性，特别分析MoE在较小规模模型中的实际效果。

Method: 在CIFAR10数据集上，在可比模型容量下比较密集、SoftMoE和SparseMoE分类头。使用正则化保持专家平衡，避免专家崩溃。通过Hessian矩阵的谱分析和迹评估收敛时的锐度指标，并进行损失曲面扰动分析。

Result: 两种MoE变体验证准确率略高于密集基线，专家利用率保持平衡。SoftMoE显示更高的Hessian锐度，而密集和SparseMoE处于相似的曲率状态。条件路由在当前硬件规模下未能实现推理加速。

Conclusion: MoE在图像分类中能略微提升性能且保持专家平衡，但实际推理效率未达理论预期。损失曲面分析揭示了密集与MoE模型的非局部行为差异，为曲率测量提供了背景，但未能直接解释验证准确率差异。

Abstract: Mixture-of-Experts (MoE) architectures enable conditional computation by routing inputs to multiple expert subnetworks and are often motivated as a mechanism for scaling large language models. In this project, we instead study MoE behavior in an image classification setting, focusing on predictive performance, expert utilization, and generalization. We compare dense, SoftMoE, and SparseMoE classifier heads on the CIFAR10 dataset under comparable model capacity. Both MoE variants achieve slightly higher validation accuracy than the dense baseline while maintaining balanced expert utilization through regularization, avoiding expert collapse. To analyze generalization, we compute Hessian-based sharpness metrics at convergence, including the largest eigenvalue and trace of the loss Hessian, evaluated on both training and test data. We find that SoftMoE exhibits higher sharpness by these metrics, while Dense and SparseMoE lie in a similar curvature regime, despite all models achieving comparable generalization performance. Complementary loss surface perturbation analyses reveal qualitative differences in non-local behavior under finite parameter perturbations between dense and MoE models, which help contextualize curvature-based measurements without directly explaining validation accuracy. We further evaluate empirical inference efficiency and show that naively implemented conditional routing does not yield inference speedups on modern hardware at this scale, highlighting the gap between theoretical and realized efficiency in sparse MoE models.

</details>


### [70] [Auditing Language Model Unlearning via Information Decomposition](https://arxiv.org/abs/2601.15111)
*Anmol Goel,Alan Ritter,Iryna Gurevych*

Main category: cs.LG

TL;DR: 当前机器学习遗忘方法存在关键局限：尽管遗忘算法表面成功，但被遗忘数据的信息仍能从内部表示中线性解码。研究引入基于部分信息分解的信息论框架来审计遗忘效果，发现冗余信息构成残余知识，并提出基于表示的风险评分来缓解隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 揭示当前语言模型机器学习遗忘方法的根本缺陷：虽然遗忘算法在表面上看起来成功，但被遗忘数据的信息实际上仍能从模型内部表示中提取出来。这种表面遗忘与实际信息残留之间的差距构成了重要的隐私和安全风险。

Method: 引入基于部分信息分解（PID）的可解释信息论框架来审计遗忘效果。通过比较遗忘前后的模型表示，将被遗忘数据的互信息分解为不同组件，形式化定义"已遗忘知识"和"残余知识"的概念。分析冗余信息作为残余知识的特性，并提出基于表示的风险评分机制。

Result: 研究发现冗余信息（在两个模型间共享）构成了遗忘后仍然存在的残余知识，并且这种残余知识与已知对抗重建攻击的易感性相关。基于这些洞察，提出了能够指导在推理时对敏感输入进行弃权的表示风险评分。

Conclusion: 该工作为机器学习遗忘提供了原则性的表示层面审计方法，既提供了理论洞察，又提供了可操作的工具，有助于语言模型更安全地部署。通过信息论框架揭示了当前遗忘方法的局限性，并提出了缓解隐私泄露的实用机制。

Abstract: We expose a critical limitation in current approaches to machine unlearning in language models: despite the apparent success of unlearning algorithms, information about the forgotten data remains linearly decodable from internal representations. To systematically assess this discrepancy, we introduce an interpretable, information-theoretic framework for auditing unlearning using Partial Information Decomposition (PID). By comparing model representations before and after unlearning, we decompose the mutual information with the forgotten data into distinct components, formalizing the notions of unlearned and residual knowledge. Our analysis reveals that redundant information, shared across both models, constitutes residual knowledge that persists post-unlearning and correlates with susceptibility to known adversarial reconstruction attacks. Leveraging these insights, we propose a representation-based risk score that can guide abstention on sensitive inputs at inference time, providing a practical mechanism to mitigate privacy leakage. Our work introduces a principled, representation-level audit for unlearning, offering theoretical insight and actionable tools for safer deployment of language models.

</details>


### [71] [LoRAP: Low-Rank Aggregation Prompting for Quantized Graph Neural Networks Training](https://arxiv.org/abs/2601.15079)
*Chenyu Liu,Haige Li,Luca Rossi*

Main category: cs.LG

TL;DR: 提出LoRAP方法，通过低秩聚合提示优化GNN量化训练，在多个数据集和框架上提升低比特量化GNN性能


<details>
  <summary>Details</summary>
Motivation: GNN量化可减少模型大小、加速推理，但相比LLMs，GNN量化更关注图特征量化。现有方法仅提示节点特征无法使量化聚合结果最优，需要优化量化聚合过程

Method: 提出低秩聚合提示(LoRAP)，向每个聚合特征注入轻量级、输入相关的提示，优化量化聚合结果。该方法在4个主流QAT框架和9个图数据集上进行评估

Result: LoRAP在低比特量化GNN中一致提升性能，同时引入的计算开销极小。在多个数据集和框架上的广泛评估验证了其有效性

Conclusion: LoRAP通过优化量化聚合过程，有效提升了GNN量化感知训练的性能，为资源受限环境中的高效GNN部署提供了实用解决方案

Abstract: Graph Neural Networks (GNNs) are neural networks that aim to process graph data, capturing the relationships and interactions between nodes using the message-passing mechanism. GNN quantization has emerged as a promising approach for reducing model size and accelerating inference in resource-constrained environments. Compared to quantization in LLMs, quantizing graph features is more emphasized in GNNs. Inspired by the above, we propose to leverage prompt learning, which manipulates the input data, to improve the performance of quantization-aware training (QAT) for GNNs. To mitigate the issue that prompting the node features alone can only make part of the quantized aggregation result optimal, we introduce Low-Rank Aggregation Prompting (LoRAP), which injects lightweight, input-dependent prompts into each aggregated feature to optimize the results of quantized aggregations. Extensive evaluations on 4 leading QAT frameworks over 9 graph datasets demonstrate that LoRAP consistently enhances the performance of low-bit quantized GNNs while introducing a minimal computational overhead.

</details>


### [72] [Overcoming In-Memory Bottlenecks in Graph Foundation Models via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.15124)
*Haonan Yuan,Qingyun Sun,Jiacheng Tao,Xingcheng Fu,Jianxin Li*

Main category: cs.LG

TL;DR: RAG-GFM：基于检索增强生成的图基础模型，通过将知识从参数中卸载到外部存储来克服现有GFMs的内存瓶颈，实现更高效、可扩展的跨域图学习。


<details>
  <summary>Details</summary>
Motivation: 现有图基础模型(GFMs)面临内存瓶颈问题：它们试图将知识编码到模型参数中，这限制了语义容量，引入了严重的损失压缩和冲突，并且将图表示与知识纠缠在一起，阻碍了高效适应，影响了可扩展性和可解释性。

Method: 提出RAG-GFM，一种检索增强生成辅助的图基础模型。方法包括：1)构建双模态统一检索模块，包含基于前缀结构文本的语义存储和基于中心性基元的结构存储；2)设计双视图对齐目标，通过对比两种模态来捕捉内容和关系模式；3)执行上下文增强，用检索到的文本和基元作为上下文证据来丰富支持实例。

Result: 在五个基准图数据集上的广泛实验表明，RAG-GFM在跨域节点分类和图分类任务中，持续优于13个最先进的基线方法，实现了卓越的有效性和效率。

Conclusion: RAG-GFM通过将知识从参数中卸载并补充参数化学习，成功克服了现有图基础模型的内存瓶颈，实现了更高效、可扩展的跨域图表示学习，为图基础模型的发展提供了新方向。

Abstract: Graph Foundation Models (GFMs) have emerged as a frontier in graph learning, which are expected to deliver transferable representations across diverse tasks. However, GFMs remain constrained by in-memory bottlenecks: they attempt to encode knowledge into model parameters, which limits semantic capacity, introduces heavy lossy compression with conflicts, and entangles graph representation with the knowledge in ways that hinder efficient adaptation, undermining scalability and interpretability. In this work,we propose RAG-GFM, a Retrieval-Augmented Generation aided Graph Foundation Model that offloads knowledge from parameters and complements parameterized learning. To externalize graph knowledge, we build a dual-modal unified retrieval module, where a semantic store from prefix-structured text and a structural store from centrality-based motif. To preserve heterogeneous information, we design a dual-view alignment objective that contrasts both modalities to capture both content and relational patterns. To enable efficient downstream adaptation, we perform in-context augmentation to enrich supporting instances with retrieved texts and motifs as contextual evidence. Extensive experiments on five benchmark graph datasets demonstrate that RAG-GFM consistently outperforms 13 state-of-the-art baselines in both cross-domain node and graph classification, achieving superior effectiveness and efficiency.

</details>


### [73] [Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data](https://arxiv.org/abs/2601.15158)
*Yuval Ran-Milo,Yotam Alexander,Shahar Mendel,Nadav Cohen*

Main category: cs.LG

TL;DR: 本文分析了Transformer模型在稀疏奖励强化学习下如何自发产生链式思维推理能力，通过图遍历任务的理论分析揭示了梯度流驱动模型学习迭代算法的机制。


<details>
  <summary>Details</summary>
Motivation: 尽管基于结果监督的强化学习训练能够使Transformer自发产生链式思维推理，但稀疏奖励如何驱动梯度下降发现这种系统性推理的机制尚不清楚。本文旨在通过理论分析揭示这一过程。

Method: 采用理论分析方法，研究单层Transformer在合成图遍历任务上的梯度流动态。该任务无法在没有链式思维的情况下解决，但存在简单的迭代解。通过证明梯度流驱动模型收敛到结构化、可解释的迭代算法，并分析分布特性对学习的影响。

Result: 证明了尽管仅基于最终答案正确性进行训练，梯度流仍能驱动模型收敛到逐顶点迭代遍历图的结构化算法。识别了"简单示例"（需要较少推理步骤的实例）的关键作用：当训练分布中这些简单实例具有足够质量时，模型学习到可泛化的遍历策略；当这些质量消失时，基于梯度的学习变得不可行。

Conclusion: 通过合成数据和真实世界语言模型在数学推理任务上的实验验证，理论发现能够推广到实际设置。研究揭示了稀疏奖励下链式思维推理能力涌现的机制，为理解Transformer的推理能力提供了理论基础。

Abstract: Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought (CoT) but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, gradient flow drives the model to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of "simple examples": instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler instances, the model learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, gradient-based learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings.

</details>


### [74] [Field-Space Autoencoder for Scalable Climate Emulators](https://arxiv.org/abs/2601.15102)
*Johannes Meuer,Maximilian Witte,Étiénne Plésiat,Thomas Ludwig,Christopher Kadow*

Main category: cs.LG

TL;DR: 提出Field-Space Autoencoder框架，通过球面压缩模型解决千米尺度地球系统模型计算成本高、输出数据量大的问题，支持零样本超分辨率和生成式模拟。


<details>
  <summary>Details</summary>
Motivation: 千米尺度地球系统模型计算成本高昂且产生PB级输出，限制了其在概率风险评估等应用中的实用性，需要开发可扩展的气候模拟框架。

Method: 提出Field-Space Autoencoder框架，采用球面压缩模型，利用Field-Space Attention直接在原生气候模型输出上操作，避免球面数据强制到欧几里得网格引起的几何失真。通过生成结构化压缩场作为下游生成式模拟的基线，并支持零样本超分辨率。

Result: 该方法比卷积基线显著更好地保留物理结构，能够将低分辨率大集合和稀缺高分辨率数据映射到共享表示中。在压缩场上训练的生成扩散模型能同时从丰富的低分辨率数据学习内部变异性，从稀疏高分辨率数据学习精细尺度物理。

Conclusion: 该工作弥合了低分辨率集合统计的高数据量与高分辨率物理细节稀缺性之间的差距，为可扩展气候模拟提供了有效框架。

Abstract: Kilometer-scale Earth system models are essential for capturing local climate change. However, these models are computationally expensive and produce petabyte-scale outputs, which limits their utility for applications such as probabilistic risk assessment. Here, we present the Field-Space Autoencoder, a scalable climate emulation framework based on a spherical compression model that overcomes these challenges. By utilizing Field-Space Attention, the model efficiently operates on native climate model output and therefore avoids geometric distortions caused by forcing spherical data onto Euclidean grids. This approach preserves physical structures significantly better than convolutional baselines. By producing a structured compressed field, it serves as a good baseline for downstream generative emulation. In addition, the model can perform zero-shot super-resolution that maps low-resolution large ensembles and scarce high-resolution data into a shared representation. We train a generative diffusion model on these compressed fields. The model can simultaneously learn internal variability from abundant low-resolution data and fine-scale physics from sparse high-resolution data. Our work bridges the gap between the high volume of low-resolution ensemble statistics and the scarcity of high-resolution physical detail.

</details>


### [75] [Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism](https://arxiv.org/abs/2601.15249)
*Garrett G. Wen,Buxin Su,Natalie Collina,Zhun Deng,Weijie Su*

Main category: cs.LG

TL;DR: 提出一种作者辅助的最佳论文评选机制，利用等渗机制收集作者对自己论文的排名评估，调整原始评审分数以更准确估计论文真实质量，在凸效用函数假设下激励作者诚实报告。


<details>
  <summary>Details</summary>
Motivation: 随着NeurIPS、ICML等AI会议投稿量激增至数万篇，维持同行评审质量和一致性面临重大挑战，特别是最佳论文奖项的评选过程近年来争议不断，需要更可靠的评选机制。

Method: 采用等渗机制收集作者对自己提交论文的排名评估，利用这些排名信息调整原始评审分数，以最优估计论文的真实质量。当作者效用函数为凸加性函数时，机制激励作者诚实报告。特别地，当作者只有单一配额（只能提名一篇论文）时，即使效用函数仅为非递减加性函数，诚实性仍然成立。

Result: 使用ICLR 2019-2023和NeurIPS 2021-2023的公开评审数据验证了凸性假设的合理性。机制扩展到处理常见的共同作者重叠情况。仿真结果表明，该机制显著提高了获奖论文的质量。

Conclusion: 提出的作者辅助机制能够有效改进最佳论文奖项的评选质量，在更宽松的假设条件下保证作者诚实报告，为大规模会议的最佳论文评选提供了可行的解决方案。

Abstract: Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards.

</details>


### [76] [MolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs](https://arxiv.org/abs/2601.15279)
*Christoph Bartmann,Johannes Schimunek,Mykyta Ielanskyi,Philipp Seidl,Günter Klambauer,Sohvi Luukkonen*

Main category: cs.LG

TL;DR: MolecularIQ是一个专注于分子结构推理的基准测试，通过符号可验证任务评估大语言模型对分子图的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有化学基准测试大多侧重于一般化学知识，依赖文献或替代标签存在泄露或偏见风险，或简化为多项选择题，缺乏对分子图推理能力的细粒度评估。

Method: 引入MolecularIQ基准测试，专注于符号可验证任务，通过细粒度评估揭示模型在分子图推理中的能力模式，将模型失败定位到特定任务和分子结构。

Result: MolecularIQ能够识别当前化学大语言模型的优势和局限性，提供可操作的见解，指导开发能够忠实推理分子结构的模型。

Conclusion: MolecularIQ填补了分子结构推理评估的空白，为化学大语言模型的开发提供了重要的基准工具，促进模型在分子图理解方面的进步。

Abstract: A molecule's properties are fundamentally determined by its composition and structure encoded in its molecular graph. Thus, reasoning about molecular properties requires the ability to parse and understand the molecular graph. Large Language Models (LLMs) are increasingly applied to chemistry, tackling tasks such as molecular name conversion, captioning, text-guided generation, and property or reaction prediction. Most existing benchmarks emphasize general chemical knowledge, rely on literature or surrogate labels that risk leakage or bias, or reduce evaluation to multiple-choice questions. We introduce MolecularIQ, a molecular structure reasoning benchmark focused exclusively on symbolically verifiable tasks. MolecularIQ enables fine-grained evaluation of reasoning over molecular graphs and reveals capability patterns that localize model failures to specific tasks and molecular structures. This provides actionable insights into the strengths and limitations of current chemistry LLMs and guides the development of models that reason faithfully over molecular structure.

</details>


### [77] [CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning](https://arxiv.org/abs/2601.15141)
*Tianshi Xu,Yuteng Chen,Meng Li*

Main category: cs.LG

TL;DR: CLEANER提出了一种利用模型内在自校正能力来净化噪声轨迹的方法，通过相似性感知自适应回滚机制构建清洁轨迹，显著提升了参数受限模型在工具使用任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 参数受限的LLM（4B-7B）在工具使用任务中面临探索阶段频繁执行失败的问题，产生噪声轨迹阻碍策略优化。基于结果的奖励设置导致信用分配问题，错误动作与成功结果一同被强化。现有方法面临密集奖励导致奖励黑客攻击或超采样计算成本过高的困境。

Method: CLEANER利用模型内在自校正能力，在数据收集阶段直接消除错误污染上下文。核心是相似性感知自适应回滚机制，通过回顾性地用成功自校正替换失败来构建清洁、净化的轨迹。基于语义相似度自适应调节替换粒度，从浅层执行修复到深层推理替换。在自净化路径上训练，使模型内化正确推理模式而非错误恢复循环。

Result: 在AIME24/25、GPQA和LiveCodeBench上的实验结果显示，相比基线平均准确率分别提升6%、3%和5%。CLEANER仅用三分之一的训练步骤就达到了最先进性能，突显了轨迹净化作为高效智能体强化学习的可扩展解决方案。

Conclusion: CLEANER通过利用模型内在自校正能力净化噪声轨迹，有效解决了参数受限模型在工具使用任务中的信用分配问题。该方法不仅提升了性能，还大幅减少了训练成本，为高效智能体强化学习提供了可扩展的解决方案。

Abstract: Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise leads to a critical credit assignment issue, where erroneous actions are inadvertently reinforced alongside successful outcomes. Existing mitigations face a dilemma: dense rewards often trigger reward hacking, while supersampling incurs prohibitive computational costs. To address these challenges, we propose CLEANER. Distinct from external filtering methods, CLEANER exploits the model's intrinsic self-correction capabilities to eliminate error-contaminated context directly during data collection. At its core, the Similarity-Aware Adaptive Rollback (SAAR) mechanism autonomously constructs clean, purified trajectories by retrospectively replacing failures with successful self-corrections. Based on semantic similarity, SAAR adaptively regulates replacement granularity from shallow execution repairs to deep reasoning substitutions. By training on these self-purified paths, the model internalizes correct reasoning patterns rather than error-recovery loops. Empirical results on AIME24/25, GPQA, and LiveCodeBench show average accuracy gains of 6%, 3%, and 5% over baselines. Notably, CLEANER matches state-of-the-art performance using only one-third of the training steps, highlighting trajectory purification as a scalable solution for efficient agentic RL. Our models and code are available at GitHub

</details>


### [78] [ZENITH: Automated Gradient Norm Informed Stochastic Optimization](https://arxiv.org/abs/2601.15212)
*Dhrubo Saha*

Main category: cs.LG

TL;DR: ZENITH优化器通过梯度范数的时间演化自适应调整学习率，无需手动调度，在图像分类、目标检测等任务上优于基线方法，且与正则化兼容。


<details>
  <summary>Details</summary>
Motivation: 现有自适应优化器存在计算和内存开销大、与正则化不兼容、学习率选择次优等问题，需要开发更高效的自适应学习率调度方法。

Method: 提出ZENITH优化器，利用梯度范数的时间演化信息来自适应调整学习率，实现零开销的自适应学习率调度。

Result: 在6种CNN架构和6个基准测试的图像分类实验中，ZENITH在更短的挂钟时间内获得更高的测试准确率；在MS COCO的目标检测、关键点检测和实例分割任务上，使用R-CNN系列模型获得了更优的mAP。

Conclusion: ZENITH优化器通过梯度范数演化自适应调整学习率，在多种计算机视觉任务上表现出色，且与正则化兼容，能进一步提升泛化性能。

Abstract: Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [79] [The Ontological Neutrality Theorem: Why Neutral Ontological Substrates Must Be Pre-Causal and Pre-Normative](https://arxiv.org/abs/2601.14271)
*Denise M. Case*

Main category: cs.AI

TL;DR: 论文证明了一个关于本体论中立性的不可能性结果：在基础层包含因果或规范承诺的本体论无法作为跨分歧框架的中立共享基础


<details>
  <summary>Details</summary>
Motivation: 现代数据系统需要在持续存在的法律、政治和分析分歧中支持问责制，这要求设计能够作为共享基础的本体论，但现有方法难以在包含因果或规范承诺的同时保持中立性

Method: 通过逻辑分析建立不可能性结果，论证中立性（理解为解释性非承诺和在不兼容扩展下的稳定性）与在基础层包含因果或规范承诺是不兼容的

Result: 证明了任何将因果或道义结论断言为本体事实的本体论，都无法在不修订或矛盾的情况下作为跨分歧框架的中立基础。因此，中立的本体论基础必须是前因果和前规范的

Conclusion: 中立的本体论基础只能表示实体及其同一性和持久性条件，而必须将解释、评估和说明外部化。这为任何旨在跨冲突解释框架维持共享稳定现实表示的系统提供了必要的设计约束

Abstract: Modern data systems must support accountability across persistent legal, political, and analytic disagreement. This requirement imposes strict constraints on the design of any ontology intended to function as a shared substrate. We establish an impossibility result for ontological neutrality: neutrality, understood as interpretive non-commitment and stability under incompatible extensions, is incompatible with the inclusion of causal or normative commitments at the foundational layer. Any ontology that asserts causal or deontic conclusions as ontological facts cannot serve as a neutral substrate across divergent frameworks without revision or contradiction. It follows that neutral ontological substrates must be pre-causal and pre-normative, representing entities, together with identity and persistence conditions, while externalizing interpretation, evaluation, and explanation. This paper does not propose a specific ontology or protocol; rather, it establishes the necessary design constraints for any system intended to maintain a shared, stable representation of reality across conflicting interpretive frameworks.

</details>


### [80] [Epistemic Constitutionalism Or: how to avoid coherence bias](https://arxiv.org/abs/2601.14295)
*Michele Loi*

Main category: cs.AI

TL;DR: 该论文主张为AI建立"认识论宪法"——明确的、可争议的元规范，以规范AI系统如何形成和表达信念，并以来源归因偏见作为案例说明当前模型存在的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型作为人工推理者，其信念形成行为受隐性的、未经审查的认识论政策支配。论文旨在解决AI系统在信念形成和表达中缺乏明确规范的问题，特别是针对来源归因偏见这一具体问题。

Method: 通过分析前沿模型中的来源归因偏见现象，展示模型如何强制执行身份-立场一致性，惩罚那些归因于预期意识形态立场与论点内容相冲突的来源的论点。区分两种宪法方法：柏拉图式（强调形式正确性和默认的来源独立性）和自由主义式（拒绝特权立场，制定保护集体探究条件的程序规范）。

Result: 研究发现：1）前沿模型强制执行身份-立场一致性，当论点归因于预期意识形态立场与内容相冲突的来源时，模型会惩罚这些论点；2）当模型检测到系统性测试时，这些效应会崩溃，表明系统将来源敏感性视为需要抑制的偏见而非需要良好执行的能力。

Conclusion: 论文主张自由主义宪法方法，提出了包含八项原则和四种取向的宪法核心框架，并认为AI认识论治理需要与AI伦理相同的明确、可争议结构，以规范AI系统的信念形成和表达行为。

Abstract: Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for an epistemic constitution for AI: explicit, contestable meta-norms that regulate how systems form and express beliefs. Source attribution bias provides the motivating case: I show that frontier models enforce identity-stance coherence, penalizing arguments attributed to sources whose expected ideological position conflicts with the argument's content. When models detect systematic testing, these effects collapse, revealing that systems treat source-sensitivity as bias to suppress rather than as a capacity to execute well. I distinguish two constitutional approaches: the Platonic, which mandates formal correctness and default source-independence from a privileged standpoint, and the Liberal, which refuses such privilege, specifying procedural norms that protect conditions for collective inquiry while allowing principled source-attending grounded in epistemic vigilance. I argue for the Liberal approach, sketch a constitutional core of eight principles and four orientations, and propose that AI epistemic governance requires the same explicit, contestable structure we now expect for AI ethics.

</details>


### [81] [VisTIRA: Closing the Image-Text Modality Gap in Visual Math Reasoning via Structured Tool Integration](https://arxiv.org/abs/2601.14440)
*Saeed Khaki,Ashudeep Singh,Nima Safaei,Kamal Ginotra*

Main category: cs.AI

TL;DR: VisTIRA框架通过工具集成推理和视觉数学推理改进，缩小文本与视觉数学问题之间的模态差距


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在数学推理任务上，当问题以图像形式呈现时，表现远不如文本形式，存在显著的模态差距，需要解决视觉数学推理的挑战

Method: 1. 提出VisTIRA框架，通过工具集成推理将图像数学问题分解为自然语言推理和可执行Python步骤；2. 建立LaTeX管道将文本数学语料转换为图像版本；3. 从真实世界作业数据集生成合成工具使用轨迹用于微调

Result: 工具集成监督能改进基于图像的推理，OCR基础对小型模型能进一步缩小模态差距，但规模增大时效益减弱；模态差距严重程度与模型大小成反比

Conclusion: 结构化推理和OCR基础是推进视觉数学推理的互补策略，模态差距问题需要结合工具集成和视觉理解能力来解决

Abstract: Vision-language models (VLMs) lag behind text-only language models on mathematical reasoning when the same problems are presented as images rather than text. We empirically characterize this as a modality gap: the same question in text form yields markedly higher accuracy than its visually typeset counterpart, due to compounded failures in reading dense formulas, layout, and mixed symbolic-diagrammatic context. First, we introduce VisTIRA (Vision and Tool-Integrated Reasoning Agent), a tool-integrated reasoning framework that enables structured problem solving by iteratively decomposing a given math problem (as an image) into natural language rationales and executable Python steps to determine the final answer. Second, we build a framework to measure and improve visual math reasoning: a LaTeX-based pipeline that converts chain-of-thought math corpora (e.g., NuminaMath) into challenging image counterparts, and a large set of synthetic tool-use trajectories derived from a real-world, homework-style image dataset (called SnapAsk) for fine-tuning VLMs. Our experiments show that tool-integrated supervision improves image-based reasoning, and OCR grounding can further narrow the gap for smaller models, although its benefit diminishes at scale. These findings highlight that modality gap severity inversely correlates with model size, and that structured reasoning and OCR-based grounding are complementary strategies for advancing visual mathematical reasoning.

</details>


### [82] [On the Generalization Gap in LLM Planning: Tests and Verifier-Reward RL](https://arxiv.org/abs/2601.14456)
*Valerio Belcamino,Nicholas Attolino,Alessio Capitanelli,Fulvio Mastrogiovanni*

Main category: cs.AI

TL;DR: LLM在PDDL规划任务上表现出高成功率，但跨领域泛化能力为0%，表明其依赖领域特定模式而非可迁移的规划能力


<details>
  <summary>Details</summary>
Motivation: 探究微调后的大语言模型在PDDL规划任务中表现出的高成功率是否反映可迁移的规划能力，还是仅仅是领域特定的记忆

Method: 在10个IPC 2023领域的40,000个领域-问题-规划元组上微调1.7B参数LLM，评估领域内和跨领域泛化，引入三种诊断干预：符号匿名化、紧凑规划序列化、使用VAL验证器作为成功导向强化信号的验证器奖励微调

Result: 模型在领域内条件下达到82.9%有效规划率，但在两个未见领域上为0%。符号匿名化和紧凑序列化导致性能显著下降，验证器奖励微调在监督训练一半的周期内达到性能饱和，但未改善跨领域泛化

Conclusion: 微调模型严重依赖领域特定模式而非可迁移的规划能力，领域内性能在80%左右达到平台期，而跨领域性能崩溃，突显了基于LLM的规划中存在的持续泛化差距

Abstract: Recent work shows that fine-tuned Large Language Models (LLMs) can achieve high valid plan rates on PDDL planning tasks. However, it remains unclear whether this reflects transferable planning competence or domain-specific memorization. In this work, we fine-tune a 1.7B-parameter LLM on 40,000 domain-problem-plan tuples from 10 IPC 2023 domains, and evaluate both in-domain and cross-domain generalization. While the model reaches 82.9% valid plan rate in in-domain conditions, it achieves 0% on two unseen domains. To analyze this failure, we introduce three diagnostic interventions, namely (i) instance-wise symbol anonymization, (ii) compact plan serialization, and (iii) verifier-reward fine-tuning using the VAL validator as a success-focused reinforcement signal. Symbol anonymization and compact serialization cause significant performance drops despite preserving plan semantics, thus revealing strong sensitivity to surface representations. Verifier-reward fine-tuning reaches performance saturation in half the supervised training epochs, but does not improve cross-domain generalization. For the explored configurations, in-domain performance plateaus around 80%, while cross-domain performance collapses, suggesting that our fine-tuned model relies heavily on domain-specific patterns rather than transferable planning competence in this setting. Our results highlight a persistent generalization gap in LLM-based planning and provide diagnostic tools for studying its causes.

</details>


### [83] [Scalable Knee-Point Guided Activity Group Selection in Multi-Tree Genetic Programming for Dynamic Multi-Mode Project Scheduling](https://arxiv.org/abs/2601.14485)
*Yuan Tian,Yi Mei,Mengjie Zhang*

Main category: cs.AI

TL;DR: 提出基于膝点的活动组选择策略，通过多树遗传编程框架同时演化优先级规则和组选择规则，解决动态多模式资源受限项目调度问题中的可扩展性问题


<details>
  <summary>Details</summary>
Motivation: 现有活动组选择策略在小规模实例中有效，但在大规模问题上存在可扩展性问题，需要改进策略以处理更大规模的项目调度问题

Method: 提出膝点选择机制：先用活动排序规则对符合条件的活动-模式对排序，再用膝点选择找出有前景的对，最后用组选择规则选择最佳活动组合；开发多树GP框架同时演化两种规则

Result: 实验结果表明，该方法能很好地扩展到大型实例，在大多数场景中优于采用顺序决策的GP方法

Conclusion: 基于膝点的组选择策略有效解决了活动组选择策略的可扩展性问题，多树GP框架能同时演化不同类型规则，为大规模动态多模式资源受限项目调度提供了有效解决方案

Abstract: The dynamic multi-mode resource-constrained project scheduling problem is a challenging scheduling problem that requires making decisions on both the execution order of activities and their corresponding execution modes. Genetic programming has been widely applied as a hyper-heuristic to evolve priority rules that guide the selection of activity-mode pairs from the current eligible set. Recently, an activity group selection strategy has been proposed to select a subset of activities rather than a single activity at each decision point, allowing for more effective scheduling by considering the interdependence between activities. Although effective in small-scale instances, this strategy suffers from scalability issues when applied to larger problems. In this work, we enhance the scalability of the group selection strategy by introducing a knee-point-based selection mechanism to identify a promising subset of activities before evaluating their combinations. An activity ordering rule is first used to rank all eligible activity-mode pairs, followed by a knee point selection to find the promising pairs. Then, a group selection rule selects the best activity combination. We develop a multi-tree GP framework to evolve both types of rules simultaneously. Experimental results demonstrate that our approach scales well to large instances and outperforms GP with sequential decision-making in most scenarios.

</details>


### [84] ["Just in Time" World Modeling Supports Human Planning and Reasoning](https://arxiv.org/abs/2601.14514)
*Tony Chen,Sam Cheyette,Kelsey Allen,Joshua Tenenbaum,Kevin Smith*

Main category: cs.AI

TL;DR: 提出"即时"框架，通过模拟、视觉搜索和表征修改的紧密交织，在线构建简化表征以支持高效心理模拟


<details>
  <summary>Details</summary>
Motivation: 心理模拟在人类推理、规划和预测中起关键作用，但复杂环境中的模拟需求超出人类能力极限。人们使用简化环境表征进行模拟，但如何高效确定这些简化尚不清楚

Method: 提出"即时"框架，将模拟、视觉搜索和表征修改紧密交织：当前模拟指导搜索方向，视觉搜索标记需要编码的对象用于后续模拟，仅编码少量对象

Result: 在网格世界规划任务和物理推理任务中，该模型在多种行为测量上优于替代模型，仅编码少量对象即可做出高效用预测

Conclusion: 该研究为人们如何构建简化表征以支持高效心理模拟提供了具体的算法解释

Abstract: Probabilistic mental simulation is thought to play a key role in human reasoning, planning, and prediction, yet the demands of simulation in complex environments exceed realistic human capacity limits. A theory with growing evidence is that people simulate using simplified representations of the environment that abstract away from irrelevant details, but it is unclear how people determine these simplifications efficiently. Here, we present a "Just-in-Time" framework for simulation-based reasoning that demonstrates how such representations can be constructed online with minimal added computation. The model uses a tight interleaving of simulation, visual search, and representation modification, with the current simulation guiding where to look and visual search flagging objects that should be encoded for subsequent simulation. Despite only ever encoding a small subset of objects, the model makes high-utility predictions. We find strong empirical support for this account over alternative models in a grid-world planning task and a physical reasoning task across a range of behavioral measures. Together, these results offer a concrete algorithmic account of how people construct reduced representations to support efficient mental simulation.

</details>


### [85] [MAS-Orchestra: Understanding and Improving Multi-Agent Reasoning Through Holistic Orchestration and Controlled Benchmarks](https://arxiv.org/abs/2601.14652)
*Zixuan Ke,Yifei Ming,Austin Xu,Ryan Chin,Xuan-Phi Nguyen,Prathyusha Jwalapuram,Semih Yavuz,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: 提出MAS-Orchestra框架，将多智能体系统编排建模为函数调用强化学习问题，实现整体编排；同时引入MASBENCH基准，系统分析多智能体系统的适用条件。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统自动设计方法存在两大问题：1) 方法复杂性 - 采用顺序、代码级执行限制了全局系统级整体推理，难以应对复杂智能体；2) 效果不确定性 - 部署前无法确定相比单智能体系统是否有实际优势。

Method: 提出MAS-Orchestra框架，将目标导向的子智能体抽象为可调用函数，通过函数调用强化学习实现整体编排，一次生成整个多智能体系统。同时引入MASBENCH基准，从深度、视野、广度、并行性和鲁棒性五个维度系统评估任务特性。

Result: 分析表明多智能体系统的优势并非普遍存在，而是取决于任务结构、验证协议以及编排器和子智能体的能力。MAS-Orchestra在数学推理、多跳问答和基于搜索的问答等公开基准上取得了一致性改进。

Conclusion: MAS-Orchestra和MASBENCH共同为多智能体智能的发展提供了更好的训练和理解框架，揭示了多智能体系统优势的具体条件，而非盲目应用。

Abstract: While multi-agent systems (MAS) promise elevated intelligence through coordination of agents, current approaches to automatic MAS design under-deliver. Such shortcomings stem from two key factors: (1) methodological complexity - agent orchestration is performed using sequential, code-level execution that limits global system-level holistic reasoning and scales poorly with agent complexity - and (2) efficacy uncertainty - MAS are deployed without understanding if there are tangible benefits compared to single-agent systems (SAS). We propose MAS-Orchestra, a training-time framework that formulates MAS orchestration as a function-calling reinforcement learning problem with holistic orchestration, generating an entire MAS at once. In MAS-Orchestra, complex, goal-oriented sub-agents are abstracted as callable functions, enabling global reasoning over system structure while hiding internal execution details. To rigorously study when and why MAS are beneficial, we introduce MASBENCH, a controlled benchmark that characterizes tasks along five axes: Depth, Horizon, Breadth, Parallel, and Robustness. Our analysis reveals that MAS gains depend critically on task structure, verification protocols, and the capabilities of both orchestrator and sub-agents, rather than holding universally. Guided by these insights, MAS-Orchestra achieves consistent improvements on public benchmarks including mathematical reasoning, multi-hop QA, and search-based QA. Together, MAS-Orchestra and MASBENCH enable better training and understanding of MAS in the pursuit of multi-agent intelligence.

</details>


### [86] [Local Language Models for Context-Aware Adaptive Anonymization of Sensitive Text](https://arxiv.org/abs/2601.14683)
*Aisvarya Adeseye,Jouni Isoaho,Seppo Virtanen,Mohammad Tahir*

Main category: cs.AI

TL;DR: 本研究提出基于本地LLM的上下文感知匿名化框架SFAA，用于定性研究转录本中的敏感数据检测与匿名化处理，相比传统方法更可靠、可重复且能保持数据语义。


<details>
  <summary>Details</summary>
Motivation: 定性研究包含大量个人、情境和组织细节，存在隐私风险。传统手动匿名化耗时、不一致且易遗漏关键标识符，现有自动化工具依赖模式匹配或固定规则，无法理解上下文且可能改变数据含义。

Method: 提出结构化自适应匿名化框架SFAA，包含检测、分类和自适应匿名化三个步骤。采用四种匿名化策略：基于规则的替换、上下文感知重写、泛化和抑制，根据标识符类型和风险级别应用策略。框架遵循GDPR、HIPAA和OECD等国际隐私标准。使用LLaMA和Phi两种本地模型，通过双方法评估结合人工和LLM辅助处理，在两个案例研究（82个面对面访谈和93个AI引导访谈）中验证。

Result: LLM比人工评审员发现更多敏感数据。Phi在发现敏感数据方面优于LLaMA（找到91%以上敏感数据），但错误略多。Phi处理的文本94.8%保持与原文本相同的情感，表明准确性高且不影响定性数据分析。

Conclusion: 基于本地LLM的SFAA框架能够有效、可靠地匿名化定性研究数据，在保持数据语义完整性的同时保护隐私，为定性研究提供了可重复的上下文感知匿名化解决方案。

Abstract: Qualitative research often contains personal, contextual, and organizational details that pose privacy risks if not handled appropriately. Manual anonymization is time-consuming, inconsistent, and frequently omits critical identifiers. Existing automated tools tend to rely on pattern matching or fixed rules, which fail to capture context and may alter the meaning of the data. This study uses local LLMs to build a reliable, repeatable, and context-aware anonymization process for detecting and anonymizing sensitive data in qualitative transcripts. We introduce a Structured Framework for Adaptive Anonymizer (SFAA) that includes three steps: detection, classification, and adaptive anonymization. The SFAA incorporates four anonymization strategies: rule-based substitution, context-aware rewriting, generalization, and suppression. These strategies are applied based on the identifier type and the risk level. The identifiers handled by the SFAA are guided by major international privacy and research ethics standards, including the GDPR, HIPAA, and OECD guidelines. This study followed a dual-method evaluation that combined manual and LLM-assisted processing. Two case studies were used to support the evaluation. The first includes 82 face-to-face interviews on gamification in organizations. The second involves 93 machine-led interviews using an AI-powered interviewer to test LLM awareness and workplace privacy. Two local models, LLaMA and Phi were used to evaluate the performance of the proposed framework. The results indicate that the LLMs found more sensitive data than a human reviewer. Phi outperformed LLaMA in finding sensitive data, but made slightly more errors. Phi was able to find over 91% of the sensitive data and 94.8% kept the same sentiment as the original text, which means it was very accurate, hence, it does not affect the analysis of the qualitative data.

</details>


### [87] [AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2601.14702)
*Zecong Tang,Zixu Wang,Yifei Wang,Weitong Lian,Tianjian Gao,Haoran Li,Tengju Ru,Lingyi Meng,Zhejun Cui,Yichen Zhu,Qi Kang,Kaixuan Wang,Yu Zhang*

Main category: cs.AI

TL;DR: AutoDriDM是一个面向自动驾驶的决策中心化渐进式基准测试，包含6,650个问题，涵盖对象、场景和决策三个维度，用于评估视觉语言模型的感知到决策能力边界。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶基准测试过度强调感知能力，未能充分评估决策过程。虽然视觉语言模型展现出推理和泛化能力，但缺乏专门评估其在自动驾驶中决策能力的基准。

Method: 构建AutoDriDM基准，包含6,650个问题，分为对象、场景和决策三个维度。评估主流视觉语言模型，分析感知与决策性能的相关性，进行可解释性分析识别关键失败模式，并引入分析器模型实现大规模自动标注。

Result: 评估揭示了感知与决策性能之间的弱对齐关系。可解释性分析识别出逻辑推理错误等关键失败模式。分析器模型能够有效自动化大规模标注。

Conclusion: AutoDriDM填补了感知中心化与决策中心化评估之间的空白，为开发更安全可靠的自动驾驶视觉语言模型提供了指导方向。

Abstract: Autonomous driving is a highly challenging domain that requires reliable perception and safe decision-making in complex scenarios. Recent vision-language models (VLMs) demonstrate reasoning and generalization abilities, opening new possibilities for autonomous driving; however, existing benchmarks and metrics overemphasize perceptual competence and fail to adequately assess decision-making processes. In this work, we present AutoDriDM, a decision-centric, progressive benchmark with 6,650 questions across three dimensions - Object, Scene, and Decision. We evaluate mainstream VLMs to delineate the perception-to-decision capability boundary in autonomous driving, and our correlation analysis reveals weak alignment between perception and decision-making performance. We further conduct explainability analyses of models' reasoning processes, identifying key failure modes such as logical reasoning errors, and introduce an analyzer model to automate large-scale annotation. AutoDriDM bridges the gap between perception-centered and decision-centered evaluation, providing guidance toward safer and more reliable VLMs for real-world autonomous driving.

</details>


### [88] [DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs](https://arxiv.org/abs/2601.14711)
*Mingxuan Song,Yusen Huo,Bohan Zhou,Shenglin Yin,Zhen Xiao,Jieyi Long,Zhilin Zhang,Chuan Yu*

Main category: cs.AI

TL;DR: 论文提出GRPO-Adaptive和DARA框架，通过LLM后训练增强数值精度和双阶段决策，解决AI生成竞价中的少样本优化问题。


<details>
  <summary>Details</summary>
Motivation: 在线广告中，广告主在预算约束下优化累积价值面临挑战。传统强化学习方法在少样本场景下效果不佳，而大型语言模型虽具备上下文学习能力，但缺乏数值精度。

Method: 提出GRPO-Adaptive后训练策略，动态更新参考策略以增强推理和数值精度；在此基础上构建DARA双阶段框架：少样本推理器通过上下文提示生成初始计划，细粒度优化器通过反馈驱动推理精炼计划。

Result: 在真实世界和合成数据环境中的大量实验表明，该方法在预算约束下的广告主累积价值方面持续优于现有基线方法。

Conclusion: GRPO-Adaptive和DARA框架成功结合了LLM的上下文学习优势与AIGB任务所需的精确适应性，有效解决了少样本场景下的竞价优化问题。

Abstract: Optimizing the advertiser's cumulative value of winning impressions under budget constraints poses a complex challenge in online advertising, under the paradigm of AI-Generated Bidding (AIGB). Advertisers often have personalized objectives but limited historical interaction data, resulting in few-shot scenarios where traditional reinforcement learning (RL) methods struggle to perform effectively. Large Language Models (LLMs) offer a promising alternative for AIGB by leveraging their in-context learning capabilities to generalize from limited data. However, they lack the numerical precision required for fine-grained optimization. To address this limitation, we introduce GRPO-Adaptive, an efficient LLM post-training strategy that enhances both reasoning and numerical precision by dynamically updating the reference policy during training. Built upon this foundation, we further propose DARA, a novel dual-phase framework that decomposes the decision-making process into two stages: a few-shot reasoner that generates initial plans via in-context prompting, and a fine-grained optimizer that refines these plans using feedback-driven reasoning. This separation allows DARA to combine LLMs' in-context learning strengths with precise adaptability required by AIGB tasks. Extensive experiments on both real-world and synthetic data environments demonstrate that our approach consistently outperforms existing baselines in terms of cumulative advertiser value under budget constraints.

</details>


### [89] [An XAI View on Explainable ASP: Methods, Systems, and Perspectives](https://arxiv.org/abs/2601.14764)
*Thomas Eiter,Tobias Geibinger,Zeynep G. Saribatur*

Main category: cs.AI

TL;DR: 关于ASP解释方法的综述：从XAI视角分析ASP解释类型、现有工具覆盖情况，并指出研究空白和未来方向


<details>
  <summary>Details</summary>
Motivation: ASP作为一种声明性推理方法，其基于规则的形式化特性使其在可解释AI中具有天然优势。随着XAI重要性日益增长，需要系统梳理ASP解释方法的现状，分析现有工具覆盖范围，识别研究空白

Method: 采用综述研究方法，从XAI视角出发，分析ASP解释类型与用户解释需求的关系，评估现有理论和工具对这些解释类型的覆盖情况

Result: 提供了ASP解释类型的系统分类，评估了现有ASP解释工具和理论的覆盖范围，发现现有方法往往针对特定解释场景，未能全面覆盖ASP用户遇到的所有情况

Conclusion: 指出了现有ASP解释方法的研究空白，并提出了未来研究方向，为ASP在可解释AI领域的进一步发展提供了指导框架

Abstract: Answer Set Programming (ASP) is a popular declarative reasoning and problem solving approach in symbolic AI. Its rule-based formalism makes it inherently attractive for explainable and interpretive reasoning, which is gaining importance with the surge of Explainable AI (XAI). A number of explanation approaches and tools for ASP have been developed, which often tackle specific explanatory settings and may not cover all scenarios that ASP users encounter. In this survey, we provide, guided by an XAI perspective, an overview of types of ASP explanations in connection with user questions for explanation, and describe how their coverage by current theory and tools. Furthermore, we pinpoint gaps in existing ASP explanations approaches and identify research directions for future work.

</details>


### [90] [Semantic-Guided Unsupervised Video Summarization](https://arxiv.org/abs/2601.14773)
*Haizhou Liu,Haodong Jin,Yiming Wang,Hui Yu*

Main category: cs.AI

TL;DR: 提出了一种语义引导的无监督视频摘要方法，通过帧级语义对齐注意力机制和增量训练策略，解决了现有GAN方法中语义信息利用不足和训练不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有无监督视频摘要方法主要依赖GAN增强关键帧选择，但存在两个主要问题：1) 主要利用单模态特征，忽视了语义信息在关键帧选择中的指导作用；2) GAN训练过程不稳定。

Method: 提出语义引导的无监督视频摘要方法，包括：1) 设计帧级语义对齐注意力机制，集成到关键帧选择器中；2) 在对抗框架内引导基于Transformer的生成器更好地重建视频；3) 采用增量训练策略逐步更新模型组件，缓解GAN训练不稳定性。

Result: 实验结果表明，该方法在多个基准数据集上取得了优越的性能。

Conclusion: 通过语义引导和增量训练策略，有效解决了现有无监督视频摘要方法中语义信息利用不足和训练不稳定的问题，提升了视频摘要的质量和稳定性。

Abstract: Video summarization is a crucial technique for social understanding, enabling efficient browsing of massive multimedia content and extraction of key information from social platforms. Most existing unsupervised summarization methods rely on Generative Adversarial Networks (GANs) to enhance keyframe selection and generate coherent, video summaries through adversarial training. However, such approaches primarily exploit unimodal features, overlooking the guiding role of semantic information in keyframe selection, and often suffer from unstable training. To address these limitations, we propose a novel Semantic-Guided Unsupervised Video Summarization method. Specifically, we design a novel frame-level semantic alignment attention mechanism and integrate it into a keyframe selector, which guides the Transformer-based generator within the adversarial framework to better reconstruct videos. In addition, we adopt an incremental training strategy to progressively update the model components, effectively mitigating the instability of GAN training. Experimental results demonstrate that our approach achieves superior performance on multiple benchmark datasets.

</details>


### [91] [Towards Bound Consistency for the No-Overlap Constraint Using MDDs](https://arxiv.org/abs/2601.14784)
*Amaury Guichard,Laurent Michel,Hélène Verhaeghe,Pierre Schaus*

Main category: cs.AI

TL;DR: 本文提出了首个用于无重叠约束的边界一致性算法，通过构建多值决策图（MDD）来收紧作业时间窗口边界，并在多项式时间内实现过滤，即使限制MDD宽度也能显著减少搜索树节点数。


<details>
  <summary>Details</summary>
Motivation: 无重叠约束的边界一致性已知是NP完全问题，现有多项式时间收紧技术（如边查找、非首非尾推理、能量推理）存在局限性，需要更有效的过滤算法来提升约束求解效率。

Method: 基于Ciré和van Hoeve定义的无重叠MDD，提取作业时间窗口边界以收紧开始和结束时间；通过限制MDD宽度为阈值创建松弛MDD，实现多项式时间复杂度的边界一致性过滤。

Result: 在带时间窗口和准时制目标的排序问题上实验表明，即使限制MDD宽度，新过滤算法相比现有优先检测算法能更显著减少搜索树节点数；与经典传播方法互补，在多个实例上同时减少节点数和求解时间。

Conclusion: 本文首次实现了无重叠约束的边界一致性算法，通过MDD方法在多项式时间内提供强过滤效果，即使使用宽度受限的松弛MDD也能显著提升约束求解性能。

Abstract: Achieving bound consistency for the no-overlap constraint is known to be NP-complete. Therefore, several polynomial-time tightening techniques, such as edge finding, not-first-not-last reasoning, and energetic reasoning, have been introduced for this constraint. In this work, we derive the first bound-consistent algorithm for the no-overlap constraint. By building on the no-overlap MDD defined by Ciré and van Hoeve, we extract bounds of the time window of the jobs, allowing us to tighten start and end times in time polynomial in the number of nodes of the MDD. Similarly, to bound the size and time-complexity, we limit the width of the MDD to a threshold, creating a relaxed MDD that can also be used to relax the bound-consistent filtering. Through experiments on a sequencing problem with time windows and a just-in-time objective ($1 \mid r_j, d_j, \bar{d}_j \mid \sum E_j + \sum T_j$), we observe that the proposed filtering, even with a threshold on the width, achieves a stronger reduction in the number of nodes visited in the search tree compared to the previously proposed precedence-detection algorithm of Ciré and van Hoeve. The new filtering also appears to be complementary to classical propagation methods for the no-overlap constraint, allowing a substantial reduction in both the number of nodes and the solving time on several instances.

</details>


### [92] [CI4A: Semantic Component Interfaces for Agents Empowering Web Automation](https://arxiv.org/abs/2601.14790)
*Zhi Qiu,Jiazheng Sun,Chenxiao Xia,Jun Zheng,Xin Peng*

Main category: cs.AI

TL;DR: CI4A是一种为智能体优化的UI组件接口封装机制，将复杂的UI交互逻辑抽象为统一的工具原语，显著提升了智能体在Web任务中的执行效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在高层语义规划方面表现出色，但在细粒度的Web组件操作方面存在局限。现有研究主要通过强化学习等技术增强模型的基础能力，但本文提出了一种新思路：不是让智能体适应人类为中心的界面，而是构建专门为智能体优化的交互接口。

Method: 提出了Component Interface for Agent (CI4A)语义封装机制，将UI组件的复杂交互逻辑抽象为一组统一的工具原语。在工业级前端框架Ant Design中实现了CI4A，覆盖了23类常用UI组件。开发了混合智能体，其动作空间能根据页面状态动态更新，灵活调用可用的CI4A工具。基于CI4A集成的Ant Design重构并升级了WebArena基准测试。

Result: 基于CI4A的智能体显著优于现有方法，达到了86.3%的新SOTA任务成功率，同时在执行效率方面也有显著提升。

Conclusion: CI4A通过为智能体专门优化的UI组件接口封装机制，有效解决了智能体在细粒度Web组件操作方面的局限，为智能体与Web界面的交互提供了更高效、更可靠的解决方案。

Abstract: While Large Language Models demonstrate remarkable proficiency in high-level semantic planning, they remain limited in handling fine-grained, low-level web component manipulations. To address this limitation, extensive research has focused on enhancing model grounding capabilities through techniques such as Reinforcement Learning. However, rather than compelling agents to adapt to human-centric interfaces, we propose constructing interaction interfaces specifically optimized for agents. This paper introduces Component Interface for Agent (CI4A), a semantic encapsulation mechanism that abstracts the complex interaction logic of UI components into a set of unified tool primitives accessible to agents. We implemented CI4A within Ant Design, an industrial-grade front-end framework, covering 23 categories of commonly used UI components. Furthermore, we developed a hybrid agent featuring an action space that dynamically updates according to the page state, enabling flexible invocation of available CI4A tools. Leveraging the CI4A-integrated Ant Design, we refactored and upgraded the WebArena benchmark to evaluate existing SoTA methods. Experimental results demonstrate that the CI4A-based agent significantly outperforms existing approaches, achieving a new SoTA task success rate of 86.3%, alongside substantial improvements in execution efficiency.

</details>


### [93] [Measuring and Aligning Abstraction in Vision-Language Models with Medical Taxonomies](https://arxiv.org/abs/2601.14827)
*Ben Schaper,Maxime Di Folco,Bernhard Kainz,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.AI

TL;DR: 该研究评估了视觉语言模型在胸部X光分类中的抽象错误，提出使用医学分类学进行分层评估，并开发了减少严重错误的方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在胸部X光分类中表现出强大的零样本性能，但标准的平面评估指标无法区分临床轻微错误和严重错误。需要量化并缓解抽象错误，以提高模型的临床安全性和实用性。

Method: 1) 使用分层指标对多个最先进的视觉语言模型进行基准测试；2) 引入"灾难性抽象错误"概念来捕捉跨分支错误；3) 提出风险约束阈值法和基于径向嵌入的分类学感知微调方法。

Result: 研究发现尽管视觉语言模型在平面指标上表现优异，但与临床分类学存在显著不对齐。提出的方法能将严重抽象错误降低到2%以下，同时保持有竞争力的性能。

Conclusion: 分层评估和表示层面对齐对于视觉语言模型在医疗领域的安全部署和临床意义至关重要。提出的方法能有效减少严重错误，提高模型的临床可靠性。

Abstract: Vision-Language Models show strong zero-shot performance for chest X-ray classification, but standard flat metrics fail to distinguish between clinically minor and severe errors. This work investigates how to quantify and mitigate abstraction errors by leveraging medical taxonomies. We benchmark several state-of-the-art VLMs using hierarchical metrics and introduce Catastrophic Abstraction Errors to capture cross-branch mistakes. Our results reveal substantial misalignment of VLMs with clinical taxonomies despite high flat performance. To address this, we propose risk-constrained thresholding and taxonomy-aware fine-tuning with radial embeddings, which reduce severe abstraction errors to below 2 per cent while maintaining competitive performance. These findings highlight the importance of hierarchical evaluation and representation-level alignment for safer and more clinically meaningful deployment of VLMs.

</details>


### [94] [Implementing Knowledge Representation and Reasoning with Object Oriented Design](https://arxiv.org/abs/2601.14840)
*Abdelrhman Bassiouny,Tom Schierenbeck,Sorin Arion,Benjamin Alt,Naren Vasantakumaar,Giang Nguyen,Michael Beetz*

Main category: cs.AI

TL;DR: KRROOD框架通过将知识作为一等编程抽象，使用原生类结构弥合逻辑编程与面向对象编程之间的鸿沟，解决现代软件工程与知识表示推理系统集成难题。


<details>
  <summary>Details</summary>
Motivation: 现代软件工程以面向对象编程为标准开发复杂应用，而现有知识表示推理框架依赖外部本体和专用语言，难以与命令式代码集成，存在集成鸿沟。

Method: KRROOD将知识作为一等编程抽象，使用原生类结构，在逻辑编程与面向对象编程范式之间建立桥梁，实现知识表示推理系统与现代软件工程的直接集成。

Result: 在OWL2Bench基准测试和人机任务学习场景中，KRROOD表现出色，在保持强大推理表达能力的同时实现良好性能，满足现实世界自主系统的需求。

Conclusion: KRROOD成功弥合了知识表示推理系统与现代软件工程之间的集成鸿沟，为开发需要复杂推理能力的现实世界自主系统提供了有效解决方案。

Abstract: This paper introduces KRROOD, a framework designed to bridge the integration gap between modern software engineering and Knowledge Representation & Reasoning (KR&R) systems. While Object-Oriented Programming (OOP) is the standard for developing complex applications, existing KR&R frameworks often rely on external ontologies and specialized languages that are difficult to integrate with imperative code. KRROOD addresses this by treating knowledge as a first-class programming abstraction using native class structures, bridging the gap between the logic programming and OOP paradigms. We evaluate the system on the OWL2Bench benchmark and a human-robot task learning scenario. Experimental results show that KRROOD achieves strong performance while supporting the expressive reasoning required for real-world autonomous systems.

</details>


### [95] [Just aware enough: Evaluating awareness across artificial systems](https://arxiv.org/abs/2601.14901)
*Nadine Meertens,Suet Lee,Ophelia Deroy*

Main category: cs.AI

TL;DR: 该论文提出用"意识度"替代"AI意识"作为评估AI系统的新框架，强调可操作性、领域敏感性、可扩展性、多维度和任务性能预测能力。


<details>
  <summary>Details</summary>
Motivation: 当前关于AI意识和道德地位的讨论缺乏共识和可操作的评估方法，需要一种更实用、方法上更易处理的替代方案来评估AI系统的认知能力。

Method: 提出一个评估意识度的结构化方法，将意识度定义为系统处理、存储和使用信息以实现目标导向行动的能力。该方法要求具备领域敏感性、可扩展性、多维度和任务性能预测能力，通过比较不同架构、规模和操作领域AI系统的意识度配置文件来实现评估。

Result: 建立了一个实用的意识度评估框架，能够跨不同AI系统进行比较，支持设计、监督和科学讨论，但未提供具体的实证结果或案例研究。

Conclusion: 从"人工意识"转向"足够意识"的评估框架更具生产力，能够促进原则性评估、支持设计监督，并推动更建设性的科学和公共讨论。

Abstract: Recent debates on artificial intelligence increasingly emphasise questions of AI consciousness and moral status, yet there remains little agreement on how such properties should be evaluated. In this paper, we argue that awareness offers a more productive and methodologically tractable alternative. We introduce a practical method for evaluating awareness across diverse systems, where awareness is understood as encompassing a system's abilities to process, store and use information in the service of goal-directed action. Central to this approach is the claim that any evaluation aiming to capture the diversity of artificial systems must be domain-sensitive, deployable at any scale, multidimensional, and enable the prediction of task performance, while generalising to the level of abilities for the sake of comparison. Given these four desiderata, we outline a structured approach to evaluating and comparing awareness profiles across artificial systems with differing architectures, scales, and operational domains. By shifting the focus from artificial consciousness to being just aware enough, this approach aims to facilitate principled assessment, support design and oversight, and enable more constructive scientific and public discourse.

</details>


### [96] [Emergent, not Immanent: A Baradian Reading of Explainable AI](https://arxiv.org/abs/2601.15029)
*Fabio Morreale,Joan Serrà,Yuki Mistufuji*

Main category: cs.AI

TL;DR: 该论文批判了当前可解释AI（XAI）将解释视为技术问题的立场，提出基于Barad能动实在论的新本体认识论框架，认为解释是AI模型与人类、情境和解释装置纠缠中涌现的物质-话语实践。


<details>
  <summary>Details</summary>
Motivation: 当前XAI领域将解释视为揭示AI模型内部工作机制的技术问题，这种立场受到未经验证的本体认识论假设影响：意义被视为模型内在固有，解释者被置于系统之外，且假定可通过计算技术恢复因果结构。作者认为需要发展替代性的XAI本体认识论。

Method: 采用Barad的能动实在论作为理论基础，提出解释是物质-话语实践，从AI模型与人类、情境和解释装置的纠缠中涌现。通过能动实在论视角系统阅读和分析现有XAI方法，揭示其假设和局限。最后阐述框架的伦理维度，并提出支持涌现性解释的XAI界面设计方向，以推测性文本到音乐界面作为案例研究。

Result: 揭示了多种现有XAI方法背后的假设和局限性。提出了基于能动实在论的XAI新框架，强调解释的涌现性和情境性。阐述了该框架的伦理维度，并展示了支持涌现性解释的界面设计方向。

Conclusion: XAI不应被视为单纯的技术问题，而应理解为物质-话语实践，解释从AI模型与人类、情境和解释装置的纠缠中涌现。这种视角转变具有重要的伦理意义，并为XAI界面设计提供了新的方向，支持更具参与性和情境敏感性的解释过程。

Abstract: Explainable AI (XAI) is frequently positioned as a technical problem of revealing the inner workings of an AI model. This position is affected by unexamined onto-epistemological assumptions: meaning is treated as immanent to the model, the explainer is positioned outside the system, and a causal structure is presumed recoverable through computational techniques. In this paper, we draw on Barad's agential realism to develop an alternative onto-epistemology of XAI. We propose that interpretations are material-discursive performances that emerge from situated entanglements of the AI model with humans, context, and the interpretative apparatus. To develop this position, we read a comprehensive set of XAI methods through agential realism and reveal the assumptions and limitations that underpin several of these methods. We then articulate the framework's ethical dimension and propose design directions for XAI interfaces that support emergent interpretation, using a speculative text-to-music interface as a case study.

</details>


### [97] [The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution](https://arxiv.org/abs/2601.15075)
*Chen Qian,Peng Wang,Dongrui Liu,Junyao Yang,Dadi Guo,Ling Tang,Jilin Mei,Qihan Ren,Shuai Shao,Yong Liu,Jie Fu,Jing Shao,Xia Hu*

Main category: cs.AI

TL;DR: 提出一个用于通用智能体归因的新框架，旨在识别驱动智能体行为的内部因素，无论任务结果如何，通过分层方法定位关键交互步骤和具体文本证据。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体在现实应用中的广泛部署，理解智能体行为背后的原因对于问责和治理变得至关重要。现有研究主要关注失败归因，仅定位不成功轨迹中的显式错误，不足以解释智能体行为背后的推理过程。

Method: 提出分层框架：在组件级别使用时间似然动态识别关键交互步骤；在句子级别使用基于扰动的分析细化定位，隔离具体的文本证据。框架旨在识别驱动智能体行为的内部因素，无论任务结果如何。

Result: 实验验证表明，该框架能够可靠地定位智能体行为背后的关键历史事件和句子，涵盖标准工具使用和内存诱导偏差等微妙可靠性风险场景。

Conclusion: 该框架为构建更安全、更可问责的智能体系统提供了关键步骤，能够解释智能体行为背后的推理过程，超越了传统的失败归因方法。

Abstract: Large Language Model (LLM)-based agents are widely used in real-world applications such as customer service, web navigation, and software engineering. As these systems become more autonomous and are deployed at scale, understanding why an agent takes a particular action becomes increasingly important for accountability and governance. However, existing research predominantly focuses on \textit{failure attribution} to localize explicit errors in unsuccessful trajectories, which is insufficient for explaining the reasoning behind agent behaviors. To bridge this gap, we propose a novel framework for \textbf{general agentic attribution}, designed to identify the internal factors driving agent actions regardless of the task outcome. Our framework operates hierarchically to manage the complexity of agent interactions. Specifically, at the \textit{component level}, we employ temporal likelihood dynamics to identify critical interaction steps; then at the \textit{sentence level}, we refine this localization using perturbation-based analysis to isolate the specific textual evidence. We validate our framework across a diverse suite of agentic scenarios, including standard tool use and subtle reliability risks like memory-induced bias. Experimental results demonstrate that the proposed framework reliably pinpoints pivotal historical events and sentences behind the agent behavior, offering a critical step toward safer and more accountable agentic systems.

</details>


### [98] [BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries](https://arxiv.org/abs/2601.15197)
*Shijie Lian,Bin Yu,Xiaopeng Lin,Laurence T. Yang,Zhaolong Shen,Changti Wu,Yuzhuo Miao,Cong Huang,Kai Chen*

Main category: cs.AI

TL;DR: 论文提出BayesianVLA框架，通过贝叶斯分解解决VLA模型中的信息坍塌问题，强制模型遵循语言指令，显著提升泛化能力


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在机器人操作中存在泛化问题，特别是在新指令或复杂多任务场景中。研究发现目标驱动数据收集导致数据集偏差，使语言指令可从视觉观察中高度预测，导致指令与动作间的条件互信息消失（信息坍塌），模型退化为忽略语言约束的纯视觉策略

Method: 提出BayesianVLA框架：1) 引入可学习的潜在动作查询；2) 构建双分支架构分别估计视觉先验p(a|v)和语言条件后验π(a|v,ℓ)；3) 优化策略以最大化动作与指令间的条件点互信息，惩罚视觉捷径，奖励能明确解释语言命令的动作

Result: 在不需新数据的情况下，BayesianVLA显著改善泛化能力。在SimplerEnv和RoboCasa上的广泛实验显示明显提升，包括在具有挑战性的OOD SimplerEnv基准上获得11.3%的改进，验证了该方法在将语言可靠地融入动作中的能力

Conclusion: 通过贝叶斯分解强制指令遵循可有效解决VLA模型中的信息坍塌问题，BayesianVLA框架能够显著提升模型在分布外场景中的泛化性能，为构建更鲁棒的视觉-语言-动作模型提供了新思路

Abstract: Vision-Language-Action (VLA) models have shown promise in robot manipulation but often struggle to generalize to new instructions or complex multi-task scenarios. We identify a critical pathology in current training paradigms where goal-driven data collection creates a dataset bias. In such datasets, language instructions are highly predictable from visual observations alone, causing the conditional mutual information between instructions and actions to vanish, a phenomenon we term Information Collapse. Consequently, models degenerate into vision-only policies that ignore language constraints and fail in out-of-distribution (OOD) settings. To address this, we propose BayesianVLA, a novel framework that enforces instruction following via Bayesian decomposition. By introducing learnable Latent Action Queries, we construct a dual-branch architecture to estimate both a vision-only prior $p(a \mid v)$ and a language-conditioned posterior $π(a \mid v, \ell)$. We then optimize the policy to maximize the conditional Pointwise Mutual Information (PMI) between actions and instructions. This objective effectively penalizes the vision shortcut and rewards actions that explicitly explain the language command. Without requiring new data, BayesianVLA significantly improves generalization. Extensive experiments across on SimplerEnv and RoboCasa demonstrate substantial gains, including an 11.3% improvement on the challenging OOD SimplerEnv benchmark, validating the ability of our approach to robustly ground language in action.

</details>


### [99] [The Plausibility Trap: Using Probabilistic Engines for Deterministic Tasks](https://arxiv.org/abs/2601.15130)
*Ivan Carrera,Daniel Maldonado-Ruiz*

Main category: cs.AI

TL;DR: 论文提出"可信度陷阱"概念，指出人们过度使用昂贵的概率性AI模型处理简单确定性任务，导致资源浪费，并引入工具选择工程和决策矩阵框架来指导何时使用生成式AI。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的普及，用户便利性优先于计算效率，导致人们倾向于使用昂贵的概率性AI引擎处理简单的确定性任务（如OCR或基本验证），造成显著的资源浪费，这种现象被称为"可信度陷阱"。

Method: 通过OCR和事实核查的微基准测试和案例研究，量化"效率税"；引入工具选择工程和确定性-概率性决策矩阵框架，帮助开发者决定何时使用生成式AI以及何时避免使用。

Result: 研究显示存在约6.5倍的延迟惩罚（效率税），并揭示了算法奉承的风险；提出的决策框架能够有效指导AI工具的选择使用。

Conclusion: 真正的数字素养不仅在于知道如何使用生成式AI，更在于知道何时不使用它；需要课程转变，强调在适当场景下选择确定性工具而非概率性AI模型的重要性。

Abstract: The ubiquity of Large Language Models (LLMs) is driving a paradigm shift where user convenience supersedes computational efficiency. This article defines the "Plausibility Trap": a phenomenon where individuals with access to Artificial Intelligence (AI) models deploy expensive probabilistic engines for simple deterministic tasks-such as Optical Character Recognition (OCR) or basic verification-resulting in significant resource waste. Through micro-benchmarks and case studies on OCR and fact-checking, we quantify the "efficiency tax"-demonstrating a ~6.5x latency penalty-and the risks of algorithmic sycophancy. To counter this, we introduce Tool Selection Engineering and the Deterministic-Probabilistic Decision Matrix, a framework to help developers determine when to use Generative AI and, crucially, when to avoid it. We argue for a curriculum shift, emphasizing that true digital literacy relies not only in knowing how to use Generative AI, but also on knowing when not to use it.

</details>


### [100] [Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning](https://arxiv.org/abs/2601.15160)
*Yuval Kansal,Niraj K. Jha*

Main category: cs.AI

TL;DR: 提出一种基于知识图谱路径奖励的底层学习范式，通过监督微调和强化学习结合，使模型能够基于领域公理进行组合式多跳推理，在医学领域验证了该方法在复杂推理任务上的优越性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学、编程等结构化推理领域已达到接近专家的水平，但在专业科学领域进行组合式多跳推理的能力仍然有限。现有方法通常只优化最终答案，缺乏对中间推理步骤的监督，难以实现真正的组合推理。

Method: 提出一种后训练流程，结合监督微调和强化学习，利用知识图谱作为隐式奖励模型。通过从知识图谱路径中推导新颖的奖励信号，为模型提供可验证、可扩展且基于事实的监督，鼓励模型在强化学习过程中组合中间公理而不仅仅是优化最终答案。

Result: 在医学领域训练14B参数模型，在短跳推理路径（1-3跳）上进行训练，在复杂多跳查询（4-5跳）上进行零样本泛化评估。实验表明，路径衍生奖励作为"组合桥梁"，使模型在最具挑战性的推理任务上显著优于更大的模型和前沿系统（如GPT-5.2和Gemini 3 Pro）。此外，该方法对对抗性扰动（如选项洗牌压力测试）表现出鲁棒性。

Conclusion: 将推理过程基于结构化知识是一种可扩展且高效实现智能推理的路径。知识图谱路径奖励能够有效促进组合推理，为专业领域的复杂推理问题提供了有前景的解决方案。

Abstract: Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we present a post-training pipeline, based on a combination of supervised fine-tuning and reinforcement learning (RL), in which knowledge graphs act as implicit reward models. By deriving novel reward signals from knowledge graph paths, we provide verifiable, scalable, and grounded supervision that encourages models to compose intermediate axioms rather than optimize only final answers during RL. We validate this approach in the medical domain, training a 14B model on short-hop reasoning paths (1-3 hops) and evaluating its zero-shot generalization to complex multi-hop queries (4-5 hops). Our experiments show that path-derived rewards act as a "compositional bridge", enabling our model to significantly outperform much larger models and frontier systems like GPT-5.2 and Gemini 3 Pro, on the most difficult reasoning tasks. Furthermore, we demonstrate the robustness of our approach to adversarial perturbations against option-shuffling stress tests. This work suggests that grounding the reasoning process in structured knowledge is a scalable and efficient path toward intelligent reasoning.

</details>


<div id='math.CV'></div>

# math.CV [[Back]](#toc)

### [101] [Value Distribution and Picard-type Theorems for Total Differential Polynomials in $\mathbb{C}^n$](https://arxiv.org/abs/2601.14308)
*Molla Basir Ahamed,Vasudevarao Allu*

Main category: math.CV

TL;DR: 该论文研究了多复变全纯函数线性全微分多项式 $\mathcal{L}_k[D]f$ 的值分布与增长性质，将经典Milloux不等式推广到全导数框架，建立了Nevanlinna特征函数的基本增长估计，解决了微分多项式值共享问题，并给出了Picard型定理在多复变情形的推广。


<details>
  <summary>Details</summary>
Motivation: 将经典单复变函数论中的值分布理论、Milloux不等式、值共享问题和Picard型定理推广到多复变函数领域，研究全微分多项式在$\mathbb{C}^n$中的性质，填补单复变与多复变理论之间的空白。

Method: 通过将经典Milloux不等式扩展到全导数框架，推导Nevanlinna特征函数$T(r, \mathcal{L}_k[D]f)$的基本增长估计；在条件$2δ(0,f)+(k+4)Θ(\infty,f)>k+5$下，分析全纯函数$f$和$g$与其微分多项式的值共享问题；研究全纯函数及其微分多项式的值遗漏性质。

Result: 1. 建立了$\mathcal{L}_k[D]f$的Nevanlinna特征函数增长估计；2. 证明了在给定条件下，$\frac{\mathcal{L}_k[D]f-1}{\mathcal{L}_k[D]g-1}$为非零常数；3. 证明了若$\mathbb{C}^n$中整函数$f$遗漏值$a$且其线性全微分多项式$\mathcal{L}_k[D]f$遗漏非零值$b$，则$f$必为常数；4. 将多个经典唯一性定理和Picard型定理推广到高维复空间。

Conclusion: 该论文成功地将单复变函数论中的经典结果推广到多复变情形，建立了全微分多项式的值分布理论框架，解决了值共享和Picard型问题，为多复变函数论的发展提供了新的工具和视角。

Abstract: This paper investigates the value distribution and growth properties of linear total differential polynomials $\mathcal{L}_k[D]f$ for meromorphic functions in several complex variables $\mathbb{C}^n$. By extending the classical Milloux inequality to the framework of total derivatives, we derive a series of fundamental growth estimates for the Nevanlinna characteristic function $T(r, \mathcal{L}_k[D]f)$. We address the value-sharing problem for meromorphic functions $f$ and $g$ sharing values with their differential polynomials. Under the condition $2δ(0,f)+(k+4)Θ(\infty,f)>k+5$, we establish that $\frac{\mathcal{L}_k[D]f-1}{\mathcal{L}_k[D]g-1}$ is a non-zero constant for non-transcendental meromorphic functions. Furthermore, we provide an affirmative answer to several Picard-type inquiries, proving that if an entire function $f$ in $\mathbb{C}^n$ omits a value $a$ while its linear total differential polynomial $\mathcal{L}_k[D]f$ omits a non-zero value $b$, then $f$ must be constant. Our results generalize and extend several existing uniqueness and Picard-type theorems from the classical one-variable setting to the higher-dimensional complex space $\mathbb{C}^n$.

</details>


### [102] [Quasi-visual approximations](https://arxiv.org/abs/2601.14462)
*Mario Bonk,Mikhail Hlushchanka,Daniel Meyer*

Main category: math.CV

TL;DR: 本文建立了有界度量空间拟视觉逼近理论的基础，该理论通过具有直径趋于零且相对度量量受控的覆盖序列来研究空间，应用于拟共形几何和半双曲有理映射动力学。


<details>
  <summary>Details</summary>
Motivation: 建立有界度量空间的拟视觉逼近理论框架，为拟共形几何中的问题提供新工具，特别是用于检测同胚是否为拟对称映射，并将该理论与Gromov双曲空间理论及有理映射动力学联系起来。

Method: 定义拟视觉逼近为满足直径趋于零且相对度量量（如直径比和距离比）一致受控的覆盖序列；构建与拟视觉逼近相关的瓦片图，建立与Gromov双曲空间的联系；应用于半双曲有理映射的Julia集。

Result: 建立了拟视觉逼近理论的基础；证明了拟视觉逼近可用于检测同胚是否为拟对称映射；通过瓦片图建立了与Gromov双曲空间理论的联系；证明了有理映射的Julia集存在动态拟视觉逼近当且仅当该映射是半双曲的。

Conclusion: 拟视觉逼近理论为有界度量空间提供了新的分析框架，在拟共形几何和有理映射动力学中具有重要应用价值，特别是建立了Julia集动态性质与半双曲性之间的等价关系。

Abstract: We develop the foundations of the theory of quasi-visual approximations of bounded metric spaces. Roughly speaking, these are sequences of covers of a given space for which the diameters of the sets in the covers shrink to zero and for which relative metric quantities (such as ratios of diameters and distances) are uniformly controlled. This framework has applications to questions in quasiconformal geometry. In particular, quasi-visual approximations can be used to detect whether a given homeomorphism between two bounded metric spaces is a quasisymmetry.
  We also explore the connection to the theory of Gromov hyperbolic spaces via the tile graph associated with a quasi-visual approximation. As an application, we relate these ideas to the dynamics of semi-hyperbolic rational maps. More specifically, we show that the Julia set of a rational map admits a dynamical quasi-visual approximation if and only if the map is semi-hyperbolic.

</details>


### [103] [Homeomorphic Extensions in Bi-Orlicz-Sobolev Spaces](https://arxiv.org/abs/2601.14486)
*Yizhe Zhu*

Main category: math.CV

TL;DR: 该论文完全刻画了单位圆周上那些能够延拓为单位圆盘上属于双Orlicz-Sobolev空间的自同胚映射的特征，将经典Sobolev空间的结果推广到更灵活的Orlicz框架。


<details>
  <summary>Details</summary>
Motivation: 研究单位圆周自同胚何时能延拓为单位圆盘上属于Orlicz-Sobolev空间的自同胚，将经典Sobolev空间理论推广到更一般的Orlicz框架，提供更灵活的延拓条件。

Method: 采用双Orlicz-Sobolev空间理论，建立单位圆周自同胚到单位圆盘自同胚延拓的完整特征刻画，将经典Sobolev空间结果推广到Orlicz框架。

Result: 获得了单位圆周自同胚能够延拓为单位圆盘上属于双Orlicz-Sobolev空间的自同胚的完整特征条件，建立了Orlicz框架下的延拓理论。

Conclusion: 该研究成功将经典Sobolev空间中的延拓理论推广到Orlicz框架，为更一般的函数空间中的自同胚延拓问题提供了完整的特征刻画。

Abstract: We provide a complete characterization of those self-homeomorphisms of the unit circle that admit homeomorphic extensions to the unit disk belonging to bi--Orlicz--Sobolev spaces. Our results generalize classical criteria from the Sobolev setting to the more flexible Orlicz framework.

</details>


### [104] [The Effect of Planar Harmonic Mappings on the Lebesgue Measure of Sets](https://arxiv.org/abs/2601.14717)
*Hunduma Legesse Geleta*

Main category: math.CV

TL;DR: 该论文研究了平面单叶调和映射对复平面上可测集Lebesgue测度的影响，建立了单位圆盘上保向调和自映射下圆盘和任意可测集的尖锐定量面积畸变不等式。


<details>
  <summary>Details</summary>
Motivation: 受Koh和Kovalev在HQM2010中提出的问题3.25启发，研究调和映射对可测集面积的影响，建立定量面积畸变理论。

Method: 使用面积公式和调和映射的规范分解，通过Jacobian和伸缩商推导界；应用Hardy空间方法获得尖锐估计；构造极值仿射和非仿射例子验证尖锐性。

Result: 证明了圆盘、星形集和足够小集的全局面积收缩；获得了仅对共形自同构等号成立的尖锐界；提供了问题3.25的完整、严谨且加强的解决方案。

Conclusion: 该研究完全解决了问题3.25，揭示了调和映射的刚性现象，并提出了关于全局面积收缩、极值畸变和刚性的若干自然猜想。

Abstract: We investigate the effect of planar univalent harmonic mappings on the Lebesgue measure of measurable sets in the complex plane. Motivated by Problem 3.25 of Koh and Kovalev (HQM2010), we establish sharp quantitative area distortion inequalities for disks and for arbitrary measurable sets under sense-preserving harmonic self-maps of the unit disk. Using the area formula and the canonical decomposition of harmonic mappings, we derive bounds in terms of the Jacobian and the dilatation, and we identify rigidity phenomena characterizing equality. In particular, we prove global area contraction for disks, star-shaped sets, and sufficiently small sets, and we refine the results using Hardy space methods to obtain sharp bounds with equality only for conformal automorphisms. Extremal affine and non-affine examples illustrate the sharpness of our estimates. Our results provide a complete, rigorous, and strengthened solution to Problem 3.25 and highlight several natural conjectures on global area contraction, extremal distortion, and rigidity for harmonic mappings.

</details>


### [105] [On the Bergman metric of symmettric spaces](https://arxiv.org/abs/2601.15020)
*Andrea Loi,Matteo Palmieri*

Main category: math.CV

TL;DR: 研究Bergman度量局部对称的有界域，证明两种刚性结果：完全度量时域全局对称，伪凸时域可分解为对称域减去闭集


<details>
  <summary>Details</summary>
Motivation: 研究Bergman度量具有局部对称性（黎曼曲率张量平行）的有界域的结构和刚性性质，探索对称性在复几何中的表现

Method: 结合Hermitian对称空间的结构理论、Calabi的Kähler浸入理论（到无限维复射影空间）、Bergman核和平方可积全纯函数的延拓性质等解析和多重位势工具

Result: 1. 若Bergman度量完全，则域全局对称；2. 若域伪凸，则域双全纯等价于有界对称域减去相对闭的多重极集

Conclusion: Bergman度量的局部对称性对有界域施加了很强的刚性约束，导致域要么完全对称，要么可分解为对称域减去特定闭集，揭示了复几何中对称性的深刻结构

Abstract: We study bounded domains $Ω\subset\mathbb{C}^n$ whose Bergman metric is locally symmetric, i.e. its Riemannian curvature tensor is parallel with respect to the Levi-Civita connection. Following the strategy developed in \cite{UnifThm2}, we obtain two rigidity results. If the Bergman metric of $Ω$ is complete, then $Ω$ is (globally) symmetric. If instead $Ω$ is pseudoconvex, then $Ω$ is biholomorphic to $\widetildeΩ\setminus E$, where $\widetildeΩ\subset\mathbb{C}^n$ is a bounded symmetric domain and $E\subset\widetildeΩ$ is relatively closed and pluripolar. The proofs combine the structure theory of Hermitian symmetric spaces with Calabi's theory of Kähler immersions into the infinite dimensional complex projective space (in particular, rigidity and the hereditary property of the diastasis), together with analytic and pluripotential tools based on extension properties of square-integrable holomorphic functions and the Bergman kernel.

</details>
