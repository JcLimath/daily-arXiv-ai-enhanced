<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 44]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 5]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.RO](#cs.RO) [Total: 15]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Analytic Bijections for Smooth and Interpretable Normalizing Flows](https://arxiv.org/abs/2601.10774)
*Mathis Gerdes,Miranda C. N. Cheng*

Main category: cs.LG

TL;DR: 提出了三种全局平滑、定义在全实数域且具有解析逆的标量双射函数族（三次有理函数、双曲正弦函数、三次多项式），以及一种新颖的径向流架构，在保持训练稳定性的同时显著减少参数数量。


<details>
  <summary>Details</summary>
Motivation: 现有归一化流设计中的标量双射面临权衡：仿射变换平滑且可解析求逆但表达能力有限；单调样条提供局部控制但仅分段平滑且定义在有界域上；残差流平滑但需要数值求逆。需要结合各种方法优点的解决方案。

Method: 1. 引入三种解析双射函数族：三次有理函数、双曲正弦函数、三次多项式，这些函数全局平滑（C^∞）、定义在全实数域、具有闭式解析逆。2. 开发径向流架构：通过直接参数化变换径向坐标同时保持角度方向，产生几何可解释的变换。

Result: 1. 新双射函数在耦合流中作为即插即用替换，匹配或超越样条性能。2. 径向流展现出卓越的训练稳定性，产生几何可解释的变换，对于具有径向结构的目标，能以1000倍更少的参数达到与耦合流相当的质量。3. 在φ^4晶格场理论的高维物理问题中，新方法超越仿射基线并解决模式崩溃问题。

Conclusion: 提出的解析双射函数族和径向流架构结合了现有方法的优点，提供了平滑、全局定义、解析可逆的解决方案，在保持训练稳定性的同时显著减少参数需求，特别适用于具有径向结构的目标和高维物理问题。

Abstract: A key challenge in designing normalizing flows is finding expressive scalar bijections that remain invertible with tractable Jacobians. Existing approaches face trade-offs: affine transformations are smooth and analytically invertible but lack expressivity; monotonic splines offer local control but are only piecewise smooth and act on bounded domains; residual flows achieve smoothness but need numerical inversion. We introduce three families of analytic bijections -- cubic rational, sinh, and cubic polynomial -- that are globally smooth ($C^\infty$), defined on all of $\mathbb{R}$, and analytically invertible in closed form, combining the favorable properties of all prior approaches. These bijections serve as drop-in replacements in coupling flows, matching or exceeding spline performance. Beyond coupling layers, we develop radial flows: a novel architecture using direct parametrization that transforms the radial coordinate while preserving angular direction. Radial flows exhibit exceptional training stability, produce geometrically interpretable transformations, and on targets with radial structure can achieve comparable quality to coupling flows with $1000\times$ fewer parameters. We provide comprehensive evaluation on 1D and 2D benchmarks, and demonstrate applicability to higher-dimensional physics problems through experiments on $φ^4$ lattice field theory, where our bijections outperform affine baselines and enable problem-specific designs that address mode collapse.

</details>


### [2] [Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework](https://arxiv.org/abs/2601.10779)
*Qingyue Zhang,Chang Chu,Haohao Fu,Tianren Peng,Yanru Wu,Guanbo Huang,Yang Li,Shao-Lun Huang*

Main category: cs.LG

TL;DR: UOWQ框架通过联合优化源任务权重和转移数量来解决多源迁移学习中的负迁移问题，理论证明适当调整权重后使用全部源样本最优，并提供闭式解和凸优化方法。


<details>
  <summary>Details</summary>
Motivation: 传统迁移学习方法通常单独优化源权重或转移样本量，忽略了二者的联合考虑，且均匀迁移可能导致负迁移，需要平衡异构源任务的贡献。

Method: 提出UOWQ理论框架，基于KL散度泛化误差的渐近分析，将多源迁移学习建模为参数估计问题，联合确定各源任务的最优权重和转移数量。

Result: 理论证明：权重适当调整后使用全部源样本总是最优；单源场景有闭式解，多源场景通过凸优化求解；在DomainNet和Office-Home等基准上优于现有方法。

Conclusion: UOWQ框架通过联合优化权重和数量有效解决了多源迁移学习中的负迁移问题，理论分析和实验验证了其有效性和实用性。

Abstract: Transfer learning plays a vital role in improving model performance in data-scarce scenarios. However, naive uniform transfer from multiple source tasks may result in negative transfer, highlighting the need to properly balance the contributions of heterogeneous sources. Moreover, existing transfer learning methods typically focus on optimizing either the source weights or the amount of transferred samples, while largely neglecting the joint consideration of the other. In this work, we propose a theoretical framework, Unified Optimization of Weights and Quantities (UOWQ), which formulates multi-source transfer learning as a parameter estimation problem grounded in an asymptotic analysis of a Kullback-Leibler divergence-based generalization error measure. The proposed framework jointly determines the optimal source weights and optimal transfer quantities for each source task. Firstly, we prove that using all available source samples is always optimal once the weights are properly adjusted, and we provide a theoretical explanation for this phenomenon. Moreover, to determine the optimal transfer weights, our analysis yields closed-form solutions in the single-source setting and develops a convex optimization-based numerical procedure for the multi-source case. Building on the theoretical results, we further propose practical algorithms for both multi-source transfer learning and multi-task learning settings. Extensive experiments on real-world benchmarks, including DomainNet and Office-Home, demonstrate that UOWQ consistently outperforms strong baselines. The results validate both the theoretical predictions and the practical effectiveness of our framework.

</details>


### [3] [Mugi: Value Level Parallelism For Efficient LLMs](https://arxiv.org/abs/2601.10823)
*Daniel Price,Prabhu Vellaisamy,John Shen,Di Wu*

Main category: cs.LG

TL;DR: 本文提出Mugi架构，通过推广值级并行(VLP)技术来优化大语言模型的计算效率，在非线性近似和小批量GEMM方面取得显著性能提升，并降低碳排放。


<details>
  <summary>Details</summary>
Motivation: 现有VLP技术主要针对大批量、低精度的通用矩阵乘法(GEMM)，但在基于Transformer的大语言模型中存在更复杂的操作。需要探索VLP如何更好地应用于LLM，提升非线性近似精度、小批量GEMM效率，并支持完整的LLM工作负载。

Method: 1) 将VLP推广到非线性近似，采用以值为中心的方法，为重要值分配更高精度；2) 优化VLP用于非对称输入的小批量GEMM，结合权重量化、KV缓存量化和分组查询注意力等LLM优化技术；3) 设计新的VLP架构Mugi，封装上述创新并支持完整LLM工作负载。

Result: Mugi在非线性softmax操作上实现吞吐量提升45倍、能效提升668倍；在LLM上实现吞吐量提升2.07倍、能效提升3.11倍；同时降低LLM运行碳排放1.45倍、隐含碳排放1.48倍。

Conclusion: 通过推广VLP技术并设计Mugi架构，能够显著提升LLM的计算性能、能效和可持续性，为高效LLM推理提供了有效的硬件架构解决方案。

Abstract: Value level parallelism (VLP) has been proposed to improve the efficiency of large-batch, low-precision general matrix multiply (GEMM) between symmetric activations and weights. In transformer based large language models (LLMs), there exist more sophisticated operations beyond activation-weight GEMM. In this paper, we explore how VLP benefits LLMs. First, we generalize VLP for nonlinear approximations, outperforming existing nonlinear approximations in end-to-end LLM accuracy, performance, and efficiency. Our VLP approximation follows a value-centric approach, where important values are assigned with greater accuracy. Second, we optimize VLP for small-batch GEMMs with asymmetric inputs efficiently, which leverages timely LLM optimizations, including weight-only quantization, key-value (KV) cache quantization, and group query attention. Finally, we design a new VLP architecture, Mugi, to encapsulate the innovations above and support full LLM workloads, while providing better performance, efficiency and sustainability. Our experimental results show that Mugi can offer significant improvements on throughput and energy efficiency, up to $45\times$ and $668\times$ for nonlinear softmax operations, and $2.07\times$ and $3.11\times$ for LLMs, and also decrease operational carbon for LLM operation by $1.45\times$ and embodied carbon by $1.48\times$.

</details>


### [4] [AI-Guided Human-In-the-Loop Inverse Design of High Performance Engineering Structures](https://arxiv.org/abs/2601.10859)
*Dat Quoc Ha,Md Ferdous Alam,Markus J. Buehler,Faez Ahmed,Josephine V. Carstensen*

Main category: cs.LG

TL;DR: 提出一种AI协同拓扑优化方法，通过机器学习预测用户偏好的修改区域，减少人工迭代次数，提高设计效率


<details>
  <summary>Details</summary>
Motivation: 传统拓扑优化计算时间长且黑盒特性阻碍用户交互，现有的人机协同方法依赖耗时的迭代区域选择，需要减少迭代次数

Method: 采用U-Net架构的图像分割模型预测用户偏好区域，基于合成数据集训练（识别最长拓扑构件或最复杂结构连接），将AI推荐整合到人机协同拓扑优化流程中

Result: 模型成功预测合理的修改区域，在多样化非标准拓扑优化问题上具有泛化能力，相比传统方法可提高制造性或线性屈曲载荷39%，总设计时间仅增加15秒

Conclusion: AI协同人机拓扑优化方法有效减少迭代次数，提高设计效率，同时保持用户交互性，为高性能工程结构设计提供新工具

Abstract: Inverse design tools such as Topology Optimization (TO) can achieve new levels of improvement for high-performance engineered structures. However, widespread use is hindered by high computational times and a black-box nature that inhibits user interaction. Human-in-the-loop TO approaches are emerging that integrate human intuition into the design generation process. However, these rely on the time-consuming bottleneck of iterative region selection for design modifications. To reduce the number of iterative trials, this contribution presents an AI co-pilot that uses machine learning to predict the user's preferred regions. The prediction model is configured as an image segmentation task with a U-Net architecture. It is trained on synthetic datasets where human preferences either identify the longest topological member or the most complex structural connection. The model successfully predicts plausible regions for modification and presents them to the user as AI recommendations. The human preference model demonstrates generalization across diverse and non-standard TO problems and exhibits emergent behavior outside the single-region selection training data. Demonstration examples show that the new human-in-the-loop TO approach that integrates the AI co-pilot can improve manufacturability or improve the linear buckling load by 39% while only increasing the total design time by 15 sec compared to conventional simplistic TO.

</details>


### [5] [Beyond Accuracy: A Stability-Aware Metric for Multi-Horizon Forecasting](https://arxiv.org/abs/2601.10863)
*Chutian Ma,Grigorii Pomazkin,Giacinto Paolo Saggese,Paul Smith*

Main category: cs.LG

TL;DR: 提出了一种新的概率多步预测质量评估指标——预测准确性与一致性分数（AC分数），该指标同时考虑多步预测的准确性和时间一致性，并可作为可微目标函数用于训练时间序列模型。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测方法仅优化准确性，忽略了时间一致性（即模型在不同预测起点对同一未来事件的预测一致性）。这种单一目标无法全面评估概率多步预测的质量。

Method: 提出了预测准确性与一致性分数（AC分数），该指标能够同时衡量多步预测的准确性和稳定性，并允许用户通过指定权重来平衡准确性和一致性需求。将该分数实现为可微目标函数，用于训练季节性ARIMA模型。

Result: 在M4 Hourly基准数据集上评估，结果显示相比传统最大似然估计有显著改进。AC优化模型在保持相当或改进的点预测准确性的同时，对相同目标时间戳的预测波动性降低了75%。

Conclusion: 预测AC分数为概率多步预测提供了更全面的质量评估框架，能够同时优化准确性和时间一致性，在实际应用中显著提高了预测的稳定性而不牺牲准确性。

Abstract: Traditional time series forecasting methods optimize for accuracy alone. This objective neglects temporal consistency, in other words, how consistently a model predicts the same future event as the forecast origin changes. We introduce the forecast accuracy and coherence score (forecast AC score for short) for measuring the quality of probabilistic multi-horizon forecasts in a way that accounts for both multi-horizon accuracy and stability. Our score additionally provides for user-specified weights to balance accuracy and consistency requirements. As an example application, we implement the score as a differentiable objective function for training seasonal ARIMA models and evaluate it on the M4 Hourly benchmark dataset. Results demonstrate substantial improvements over traditional maximum likelihood estimation. Our AC-optimized models achieve a 75\% reduction in forecast volatility for the same target timestamps while maintaining comparable or improved point forecast accuracy.

</details>


### [6] [Action Shapley: A Training Data Selection Metric for World Model in Reinforcement Learning](https://arxiv.org/abs/2601.10905)
*Rajat Ghosh,Debojyoti Dutta*

Main category: cs.LG

TL;DR: 提出Action Shapley作为训练数据选择的公平度量，并设计随机动态算法降低指数复杂度，在数据受限的真实场景中验证了其效率和性能优势


<details>
  <summary>Details</summary>
Motivation: 在强化学习的世界模型中，训练数据质量直接影响模型效能和可解释性，特别是在与真实环境交互成本高、危险或不切实际的情况下，需要一种公平、合理的数据选择方法

Method: 引入Action Shapley作为与模型无关的训练数据选择度量，提出随机动态算法来降低传统Shapley值计算的指数复杂度

Result: 算法在五个数据受限的真实案例研究中，计算效率比传统指数时间计算提升超过80%；基于Action Shapley的训练数据选择策略始终优于临时数据选择方法

Conclusion: Action Shapley为世界模型训练提供了有效的公平数据选择框架，其高效算法使实际应用成为可能，在数据受限场景中展现出显著优势

Abstract: Numerous offline and model-based reinforcement learning systems incorporate world models to emulate the inherent environments. A world model is particularly important in scenarios where direct interactions with the real environment is costly, dangerous, or impractical. The efficacy and interpretability of such world models are notably contingent upon the quality of the underlying training data. In this context, we introduce Action Shapley as an agnostic metric for the judicious and unbiased selection of training data. To facilitate the computation of Action Shapley, we present a randomized dynamic algorithm specifically designed to mitigate the exponential complexity inherent in traditional Shapley value computations. Through empirical validation across five data-constrained real-world case studies, the algorithm demonstrates a computational efficiency improvement exceeding 80\% in comparison to conventional exponential time computations. Furthermore, our Action Shapley-based training data selection policy consistently outperforms ad-hoc training data selection.

</details>


### [7] [FAConvLSTM: Factorized-Attention ConvLSTM for Efficient Feature Extraction in Multivariate Climate Data](https://arxiv.org/abs/2601.10914)
*Francis Ndikum Nji,Jianwu Wang*

Main category: cs.LG

TL;DR: FAConvLSTM：一种用于高分辨率地球观测数据的因子化注意力ConvLSTM层，通过轻量级瓶颈、多尺度深度可分离分支和轴向空间注意力，在提升效率的同时改善空间表达能力和物理可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统ConvLSTM2D在处理高分辨率多元地球观测数据时面临挑战：密集卷积门控计算成本高，局部感受野限制了对长程空间结构和解耦气候动力学的建模。需要一种既能提高效率又能增强空间表达和物理可解释性的方法。

Method: 提出FAConvLSTM作为ConvLSTM2D的直接替代方案：1) 使用轻量级[1×1]瓶颈和共享深度空间混合对循环门计算进行因子化分解，降低通道复杂度；2) 多尺度扩张深度可分离分支和挤压-激励重校准实现跨空间尺度物理过程的高效建模；3) 窥视孔连接增强时间精度；4) 轻量级轴向空间注意力机制稀疏应用于时间维度以捕获遥相关尺度依赖；5) 专用子空间头通过带固定季节性位置编码的时间自注意力生成紧凑的每时间步嵌入。

Result: 在多元时空气候数据上的实验表明，FAConvLSTM相比标准ConvLSTM能产生更稳定、可解释和鲁棒的潜在表示，同时显著降低计算开销。

Conclusion: FAConvLSTM通过因子化注意力机制有效解决了ConvLSTM在高分辨率地球观测数据中的局限性，在保持循环动态的同时提高了效率、空间表达能力和物理可解释性，为气候动力学建模提供了更优的解决方案。

Abstract: Learning physically meaningful spatiotemporal representations from high-resolution multivariate Earth observation data is challenging due to strong local dynamics, long-range teleconnections, multi-scale interactions, and nonstationarity. While ConvLSTM2D is a commonly used baseline, its dense convolutional gating incurs high computational cost and its strictly local receptive fields limit the modeling of long-range spatial structure and disentangled climate dynamics. To address these limitations, we propose FAConvLSTM, a Factorized-Attention ConvLSTM layer designed as a drop-in replacement for ConvLSTM2D that simultaneously improves efficiency, spatial expressiveness, and physical interpretability. FAConvLSTM factorizes recurrent gate computations using lightweight [1 times 1] bottlenecks and shared depthwise spatial mixing, substantially reducing channel complexity while preserving recurrent dynamics. Multi-scale dilated depthwise branches and squeeze-and-excitation recalibration enable efficient modeling of interacting physical processes across spatial scales, while peephole connections enhance temporal precision. To capture teleconnection-scale dependencies without incurring global attention cost, FAConvLSTM incorporates a lightweight axial spatial attention mechanism applied sparsely in time. A dedicated subspace head further produces compact per timestep embeddings refined through temporal self-attention with fixed seasonal positional encoding. Experiments on multivariate spatiotemporal climate data shows superiority demonstrating that FAConvLSTM yields more stable, interpretable, and robust latent representations than standard ConvLSTM, while significantly reducing computational overhead.

</details>


### [8] [HOSL: Hybrid-Order Split Learning for Memory-Constrained Edge Training](https://arxiv.org/abs/2601.10940)
*Aakriti,Zhe Li,Dandan Liang,Chao Huang,Rui Li,Haibo Yang*

Main category: cs.LG

TL;DR: HOSL：一种混合阶分割学习框架，通过客户端使用零阶优化（减少内存）和服务器使用一阶优化（保证性能）来解决分割学习中内存效率与优化效果之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有分割学习系统主要依赖一阶优化，需要客户端存储激活等中间量，导致内存开销大，抵消了模型分割的优势。而零阶优化虽减少内存但收敛慢、性能差。需要解决内存效率与优化效果之间的根本权衡。

Method: 提出HOSL混合阶分割学习框架：客户端使用内存高效的零阶梯度估计，消除反向传播和激活存储；服务器端使用一阶优化确保快速收敛和竞争性能。理论上证明收敛率依赖于客户端模型维度而非完整模型维度。

Result: 在OPT模型（125M和1.3B参数）的6个任务上实验表明：HOSL相比一阶方法减少客户端GPU内存达3.7倍，同时准确率仅比基线低0.20%-4.23%；相比零阶基线性能提升达15.55%。

Conclusion: HOSL通过客户端零阶优化和服务器一阶优化的混合策略，有效解决了分割学习中内存效率与优化效果之间的权衡，为边缘设备上的内存高效训练提供了有效解决方案。

Abstract: Split learning (SL) enables collaborative training of large language models (LLMs) between resource-constrained edge devices and compute-rich servers by partitioning model computation across the network boundary. However, existing SL systems predominantly rely on first-order (FO) optimization, which requires clients to store intermediate quantities such as activations for backpropagation. This results in substantial memory overhead, largely negating benefits of model partitioning. In contrast, zeroth-order (ZO) optimization eliminates backpropagation and significantly reduces memory usage, but often suffers from slow convergence and degraded performance. In this work, we propose HOSL, a novel Hybrid-Order Split Learning framework that addresses this fundamental trade-off between memory efficiency and optimization effectiveness by strategically integrating ZO optimization on the client side with FO optimization on the server side. By employing memory-efficient ZO gradient estimation at the client, HOSL eliminates backpropagation and activation storage, reducing client memory consumption. Meanwhile, server-side FO optimization ensures fast convergence and competitive performance. Theoretically, we show that HOSL achieves a $\mathcal{O}(\sqrt{d_c/TQ})$ rate, which depends on client-side model dimension $d_c$ rather than the full model dimension $d$, demonstrating that convergence improves as more computation is offloaded to the server. Extensive experiments on OPT models (125M and 1.3B parameters) across 6 tasks demonstrate that HOSL reduces client GPU memory by up to 3.7$\times$ compared to the FO method while achieving accuracy within 0.20%-4.23% of this baseline. Furthermore, HOSL outperforms the ZO baseline by up to 15.55%, validating the effectiveness of our hybrid strategy for memory-efficient training on edge devices.

</details>


### [9] [Transient learning dynamics drive escape from sharp valleys in Stochastic Gradient Descent](https://arxiv.org/abs/2601.10962)
*Ning Yang,Yikuan Zhang,Qi Ouyang,Chao Tang,Yuhai Tu*

Main category: cs.LG

TL;DR: SGD通过非平衡机制选择平坦解：噪声重塑损失景观为有效势能，偏好平坦极小值；瞬态探索阶段后，能量壁垒增长导致"冻结"在单个盆地中


<details>
  <summary>Details</summary>
Motivation: 理解SGD偏好平坦、可泛化解的动力学起源，揭示学习动力学、损失景观几何与泛化之间的物理联系

Method: 分析SGD学习动力学，数值实验观察轨迹行为，使用可处理的物理模型研究噪声对景观的重塑效应

Result: 发现SGD噪声将损失景观重塑为偏好平坦解的有效势能；揭示瞬态冻结机制：训练过程中能量壁垒增长抑制谷间转移，最终将动力学困在单个盆地中；增加SGD噪声强度延迟冻结，增强向平坦极小值的收敛

Conclusion: 提出了统一物理框架，连接学习动力学、损失景观几何和泛化，为设计更有效的优化算法提供了原理指导

Abstract: Stochastic gradient descent (SGD) is central to deep learning, yet the dynamical origin of its preference for flatter, more generalizable solutions remains unclear. Here, by analyzing SGD learning dynamics, we identify a nonequilibrium mechanism governing solution selection. Numerical experiments reveal a transient exploratory phase in which SGD trajectories repeatedly escape sharp valleys and transition toward flatter regions of the loss landscape. By using a tractable physical model, we show that the SGD noise reshapes the landscape into an effective potential that favors flat solutions. Crucially, we uncover a transient freezing mechanism: as training proceeds, growing energy barriers suppress inter-valley transitions and ultimately trap the dynamics within a single basin. Increasing the SGD noise strength delays this freezing, which enhances convergence to flatter minima. Together, these results provide a unified physical framework linking learning dynamics, loss-landscape geometry, and generalization, and suggest principles for the design of more effective optimization algorithms.

</details>


### [10] [Toward Adaptive Grid Resilience: A Gradient-Free Meta-RL Framework for Critical Load Restoration](https://arxiv.org/abs/2601.10973)
*Zain ul Abdeen,Waris Gill,Ming Jin*

Main category: cs.LG

TL;DR: MGF-RL框架结合元学习和无梯度进化策略，从历史停电经验中学习可迁移初始化，快速适应新停电场景，提升配电网恢复的适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 极端事件后恢复关键负荷需要自适应控制来维持配电网韧性，但可再生能源不确定性、可调度资源有限以及非线性动态使得有效恢复困难。标准强化学习在不确定性下优化序列决策，但泛化能力差，对新停电配置或发电模式需要大量重新训练。

Method: 提出元引导的无梯度强化学习框架，将一阶元学习与进化策略耦合，无需梯度计算即可进行可扩展策略搜索，同时适应非线性、有约束的配电系统动态。从历史停电经验中学习可迁移初始化，以最少任务特定调谐快速适应未见场景。

Result: 在IEEE 13总线和IEEE 123总线测试系统上的实验表明，MGF-RL在可靠性、恢复速度和适应效率方面优于标准RL、基于MAML的元RL和模型预测控制。可泛化到未见停电和可再生能源模式，比传统RL需要更少的微调回合。提供了将适应效率与任务相似性和环境变化相关联的次线性遗憾界。

Conclusion: MGF-RL框架通过结合元学习和无梯度进化策略，实现了从历史经验中学习可迁移初始化并快速适应新场景的能力，为可再生能源丰富的配电网实时负荷恢复提供了有效解决方案，具有理论保证和实证优势。

Abstract: Restoring critical loads after extreme events demands adaptive control to maintain distribution-grid resilience, yet uncertainty in renewable generation, limited dispatchable resources, and nonlinear dynamics make effective restoration difficult. Reinforcement learning (RL) can optimize sequential decisions under uncertainty, but standard RL often generalizes poorly and requires extensive retraining for new outage configurations or generation patterns. We propose a meta-guided gradient-free RL (MGF-RL) framework that learns a transferable initialization from historical outage experiences and rapidly adapts to unseen scenarios with minimal task-specific tuning. MGF-RL couples first-order meta-learning with evolutionary strategies, enabling scalable policy search without gradient computation while accommodating nonlinear, constrained distribution-system dynamics. Experiments on IEEE 13-bus and IEEE 123-bus test systems show that MGF-RL outperforms standard RL, MAML-based meta-RL, and model predictive control across reliability, restoration speed, and adaptation efficiency under renewable forecast errors. MGF-RL generalizes to unseen outages and renewable patterns while requiring substantially fewer fine-tuning episodes than conventional RL. We also provide sublinear regret bounds that relate adaptation efficiency to task similarity and environmental variation, supporting the empirical gains and motivating MGF-RL for real-time load restoration in renewable-rich distribution grids.

</details>


### [11] [Reasoning Distillation for Lightweight Automated Program Repair](https://arxiv.org/abs/2601.10987)
*Aanand Balasubramanian,Sashank Silwal*

Main category: cs.LG

TL;DR: 轻量级符号推理监督能提升紧凑型自动程序修复模型中的修复类型分类性能


<details>
  <summary>Details</summary>
Motivation: 小型代码模型在资源受限环境中具有吸引力，但它们通常只产生单一预测，不清楚它们是否学习有意义的程序结构还是依赖浅层相关性

Method: 提出推理蒸馏方法，让大型教师模型提供结构化的符号推理标签和修复类型标签，这些标签捕获bug的高层因果属性而不依赖自由形式解释。在IntroClass基准上训练CodeT5学生模型，比较标签监督和推理蒸馏设置

Result: 推理监督持续提升宏平均性能，特别是在较少出现的bug类别上，且不增加模型大小或复杂度。正确推理轨迹与正确预测强相关，但不完全决定预测结果

Conclusion: 符号推理蒸馏是提升轻量级程序修复模型可解释性和鲁棒性的实用方法

Abstract: We study whether lightweight symbolic reasoning supervision can improve fix type classification in compact automated program repair models. Small code models are attractive for resource-constrained settings, but they typically produce only a single prediction, making it unclear whether they learn meaningful program structure or rely on shallow correlations. We propose a reasoning distillation approach in which a large teacher model provides structured symbolic reasoning tags alongside fix-type labels. These tags capture high-level causal properties of bugs without relying on free-form explanations. We train a CodeT5-based student model under label-only and reasoning-distilled settings on the IntroClass benchmark. Reasoning supervision consistently improves macro averaged performance, particularly on less frequent bug categories, without increasing model size or complexity. We further analyze the relationship between reasoning accuracy and fix-type prediction, showing that correct reasoning traces strongly correlate with correct predictions, while not fully determining them. Our results suggest that symbolic reasoning distillation is a practical way to improve interpretability and robustness in lightweight program repair models.

</details>


### [12] [Constant Metric Scaling in Riemannian Computation](https://arxiv.org/abs/2601.10992)
*Kisung You*

Main category: cs.LG

TL;DR: 该论文澄清了黎曼度量常数缩放对计算几何的影响，区分了变化的量（范数、距离、体积、梯度）和不变的几何对象（联络、测地线、指数映射），并讨论了在黎曼优化中的意义。


<details>
  <summary>Details</summary>
Motivation: 在计算几何和黎曼优化中，经常引入全局尺度参数进行度量缩放，但这种操作的影响在实践中并不总是清晰，容易与曲率变化、流形结构变化或坐标表示变化混淆。作者旨在澄清常数度量缩放的实际影响，避免误解。

Method: 提供关于任意黎曼流形上常数度量缩放的简短、自包含的说明。通过理论分析区分在缩放下变化的量（包括范数、距离、体积元素和梯度大小）和保持不变的几何对象（如Levi-Civita联络、测地线、指数和对数映射、平行移动）。

Result: 明确了常数度量缩放不影响黎曼流形的内在几何结构，只改变测量尺度。在黎曼优化中，这种缩放通常可以解释为步长的全局重新缩放，而不是底层几何的修改。

Conclusion: 该说明澄清了如何在黎曼计算中引入全局度量尺度参数而不改变这些方法所依赖的几何结构。这对于正确理解和应用黎曼优化算法具有重要意义，避免了将尺度变化误解为几何变化。

Abstract: Constant rescaling of a Riemannian metric appears in many computational settings, often through a global scale parameter that is introduced either explicitly or implicitly. Although this operation is elementary, its consequences are not always made clear in practice and may be confused with changes in curvature, manifold structure, or coordinate representation. In this note we provide a short, self-contained account of constant metric scaling on arbitrary Riemannian manifolds. We distinguish between quantities that change under such a scaling, including norms, distances, volume elements, and gradient magnitudes, and geometric objects that remain invariant, such as the Levi--Civita connection, geodesics, exponential and logarithmic maps, and parallel transport. We also discuss implications for Riemannian optimization, where constant metric scaling can often be interpreted as a global rescaling of step sizes rather than a modification of the underlying geometry. The goal of this note is purely expository and is intended to clarify how a global metric scale parameter can be introduced in Riemannian computation without altering the geometric structures on which these methods rely.

</details>


### [13] [Backdoor Attacks on Multi-modal Contrastive Learning](https://arxiv.org/abs/2601.11006)
*Simi D Kuniyilh,Rita Machacy*

Main category: cs.LG

TL;DR: 本文对对比学习中的后门攻击进行了系统综述，分析了威胁模型、攻击方法、目标领域和防御措施，强调了对比学习特有的安全漏洞及其在工业分布式环境中的安全部署意义。


<details>
  <summary>Details</summary>
Motivation: 对比学习已成为跨领域自监督表示学习的主流方法，但近期研究表明其易受后门和数据投毒攻击。攻击者可通过操纵预训练数据或模型更新来植入恶意行为。本文旨在系统梳理对比学习中的后门攻击研究现状，分析其特有漏洞，为安全部署提供指导。

Method: 采用系统性文献综述方法，对对比学习中的后门攻击进行全面的比较分析。研究内容包括：威胁模型分析、攻击方法分类、目标领域识别、现有防御措施评估。通过对比分析不同攻击策略和防御机制，揭示对比学习特有的安全漏洞。

Result: 研究发现对比学习存在独特的安全漏洞，攻击者可通过数据投毒、模型更新操纵等方式植入后门。不同领域（视觉、多模态、图学习、联邦学习）的攻击方法各有特点。现有防御措施仍存在局限性，需要针对对比学习特性设计更有效的安全机制。

Conclusion: 对比学习在安全部署方面面临严峻挑战，后门攻击威胁不容忽视。未来研究需要：1）开发针对对比学习特性的防御机制；2）建立更全面的安全评估框架；3）探索安全与性能的平衡策略。这些发现对工业分布式系统的安全部署具有重要意义。

Abstract: Contrastive learning has become a leading self- supervised approach to representation learning across domains, including vision, multimodal settings, graphs, and federated learning. However, recent studies have shown that contrastive learning is susceptible to backdoor and data poisoning attacks. In these attacks, adversaries can manipulate pretraining data or model updates to insert hidden malicious behavior. This paper offers a thorough and comparative review of backdoor attacks in contrastive learning. It analyzes threat models, attack methods, target domains, and available defenses. We summarize recent advancements in this area, underline the specific vulnerabilities inherent to contrastive learning, and discuss the challenges and future research directions. Our findings have significant implications for the secure deployment of systems in industrial and distributed environments.

</details>


### [14] [Combating Spurious Correlations in Graph Interpretability via Self-Reflection](https://arxiv.org/abs/2601.11021)
*Kecheng Cai,Chenyang Xu,Chao Peng*

Main category: cs.LG

TL;DR: 本文提出了一种自反思框架，用于提升图学习模型在具有强伪相关性的Spurious-Motif基准数据集上的可解释性性能，通过反馈机制进行迭代评估并引入基于此的微调训练方法。


<details>
  <summary>Details</summary>
Motivation: 现有可解释图学习方法在具有挑战性的Spurious-Motif基准数据集上表现显著较差，该数据集故意包含伪相关性，使模型难以区分真正相关结构与误导性模式。需要提升模型在此类具有强伪相关性数据集上的可解释性。

Method: 提出自反思框架，可集成到现有可解释图学习方法中。当方法生成节点和边的重要性分数后，框架将这些预测反馈回原始方法进行第二轮评估，形成迭代过程。进一步从图表示学习角度分析改进原因，提出基于此反馈机制的微调训练方法。

Result: 自反思技术（常用于大语言模型处理复杂任务）可有效适应并提升在具有强伪相关性数据集上的可解释性。提出的框架能够改善现有方法在Spurious-Motif基准上的性能表现。

Conclusion: 自反思框架能够有效提升可解释图学习方法在具有挑战性的Spurious-Motif数据集上的性能，通过反馈机制实现迭代评估，并可通过微调训练进一步优化模型表现。

Abstract: Interpretable graph learning has recently emerged as a popular research topic in machine learning. The goal is to identify the important nodes and edges of an input graph that are crucial for performing a specific graph reasoning task. A number of studies have been conducted in this area, and various benchmark datasets have been proposed to facilitate evaluation. Among them, one of the most challenging is the Spurious-Motif benchmark, introduced at ICLR 2022. The datasets in this synthetic benchmark are deliberately designed to include spurious correlations, making it particularly difficult for models to distinguish truly relevant structures from misleading patterns. As a result, existing methods exhibit significantly worse performance on this benchmark compared to others.
  In this paper, we focus on improving interpretability on the challenging Spurious-Motif datasets. We demonstrate that the self-reflection technique, commonly used in large language models to tackle complex tasks, can also be effectively adapted to enhance interpretability in datasets with strong spurious correlations. Specifically, we propose a self-reflection framework that can be integrated with existing interpretable graph learning methods. When such a method produces importance scores for each node and edge, our framework feeds these predictions back into the original method to perform a second round of evaluation. This iterative process mirrors how large language models employ self-reflective prompting to reassess their previous outputs. We further analyze the reasons behind this improvement from the perspective of graph representation learning, which motivates us to propose a fine-tuning training method based on this feedback mechanism.

</details>


### [15] [AVP-Pro: An Adaptive Multi-Modal Fusion and Contrastive Learning Approach for Comprehensive Two-Stage Antiviral Peptide Identification](https://arxiv.org/abs/2601.11028)
*Xinru Wen,Weizhong Lin,zi liu,Xuan Xiao*

Main category: cs.LG

TL;DR: AVP-Pro是一个用于抗病毒肽识别的两阶段预测框架，通过自适应特征融合和对比学习提高识别准确率，在通用AVP识别和功能亚型预测方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有抗病毒肽识别方法在捕捉复杂序列依赖性和区分高相似度样本方面存在局限，需要开发更准确的预测工具来支持新型药物开发。

Method: 提出AVP-Pro两阶段框架：第一阶段采用包含10种描述符的全景特征空间，结合自注意力机制和自适应门控机制，动态调节CNN提取的局部基序和BiLSTM捕获的全局依赖权重；第二阶段针对正负样本高相似度问题，采用基于BLOSUM62增强的在线困难样本挖掘对比学习策略，并结合迁移学习进行功能亚型预测。

Result: 第一阶段通用AVP识别准确率达0.9531，MCC为0.9064，优于现有SOTA方法；第二阶段在小样本条件下实现了6个病毒家族和8种特定病毒的准确分类，并开发了用户友好的Web界面。

Conclusion: AVP-Pro为抗病毒药物高通量筛选提供了强大且可解释的新工具，显著提高了抗病毒肽识别的准确性和实用性。

Abstract: The accurate identification of antiviral peptides (AVPs) is crucial for novel drug development. However, existing methods still have limitations in capturing complex sequence dependencies and distinguishing confusing samples with high similarity. To address these challenges, we propose AVP-Pro, a novel two-stage predictive framework that integrates adaptive feature fusion and contrastive learning. To comprehensively capture the physicochemical properties and deep-seated patterns of peptide sequences, we constructed a panoramic feature space encompassing 10 distinct descriptors and designed a hierarchical fusion architecture. This architecture integrates self-attention and adaptive gating mechanisms to dynamically modulate the weights of local motifs extracted by CNNs and global dependencies captured by BiLSTMs based on sequence context. Targeting the blurred decision boundary caused by the high similarity between positive and negative sample sequences, we adopted an Online Hard Example Mining (OHEM)-driven contrastive learning strategy enhanced by BLOSUM62. This approach significantly sharpened the model's discriminative power. Model evaluation results show that in the first stage of general AVP identification, the model achieved an accuracy of 0.9531 and an MCC of 0.9064, outperforming existing state-of-the-art (SOTA) methods. In the second stage of functional subtype prediction, combined with a transfer learning strategy, the model realized accurate classification of 6 viral families and 8 specific viruses under small-sample conditions. AVP-Pro provides a powerful and interpretable new tool for the high-throughput screening of antiviral drugs. To further enhance accessibility for users, we have developed a user-friendly web interface, which is available at https://wwwy1031-avp-pro.hf.space.

</details>


### [16] [OpFML: Pipeline for ML-based Operational Forecasting](https://arxiv.org/abs/2601.11046)
*Shahbaz Alvi,Giusy Fedele,Gabriele Accarino,Italo Epicoco,Ilenia Manco,Pasquale Schiano*

Main category: cs.LG

TL;DR: OpFML是一个可配置、可适配的机器学习管道，用于周期性预测，应用于每日火灾危险指数预测


<details>
  <summary>Details</summary>
Motivation: 机器学习在气候和地球科学中应用日益广泛，传统野火风险评估方法经常高估风险，需要更有效的操作预测系统

Method: 开发了OpFML（操作预测机器学习）管道，这是一个可配置、可适配的框架，用于部署机器学习模型进行周期性预测

Result: 展示了OpFML管道在每日火灾危险指数预测中的应用能力，并概述了其各种功能特性

Conclusion: OpFML提供了一个灵活的操作预测框架，特别适用于野火危险评估等周期性预测任务，能够改进传统方法的局限性

Abstract: Machine learning is finding its application in a multitude of areas in science and research, and Climate and Earth Sciences is no exception to this trend. Operational forecasting systems based on data-driven approaches and machine learning methods deploy models for periodic forecasting. Wildfire danger assessment using machine learning has garnered significant interest in the last decade, as conventional methods often overestimate the risk of wildfires. In this work, we present the code OpFML: Operational Forecasting with Machine Learning. OpFML is a configurable and adaptable pipeline that can be utilized to serve a machine learning model for periodic forecasting. We further demonstrate the capabilities of the pipeline through its application to daily Fire Danger Index forecasting and outline its various features.

</details>


### [17] [Soft Bayesian Context Tree Models for Real-Valued Time Series](https://arxiv.org/abs/2601.11079)
*Shota Saito,Yuta Nakahara,Toshiyasu Matsushima*

Main category: cs.LG

TL;DR: 提出Soft-BCT模型，一种用于实值时间序列的新型贝叶斯上下文树模型，采用软（概率）分割而非硬分割，基于变分推断进行学习，在真实数据集上表现优于或等同于传统BCT。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯上下文树（BCT）模型对实值时间序列采用硬（确定性）分割上下文空间，这可能限制了模型的表达能力。需要一种能够进行软（概率）分割的BCT模型来更好地捕捉时间序列的复杂依赖关系。

Method: 提出Soft-BCT模型，采用概率分割而非确定性分割上下文空间。基于变分推断开发学习算法，通过概率方式处理上下文空间的划分，从而更灵活地建模时间序列依赖结构。

Result: 在多个真实世界数据集上的实验表明，Soft-BCT表现出与传统BCT几乎相同或更优的性能，验证了软分割方法的有效性。

Conclusion: Soft-BCT通过引入软分割机制扩展了传统BCT模型，为实值时间序列建模提供了更灵活的表达能力，变分推断学习算法使其在实际应用中具有可行性。

Abstract: This paper proposes the soft Bayesian context tree model (Soft-BCT), which is a novel BCT model for real-valued time series. The Soft-BCT considers soft (probabilistic) splits of the context space, instead of hard (deterministic) splits of the context space as in the previous BCT for real-valued time series. A learning algorithm of the Soft-BCT is proposed based on the variational inference. For some real-world datasets, the Soft-BCT demonstrates almost the same or superior performance to the previous BCT.

</details>


### [18] [Differentially Private Subspace Fine-Tuning for Large Language Models](https://arxiv.org/abs/2601.11113)
*Lele Zheng,Xiang Wang,Tao Zhang,Yang Cao,Ke Cheng,Yulong Shen*

Main category: cs.LG

TL;DR: DP-SFT：一种两阶段子空间微调方法，通过在低维任务特定子空间注入差分隐私噪声，显著降低噪声幅度，在保持严格隐私保证的同时提升模型性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型在下游任务上的微调通常依赖敏感数据，引发隐私担忧。差分隐私虽能提供严格隐私保证，但在高维参数空间中注入噪声会产生大范数扰动，导致性能下降和训练不稳定

Method: 提出DP-SFT两阶段子空间微调方法：第一阶段通过分析主梯度方向识别低维任务特定子空间；第二阶段将完整梯度投影到该子空间，添加DP噪声，再将扰动梯度映射回原始参数空间进行模型更新

Result: 在多个数据集上的实验表明，DP-SFT在严格差分隐私约束下提高了准确性和稳定性，加速了收敛速度，相比基线DP微调方法取得了显著性能提升

Conclusion: DP-SFT通过将差分隐私噪声限制在低维任务特定子空间，有效降低了噪声幅度，在保持严格隐私保证的同时显著提升了微调性能，为大语言模型的隐私保护微调提供了有效解决方案

Abstract: Fine-tuning large language models on downstream tasks is crucial for realizing their cross-domain potential but often relies on sensitive data, raising privacy concerns. Differential privacy (DP) offers rigorous privacy guarantees and has been widely adopted in fine-tuning; however, naively injecting noise across the high-dimensional parameter space creates perturbations with large norms, degrading performance and destabilizing training. To address this issue, we propose DP-SFT, a two-stage subspace fine-tuning method that substantially reduces noise magnitude while preserving formal DP guarantees. Our intuition is that, during fine-tuning, significant parameter updates lie within a low-dimensional, task-specific subspace, while other directions change minimally. Hence, we only inject DP noise into this subspace to protect privacy without perturbing irrelevant parameters. In phase one, we identify the subspace by analyzing principal gradient directions to capture task-specific update signals. In phase two, we project full gradients onto this subspace, add DP noise, and map the perturbed gradients back to the original parameter space for model updates, markedly lowering noise impact. Experiments on multiple datasets demonstrate that DP-SFT enhances accuracy and stability under rigorous DP constraints, accelerates convergence, and achieves substantial gains over DP fine-tuning baselines.

</details>


### [19] [Optimized Algorithms for Text Clustering with LLM-Generated Constraints](https://arxiv.org/abs/2601.11118)
*Chaoqi Jia,Weihong Wu,Longkun Guo,Zhigang Lu,Chao Chen,Kok-Leong Ong*

Main category: cs.LG

TL;DR: 提出了一种基于大语言模型的约束生成方法，通过生成约束集而非传统成对约束来减少资源消耗，同时设计了针对LLM生成约束特性的聚类算法，在保持聚类精度的同时将LLM查询次数减少20倍以上。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法通过人工标注的must-link和cannot-link约束来提高精度，但标注成本高。随着大语言模型的发展，研究者开始探索利用LLM自动生成约束，但现有方法存在资源消耗大、查询效率低的问题，需要更高效的约束生成方法。

Method: 1) 提出新颖的约束生成方法，生成约束集而非成对约束，提高查询效率和约束准确性；2) 设计针对LLM生成约束特性的约束聚类算法，引入置信度阈值和惩罚机制来处理可能不准确的约束；3) 在五个文本数据集上评估方法，同时考虑约束生成成本和整体聚类性能。

Result: 在五个文本数据集上的实验结果显示，该方法在聚类精度上与最先进算法相当，同时将LLM查询次数减少了20倍以上，显著降低了资源消耗。

Conclusion: 提出的基于LLM的约束生成方法通过生成约束集而非成对约束，有效减少了资源消耗，同时设计的约束聚类算法能够处理LLM生成的不准确约束，实现了高效且准确的文本聚类。

Abstract: Clustering is a fundamental tool that has garnered significant interest across a wide range of applications including text analysis. To improve clustering accuracy, many researchers have incorporated background knowledge, typically in the form of must-link and cannot-link constraints, to guide the clustering process. With the recent advent of large language models (LLMs), there is growing interest in improving clustering quality through LLM-based automatic constraint generation. In this paper, we propose a novel constraint-generation approach that reduces resource consumption by generating constraint sets rather than using traditional pairwise constraints. This approach improves both query efficiency and constraint accuracy compared to state-of-the-art methods. We further introduce a constrained clustering algorithm tailored to the characteristics of LLM-generated constraints. Our method incorporates a confidence threshold and a penalty mechanism to address potentially inaccurate constraints. We evaluate our approach on five text datasets, considering both the cost of constraint generation and the overall clustering performance. The results show that our method achieves clustering accuracy comparable to the state-of-the-art algorithms while reducing the number of LLM queries by more than 20 times.

</details>


### [20] [Shape-morphing programming of soft materials on complex geometries via neural operator](https://arxiv.org/abs/2601.11126)
*Lu Chen,Gengxiang Chen,Xu Liu,Jingyan Su,Xuhao Lyu,Lihui Wang,Yingguang Li*

Main category: cs.LG

TL;DR: 提出S2NO神经算子，结合谱编码和空间卷积，实现复杂几何体上高保真形状变形预测，结合进化算法优化材料分布设计


<details>
  <summary>Details</summary>
Motivation: 现有形状变形软材料设计主要针对简单几何体，难以满足复杂几何体（如不规则边界、多孔结构、薄壁结构）上精确多样的变形需求，限制了在共形植入部署、气动变形等高级应用中的潜力

Method: 提出谱空间神经算子(S2NO)，整合拉普拉斯特征函数编码捕捉全局变形行为，空间卷积捕捉局部变形行为；结合进化算法优化体素级材料分布；利用神经算子的离散不变性实现超分辨率材料分布设计

Result: S2NO能在复杂几何体上实现高保真变形预测，包括不规则边界形状、多孔结构和薄壁结构；通过进化算法优化材料分布，实现精确形状变形编程；超分辨率设计进一步扩展了变形设计的多样性和复杂性

Conclusion: S2NO显著提高了复杂形状变形编程的效率和能力，为共形植入部署、气动变形等高级应用提供了有效的设计工具

Abstract: Shape-morphing soft materials can enable diverse target morphologies through voxel-level material distribution design, offering significant potential for various applications. Despite progress in basic shape-morphing design with simple geometries, achieving advanced applications such as conformal implant deployment or aerodynamic morphing requires accurate and diverse morphing designs on complex geometries, which remains challenging. Here, we present a Spectral and Spatial Neural Operator (S2NO), which enables high-fidelity morphing prediction on complex geometries. S2NO effectively captures global and local morphing behaviours on irregular computational domains by integrating Laplacian eigenfunction encoding and spatial convolutions. Combining S2NO with evolutionary algorithms enables voxel-level optimisation of material distributions for shape morphing programming on various complex geometries, including irregular-boundary shapes, porous structures, and thin-walled structures. Furthermore, the neural operator's discretisation-invariant property enables super-resolution material distribution design, further expanding the diversity and complexity of morphing design. These advancements significantly improve the efficiency and capability of programming complex shape morphing.

</details>


### [21] [FSL-BDP: Federated Survival Learning with Bayesian Differential Privacy for Credit Risk Modeling](https://arxiv.org/abs/2601.11134)
*Sultan Amed,Tanmay Sen,Sayantan Banerjee*

Main category: cs.LG

TL;DR: 提出联邦生存学习框架FSL-BDP，在保护借款人隐私的同时联合建模违约时间，解决了传统违约预测的二元分类局限和数据共享限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统信用风险模型面临两大挑战：1）二元分类忽略违约时间，将早期违约（高损失）与晚期违约（低损失）等同处理；2）集中式训练违反GDPR、CCPA等数据保护法规，禁止跨境共享借款人数据。需要一种既能保护隐私又能联合学习风险动态的解决方案。

Method: 提出联邦生存学习框架FSL-BDP，结合联邦学习和贝叶斯差分隐私。该框架在不集中敏感数据的情况下建模违约时间轨迹，提供数据依赖的贝叶斯差分隐私保证，使金融机构能够联合学习风险动态。

Result: 在三个真实信用数据集（LendingClub、SBA、Bondora）上的实验表明：联邦学习显著改变了隐私机制的有效性排序。在集中式设置中，经典差分隐私优于贝叶斯差分隐私，但在联邦设置中，贝叶斯差分隐私受益更大（+7.0% vs +1.4%），达到接近非私有性能的水平，并在大多数参与客户端中优于经典差分隐私。

Conclusion: 隐私机制的选择应在目标部署架构中评估，而非基于集中式基准。这一发现为受监管的多机构环境中设计隐私保护决策支持系统提供了实用指导。联邦学习改变了隐私技术的相对有效性，贝叶斯差分隐私在联邦设置中表现更优。

Abstract: Credit risk models are a critical decision-support tool for financial institutions, yet tightening data-protection rules (e.g., GDPR, CCPA) increasingly prohibit cross-border sharing of borrower data, even as these models benefit from cross-institution learning. Traditional default prediction suffers from two limitations: binary classification ignores default timing, treating early defaulters (high loss) equivalently to late defaulters (low loss), and centralized training violates emerging regulatory constraints. We propose a Federated Survival Learning framework with Bayesian Differential Privacy (FSL-BDP) that models time-to-default trajectories without centralizing sensitive data. The framework provides Bayesian (data-dependent) differential privacy (DP) guarantees while enabling institutions to jointly learn risk dynamics. Experiments on three real-world credit datasets (LendingClub, SBA, Bondora) show that federation fundamentally alters the relative effectiveness of privacy mechanisms. While classical DP performs better than Bayesian DP in centralized settings, the latter benefits substantially more from federation (+7.0\% vs +1.4\%), achieving near parity of non-private performance and outperforming classical DP in the majority of participating clients. This ranking reversal yields a key decision-support insight: privacy mechanism selection should be evaluated in the target deployment architecture, rather than centralized benchmarks. These findings provide actionable guidance for practitioners designing privacy-preserving decision support systems in regulated, multi-institutional environments.

</details>


### [22] [Context-aware Graph Causality Inference for Few-Shot Molecular Property Prediction](https://arxiv.org/abs/2601.11135)
*Van Thuy Hoang,O-Joun Lee*

Main category: cs.LG

TL;DR: CaMol是一个基于因果推断的上下文感知图学习框架，用于少样本分子属性预测，通过发现因果子结构提升准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于上下文学习的分子属性预测方法存在两个主要局限：1) 未能充分利用与属性因果相关的官能团先验知识；2) 难以识别与属性直接相关的关键子结构。需要一种能够从因果角度理解分子结构与属性关系的框架。

Method: CaMol采用因果推断视角，假设每个分子包含决定特定属性的潜在因果结构。方法包含三个核心组件：1) 上下文图编码化学知识，连接官能团、分子和属性以指导因果子结构发现；2) 可学习的原子掩码策略，从混杂子结构中解耦因果子结构；3) 分布干预器，通过后门调整结合因果子结构和化学基础的混杂因子，从真实化学变异中解耦因果效应。

Result: 在多个分子数据集上的实验表明，CaMol在少样本任务中实现了优越的准确性和样本效率，展示了对未见属性的泛化能力。发现的因果子结构与官能团的化学知识高度一致，支持模型的可解释性。

Conclusion: CaMol通过因果推断框架有效解决了少样本分子属性预测中的关键挑战，不仅提升了预测性能，还提供了与化学知识一致的因果解释，为基于Web的分子服务（如蛋白质结构预测和药物发现）提供了更可靠和可解释的解决方案。

Abstract: Molecular property prediction is becoming one of the major applications of graph learning in Web-based services, e.g., online protein structure prediction and drug discovery. A key challenge arises in few-shot scenarios, where only a few labeled molecules are available for predicting unseen properties. Recently, several studies have used in-context learning to capture relationships among molecules and properties, but they face two limitations in: (1) exploiting prior knowledge of functional groups that are causally linked to properties and (2) identifying key substructures directly correlated with properties. We propose CaMol, a context-aware graph causality inference framework, to address these challenges by using a causal inference perspective, assuming that each molecule consists of a latent causal structure that determines a specific property. First, we introduce a context graph that encodes chemical knowledge by linking functional groups, molecules, and properties to guide the discovery of causal substructures. Second, we propose a learnable atom masking strategy to disentangle causal substructures from confounding ones. Third, we introduce a distribution intervener that applies backdoor adjustment by combining causal substructures with chemically grounded confounders, disentangling causal effects from real-world chemical variations. Experiments on diverse molecular datasets showed that CaMol achieved superior accuracy and sample efficiency in few-shot tasks, showing its generalizability to unseen properties. Also, the discovered causal substructures were strongly aligned with chemical knowledge about functional groups, supporting the model interpretability.

</details>


### [23] [Assesing the Viability of Unsupervised Learning with Autoencoders for Predictive Maintenance in Helicopter Engines](https://arxiv.org/abs/2601.11154)
*P. Sánchez,K. Reyes,B. Radu,E. Fernández*

Main category: cs.LG

TL;DR: 比较直升机发动机预测性维护的两种方法：监督分类与基于自编码器的无监督异常检测，评估它们在真实世界数据上的性能与适用场景


<details>
  <summary>Details</summary>
Motivation: 直升机发动机的意外故障会导致严重的运行中断、安全隐患和高昂维修成本，需要有效的预测性维护策略来降低风险

Method: 对比两种方法：1) 监督分类管道，依赖正常和故障行为的标记数据；2) 基于自编码器的无监督异常检测，仅使用健康发动机数据学习正常操作模型，将偏差标记为潜在故障

Result: 监督模型在有标注故障数据时表现优异，而自编码器无需故障标签也能实现有效检测，特别适用于故障数据稀缺或不完整的场景

Conclusion: 研究突出了准确性、数据可用性和部署可行性之间的实际权衡，强调无监督学习作为航空航天应用早期故障检测的可行解决方案的潜力

Abstract: Unplanned engine failures in helicopters can lead to severe operational disruptions, safety hazards, and costly repairs. To mitigate these risks, this study compares two predictive maintenance strategies for helicopter engines: a supervised classification pipeline and an unsupervised anomaly detection approach based on autoencoders (AEs). The supervised method relies on labelled examples of both normal and faulty behaviour, while the unsupervised approach learns a model of normal operation using only healthy engine data, flagging deviations as potential faults. Both methods are evaluated on a real-world dataset comprising labelled snapshots of helicopter engine telemetry. While supervised models demonstrate strong performance when annotated failures are available, the AE achieves effective detection without requiring fault labels, making it particularly well suited for settings where failure data are scarce or incomplete. The comparison highlights the practical trade-offs between accuracy, data availability, and deployment feasibility, and underscores the potential of unsupervised learning as a viable solution for early fault detection in aerospace applications.

</details>


### [24] [Clustering High-dimensional Data: Balancing Abstraction and Representation Tutorial at AAAI 2026](https://arxiv.org/abs/2601.11160)
*Claudia Plant,Lena G. M. Bauer,Christian Böhm*

Main category: cs.LG

TL;DR: 该教程探讨聚类算法中抽象与表示之间的平衡，分析K-means、子空间聚类和深度聚类等方法如何实现这一平衡，并展望未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 聚类需要在抽象与表示之间取得平衡：既要抽象掉个体对象的冗余细节，又要保留能区分不同对象组的关键特征。当前聚类算法在这两个目标之间存在冲突，需要系统性地分析如何优化这一平衡。

Method: 通过对比分析不同聚类方法：1) 经典K-means采用高度抽象（平均化细节）和简单表示（原始空间中的高斯分布）；2) 子空间聚类和深度聚类通过更丰富的表示支持高维复杂数据；3) 深度聚类通过基于质心和基于密度的聚类损失来强制抽象；4) 子空间聚类方法学习两个潜在空间：一个用于聚类相关信息，另一个用于捕获数据中的其他信息。

Result: 分析表明：随着表示表达能力的增强，需要在目标函数中显式强制抽象以确保进行聚类而不仅仅是表示学习。当前深度聚类方法通过特定损失函数实现了抽象与表示的平衡，但这一平衡仍然具有挑战性。

Conclusion: 聚类算法的未来研究方向是更自适应地平衡抽象与表示，以提高性能、能效和可解释性。人脑在聚类和单次学习等任务中能自动找到抽象与表示的最佳平衡点，这为算法改进提供了重要启示。

Abstract: How to find a natural grouping of a large real data set? Clustering requires a balance between abstraction and representation. To identify clusters, we need to abstract from superfluous details of individual objects. But we also need a rich representation that emphasizes the key features shared by groups of objects that distinguish them from other groups of objects.
  Each clustering algorithm implements a different trade-off between abstraction and representation. Classical K-means implements a high level of abstraction - details are simply averaged out - combined with a very simple representation - all clusters are Gaussians in the original data space. We will see how approaches to subspace and deep clustering support high-dimensional and complex data by allowing richer representations. However, with increasing representational expressiveness comes the need to explicitly enforce abstraction in the objective function to ensure that the resulting method performs clustering and not just representation learning. We will see how current deep clustering methods define and enforce abstraction through centroid-based and density-based clustering losses. Balancing the conflicting goals of abstraction and representation is challenging. Ideas from subspace clustering help by learning one latent space for the information that is relevant to clustering and another latent space to capture all other information in the data.
  The tutorial ends with an outlook on future research in clustering. Future methods will more adaptively balance abstraction and representation to improve performance, energy efficiency and interpretability. By automatically finding the sweet spot between abstraction and representation, the human brain is very good at clustering and other related tasks such as single-shot learning. So, there is still much room for improvement.

</details>


### [25] [FAQ: Mitigating Quantization Error via Regenerating Calibration Data with Family-Aware Quantization](https://arxiv.org/abs/2601.11200)
*Haiyang Xiao,Weiqing Li,Jinyue Guo,Guochao Jiang,Guohua Liu,Yuewei Zhang*

Main category: cs.LG

TL;DR: FAQ提出了一种基于同家族大语言模型先验知识的校准数据再生框架，通过更大模型生成高质量校准样本，提升后训练量化精度。


<details>
  <summary>Details</summary>
Motivation: 传统后训练量化方法依赖有限校准样本，难以捕捉推理阶段的激活分布，导致量化参数存在偏差。校准数据的代表性和普适性是决定量化精度的核心瓶颈。

Method: FAQ框架首先将原始校准样本输入目标模型同家族的更大LLM，利用高度一致的知识体系再生高保真校准数据。这些携带思维链推理、符合预期激活分布的数据经过专家指导下的组间竞争选择最佳样本，然后进行重归一化以增强标准PTQ效果。

Result: 在包括Qwen3-8B在内的多个模型系列上的实验表明，FAQ相比使用原始校准数据的基线方法，将精度损失降低了高达28.5%。

Conclusion: FAQ通过利用同家族LLM的先验知识生成高质量校准数据，有效解决了传统PTQ中校准数据代表性和普适性的瓶颈问题，展示了强大的应用潜力和贡献。

Abstract: Although post-training quantization (PTQ) provides an efficient numerical compression scheme for deploying large language models (LLMs) on resource-constrained devices, the representativeness and universality of calibration data remain a core bottleneck in determining the accuracy of quantization parameters. Traditional PTQ methods typically rely on limited samples, making it difficult to capture the activation distribution during the inference phase, leading to biases in quantization parameters. To address this, we propose \textbf{FAQ} (Family-Aware Quantization), a calibration data regeneration framework that leverages prior knowledge from LLMs of the same family to generate high-fidelity calibration samples. Specifically, FAQ first inputs the original calibration samples into a larger LLM from the same family as the target model, regenerating a series of high-fidelity calibration data using a highly consistent knowledge system. Subsequently, this data, carrying Chain-of-Thought reasoning and conforming to the expected activation distribution, undergoes group competition under expert guidance to select the best samples, which are then re-normalized to enhance the effectiveness of standard PTQ. Experiments on multiple model series, including Qwen3-8B, show that FAQ reduces accuracy loss by up to 28.5\% compared to the baseline with original calibration data, demonstrating its powerful potential and contribution.

</details>


### [26] [SDFLoRA: Selective Dual-Module LoRA for Federated Fine-tuning with Heterogeneous Clients](https://arxiv.org/abs/2601.11219)
*Zhikang Shen,Jianrong Lu,Haiyuan Wan,Jianhai Chen*

Main category: cs.LG

TL;DR: SDFLoRA：一种解决联邦学习中LoRA适配器秩异构问题的选择性双模块方法，通过分离全局模块和本地模块实现鲁棒聚合和隐私保护


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）用于大语言模型（LLM）时面临参数高效方法如LoRA的秩异构问题，不同客户端使用不同的低秩配置导致直接聚合LoRA更新存在偏差和不稳定性。现有解决方案强制统一秩或将异构更新对齐到共享子空间，这会过度约束客户端特定语义、限制个性化，并在差分隐私噪声下对本地客户端信息保护较弱。

Method: 提出选择性双模块联邦LoRA（SDFLoRA），将每个客户端适配器分解为捕获可迁移知识的全局模块和保留客户端特定适应的本地模块。全局模块在客户端间选择性对齐和聚合，而本地模块保持私有。这种设计支持在秩异构下的鲁棒学习，并通过仅在全局模块中注入差分隐私噪声实现隐私感知优化。

Result: 在GLUE基准测试上的实验表明，SDFLoRA优于代表性的联邦LoRA基线方法，并实现了更好的效用-隐私权衡。

Conclusion: SDFLoRA通过解耦全局和本地模块有效解决了联邦学习中LoRA适配器的秩异构问题，在保持个性化能力的同时实现了鲁棒聚合和增强的隐私保护，为隐私保护的分布式大语言模型适应提供了实用解决方案。

Abstract: Federated learning (FL) for large language models (LLMs) has attracted increasing attention as a way to enable privacy-preserving adaptation over distributed data. Parameter-efficient methods such as LoRA are widely adopted to reduce communication and memory costs. Despite these advances, practical FL deployments often exhibit rank heterogeneity, since different clients may use different low-rank configurations. This makes direct aggregation of LoRA updates biased and unstable. Existing solutions typically enforce unified ranks or align heterogeneous updates into a shared subspace, which over-constrains client-specific semantics, limits personalization, and provides weak protection of local client information under differential privacy noise. To address this issue, we propose Selective Dual-module Federated LoRA (SDFLoRA), which decomposes each client adapter into a global module that captures transferable knowledge and a local module that preserves client-specific adaptations. The global module is selectively aligned and aggregated across clients, while local modules remain private. This design enables robust learning under rank heterogeneity and supports privacy-aware optimization by injecting differential privacy noise exclusively into the global module. Experiments on GLUE benchmarks demonstrate that SDFLoRA outperforms representative federated LoRA baselines and achieves a better utility-privacy trade-off.

</details>


### [27] [GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling](https://arxiv.org/abs/2601.11161)
*Pascal Schlachter,Bin Yang*

Main category: cs.LG

TL;DR: GMM-COMET：首个持续源自由通用域自适应方法，通过高斯混合模型伪标签和均值教师框架解决多目标域序列适应问题


<details>
  <summary>Details</summary>
Motivation: 现有源自由通用域自适应方法仅假设单一源域到目标域的偏移，而实际应用中模型需要连续适应多个不同的未标记目标域，这提出了持续SF-UniDA的新挑战

Method: 结合高斯混合模型伪标签和均值教师框架，在在线SF-UniDA基础上引入一致性损失，提高长期适应序列的稳定性和鲁棒性

Result: GMM-COMET在所有评估场景中持续优于仅使用源域的模型，为持续SF-UniDA提供了首个强基准方法

Conclusion: 该研究提出了持续源自由通用域自适应的首个解决方案，通过集成高斯混合模型伪标签和均值教师框架，为多目标域序列适应提供了有效方法

Abstract: Unsupervised domain adaptation tackles the problem that domain shifts between training and test data impair the performance of neural networks in many real-world applications. Thereby, in realistic scenarios, the source data may no longer be available during adaptation, and the label space of the target domain may differ from the source label space. This setting, known as source-free universal domain adaptation (SF-UniDA), has recently gained attention, but all existing approaches only assume a single domain shift from source to target. In this work, we present the first study on continual SF-UniDA, where the model must adapt sequentially to a stream of multiple different unlabeled target domains. Building upon our previous methods for online SF-UniDA, we combine their key ideas by integrating Gaussian mixture model-based pseudo-labeling within a mean teacher framework for improved stability over long adaptation sequences. Additionally, we introduce consistency losses for further robustness. The resulting method GMM-COMET provides a strong first baseline for continual SF-UniDA and is the only approach in our experiments to consistently improve upon the source-only model across all evaluated scenarios. Our code is available at https://github.com/pascalschlachter/GMM-COMET.

</details>


### [28] [Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation](https://arxiv.org/abs/2601.11258)
*Pingzhi Tang,Yiding Wang,Muhan Zhang*

Main category: cs.LG

TL;DR: 提出PaST框架，通过提取领域无关的技能向量，在线性注入知识操作技能，解决LLMs知识更新与推理能力分离的问题，实现高效知识适应


<details>
  <summary>Details</summary>
Motivation: LLMs面临"知识截止"挑战，其冻结的参数化记忆无法直接内化新信息。监督微调(SFT)常用于更新模型知识，但通常只更新事实内容而无法可靠提升模型使用新信息进行问答或决策的能力。强化学习(RL)对获取推理技能至关重要，但其高计算成本使其难以实现高效的在线适应。作者观察到SFT和RL诱导的参数更新几乎正交，基于此提出模块化技能转移框架

Method: 提出参数化技能转移(PaST)框架：1)从源域提取领域无关的技能向量；2)在目标模型经过轻量级SFT学习新数据后，线性注入知识操作技能。该方法支持模块化技能转移，实现高效有效的知识适应

Result: 在知识整合QA(SQuAD, LooGLE)和智能体工具使用基准(ToolBench)上验证了方法的有效性：1)SQuAD上比最先进的自编辑SFT基线提升9.9分；2)LooGLE长上下文QA上获得8.0分绝对准确率提升；3)ToolBench零样本成功率平均提升+10.3分，跨工具类别一致增益，表明技能向量具有良好的可扩展性和跨域可转移性

Conclusion: PaST框架通过分离知识更新和推理技能获取，解决了LLMs知识适应中的关键问题。提取的领域无关技能向量能够有效提升模型使用新信息的能力，在多个基准上表现出显著优势，为高效知识适应提供了新思路

Abstract: Large Language Models (LLMs) face the "knowledge cutoff" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector.

</details>


### [29] [LSTM VS. Feed-Forward Autoencoders for Unsupervised Fault Detection in Hydraulic Pumps](https://arxiv.org/abs/2601.11163)
*P. Sánchez,K. Reyes,B. Radu,E. Fernández*

Main category: cs.LG

TL;DR: 研究探索两种无监督自编码器方案用于工业液压泵早期故障检测：前馈模型分析单个传感器快照，LSTM模型捕捉短期时间窗口，仅使用健康数据训练，在包含故障的测试集上表现可靠。


<details>
  <summary>Details</summary>
Motivation: 工业液压泵的意外故障会导致生产中断和巨大成本，需要开发能够在故障发生前进行检测的方法，特别是在缺乏故障样本的情况下实现可靠监测。

Method: 采用两种无监督自编码器方案：1) 前馈自编码器分析单个时间点的传感器快照；2) LSTM自编码器捕捉短期时间窗口的时序模式。两种模型仅使用52个传感器通道的健康数据进行训练，评估时使用包含7个标注故障区间的独立数据集。

Result: 尽管训练过程中完全没有故障样本，两种模型都实现了高可靠性。这表明无监督学习方法能够有效检测液压泵的早期故障，即使只基于健康数据训练。

Conclusion: 无监督自编码器方法在工业液压泵故障检测中具有实用价值，特别是前馈和LSTM两种架构都能在仅使用健康数据训练的情况下实现可靠的早期故障检测，为实际工业应用提供了可行的解决方案。

Abstract: Unplanned failures in industrial hydraulic pumps can halt production and incur substantial costs. We explore two unsupervised autoencoder (AE) schemes for early fault detection: a feed-forward model that analyses individual sensor snapshots and a Long Short-Term Memory (LSTM) model that captures short temporal windows. Both networks are trained only on healthy data drawn from a minute-level log of 52 sensor channels; evaluation uses a separate set that contains seven annotated fault intervals. Despite the absence of fault samples during training, the models achieve high reliability.

</details>


### [30] [FEATHer: Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting](https://arxiv.org/abs/2601.11350)
*Jaehoon Lee,Seungwoo Lee,Younghwi Kim,Dohee Kim,Sunghyun Sim*

Main category: cs.LG

TL;DR: FEATHer是一种用于边缘设备上时间序列预测的超轻量级模型，在严格的内存和延迟限制下（仅需400个参数）实现准确的长时预测，在8个基准测试中取得最佳排名。


<details>
  <summary>Details</summary>
Motivation: 工业领域（如制造和智能工厂）中的时间序列预测需要在边缘设备（PLC、微控制器）上运行，这些设备有严格的延迟和内存限制（参数通常限制在几千个）。传统深度架构在此场景下不实用，需要开发能在严重约束下实现准确长时预测的模型。

Method: FEATHer引入四个关键组件：1）超轻量级多尺度分解为频率通路；2）共享密集时间核，使用投影-深度卷积-投影结构，无需循环或注意力机制；3）频率感知分支门控，基于频谱特征自适应融合表示；4）稀疏周期核，通过周期下采样重建输出以捕捉季节性。

Result: 在8个基准测试中，FEATHer取得最佳排名，获得60个第一名结果，平均排名为2.05。模型保持紧凑架构（最少仅需400个参数），在严格约束下超越了基线方法。

Conclusion: 可靠的长期预测在受限的边缘硬件上是可行的，FEATHer为工业实时推理提供了实用方向，证明了超轻量级架构在边缘设备时间序列预测中的有效性。

Abstract: Time-series forecasting is fundamental in industrial domains like manufacturing and smart factories. As systems evolve toward automation, models must operate on edge devices (e.g., PLCs, microcontrollers) with strict constraints on latency and memory, limiting parameters to a few thousand. Conventional deep architectures are often impractical here. We propose the Fourier-Efficient Adaptive Temporal Hierarchy Forecaster (FEATHer) for accurate long-term forecasting under severe limits. FEATHer introduces: (i) ultra-lightweight multiscale decomposition into frequency pathways; (ii) a shared Dense Temporal Kernel using projection-depthwise convolution-projection without recurrence or attention; (iii) frequency-aware branch gating that adaptively fuses representations based on spectral characteristics; and (iv) a Sparse Period Kernel reconstructing outputs via period-wise downsampling to capture seasonality. FEATHer maintains a compact architecture (as few as 400 parameters) while outperforming baselines. Across eight benchmarks, it achieves the best ranking, recording 60 first-place results with an average rank of 2.05. These results demonstrate that reliable long-range forecasting is achievable on constrained edge hardware, offering a practical direction for industrial real-time inference.

</details>


### [31] [TimeMar: Multi-Scale Autoregressive Modeling for Unconditional Time Series Generation](https://arxiv.org/abs/2601.11184)
*Xiangyu Xu,Qingsong Zhong,Jilin Hu*

Main category: cs.LG

TL;DR: 提出结构解耦的多尺度时间序列生成框架，通过双路径VQ-VAE分离趋势和季节性成分，采用粗到细的自回归生成方式，显著提升生成质量并减少参数量


<details>
  <summary>Details</summary>
Motivation: 时间序列分析面临数据稀缺和隐私挑战，生成建模提供了有前景的解决方案。然而，时间序列的结构复杂性（包括多尺度时间模式和异构成分）尚未得到充分解决，需要更有效的生成方法来处理这些结构特征

Method: 提出结构解耦的多尺度生成框架：1）将序列编码为多个时间分辨率的离散token，以粗到细方式进行自回归生成；2）引入双路径VQ-VAE分离趋势和季节性成分，学习语义一致的潜在表示；3）提出基于引导的重建策略，利用粗粒度季节性信号作为先验指导细粒度季节性模式的重建

Result: 在六个数据集上的实验表明，该方法比现有方法产生更高质量的时间序列。模型在显著减少参数量的情况下仍能实现强劲性能，并在生成长序列方面表现出卓越能力

Conclusion: 该研究提出的结构解耦多尺度生成框架有效解决了时间序列的结构复杂性挑战，通过分离趋势和季节性成分、多尺度编码和引导重建策略，实现了高质量的时间序列生成，为数据稀缺和隐私保护问题提供了有效解决方案

Abstract: Generative modeling offers a promising solution to data scarcity and privacy challenges in time series analysis. However, the structural complexity of time series, characterized by multi-scale temporal patterns and heterogeneous components, remains insufficiently addressed. In this work, we propose a structure-disentangled multiscale generation framework for time series. Our approach encodes sequences into discrete tokens at multiple temporal resolutions and performs autoregressive generation in a coarse-to-fine manner, thereby preserving hierarchical dependencies. To tackle structural heterogeneity, we introduce a dual-path VQ-VAE that disentangles trend and seasonal components, enabling the learning of semantically consistent latent representations. Additionally, we present a guidance-based reconstruction strategy, where coarse seasonal signals are utilized as priors to guide the reconstruction of fine-grained seasonal patterns. Experiments on six datasets show that our approach produces higher-quality time series than existing methods. Notably, our model achieves strong performance with a significantly reduced parameter count and exhibits superior capability in generating high-quality long-term sequences. Our implementation is available at https://anonymous.4open.science/r/TimeMAR-BC5B.

</details>


### [32] [MetaboNet: The Largest Publicly Available Consolidated Dataset for Type 1 Diabetes Management](https://arxiv.org/abs/2601.11505)
*Miriam K. Wolff,Peter Calhoun,Eleonora Maria Aiello,Yao Qin,Sam F. Royston*

Main category: cs.LG

TL;DR: 该研究整合了多个公开的1型糖尿病数据集，创建了名为MetaboNet的统一数据资源，包含3135名受试者和1228患者年的CGM与胰岛素数据，用于促进T1D算法开发。


<details>
  <summary>Details</summary>
Motivation: 当前1型糖尿病算法开发受到现有数据集碎片化和缺乏标准化的限制。不同数据集在结构上差异很大，访问和处理耗时，这阻碍了数据整合，降低了算法开发的可比性和泛化性。

Method: 整合多个公开可用的T1D数据集，创建统一的MetaboNet数据集。纳入标准要求同时具备连续血糖监测数据和相应的胰岛素泵剂量记录。保留辅助信息如碳水化合物摄入和体力活动数据。数据集分为完全公开子集和需数据使用协议限制的子集，并为后者提供处理管道以转换为标准化格式。

Result: MetaboNet数据集包含3135名受试者和1228患者年的重叠CGM和胰岛素数据，规模显著大于现有独立基准数据集。资源可通过https://metabo-net.org/立即下载公开子集，DUA限制子集需通过相应申请流程访问。

Conclusion: 该研究为T1D研究提供了统一的数据集，描述了其无限制和DUA管理组件的访问途径。数据集覆盖广泛的血糖谱和人口统计学特征，因此比单个数据集能产生更具泛化性的算法性能。

Abstract: Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. Current datasets differ substantially in structure and are time-consuming to access and process, which impedes data integration and reduces the comparability and generalizability of algorithmic developments. This work aims to establish a unified and accessible data resource for T1D algorithm development. Multiple publicly available T1D datasets were consolidated into a unified resource, termed the MetaboNet dataset. Inclusion required the availability of both continuous glucose monitoring (CGM) data and corresponding insulin pump dosing records. Additionally, auxiliary information such as reported carbohydrate intake and physical activity was retained when present. The MetaboNet dataset comprises 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download at https://metabo-net.org/ , and with a Data Use Agreement (DUA)-restricted subset accessible through their respective application processes. For the datasets in the latter subset, processing pipelines are provided to automatically convert the data into the standardized MetaboNet format. A consolidated public dataset for T1D research is presented, and the access pathways for both its unrestricted and DUA-governed components are described. The resulting dataset covers a broad range of glycemic profiles and demographics and thus can yield more generalizable algorithmic performance than individual datasets.

</details>


### [33] [Operator learning on domain boundary through combining fundamental solution-based artificial data and boundary integral techniques](https://arxiv.org/abs/2601.11222)
*Haochen Wu,Heng Wu,Benzhuo Lu*

Main category: cs.LG

TL;DR: 提出MAD-BNO框架：基于数学人工数据，仅使用边界数据学习边界到边界的映射，通过边界积分公式恢复内部解，无需全域采样或数值模拟。


<details>
  <summary>Details</summary>
Motivation: 针对已知基本解的线性偏微分方程，传统算子学习方法需要全域采样数据，而实际应用中边界数据更易获取。本文旨在开发仅依赖边界数据的算子学习框架，避免昂贵的外部测量或数值模拟。

Method: 结合数学人工数据方法，从目标问题的基本解直接合成训练数据。学习边界到边界的映射（Dirichlet-Neumann数据对），训练后通过边界积分公式恢复任意位置的内部解。支持Dirichlet、Neumann、混合边界条件和一般源项。

Result: 在二维Laplace、Poisson和Helmholtz方程的基准算子学习任务中验证，达到或优于现有神经算子方法的精度，同时显著减少训练时间。框架可自然扩展到三维问题和复杂几何。

Conclusion: MAD-BNO为已知基本解的线性PDE提供了一种高效、完全数据驱动的算子学习框架，仅需边界数据即可实现准确求解，具有实际应用价值和扩展潜力。

Abstract: For linear partial differential equations with known fundamental solutions, this work introduces a novel operator learning framework that relies exclusively on domain boundary data, including solution values and normal derivatives, rather than full-domain sampling. By integrating the previously developed Mathematical Artificial Data (MAD) method, which enforces physical consistency, all training data are synthesized directly from the fundamental solutions of the target problems, resulting in a fully data-driven pipeline without the need for external measurements or numerical simulations. We refer to this approach as the Mathematical Artificial Data Boundary Neural Operator (MAD-BNO), which learns boundary-to-boundary mappings using MAD-generated Dirichlet-Neumann data pairs. Once trained, the interior solution at arbitrary locations can be efficiently recovered through boundary integral formulations, supporting Dirichlet, Neumann, and mixed boundary conditions as well as general source terms. The proposed method is validated on benchmark operator learning tasks for two-dimensional Laplace, Poisson, and Helmholtz equations, where it achieves accuracy comparable to or better than existing neural operator approaches while significantly reducing training time. The framework is naturally extensible to three-dimensional problems and complex geometries.

</details>


### [34] [Sample-Near-Optimal Agnostic Boosting with Improved Running Time](https://arxiv.org/abs/2601.11265)
*Arthur da Cunha,Miakel Møller Høgsgaard,Andrea Paudice*

Main category: cs.LG

TL;DR: 提出了第一个具有接近最优样本复杂度的不可知提升算法，在问题参数固定的情况下，运行时间与样本大小呈多项式关系。


<details>
  <summary>Details</summary>
Motivation: 经典提升算法已有深入研究，但不可知情况下的提升算法研究较少。虽然最近已基本解决了不可知提升的样本复杂度问题，但已知算法具有指数级运行时间，限制了实际应用。

Method: 提出了一种新的不可知提升算法，在保持接近最优样本复杂度的同时，实现了多项式时间运行。算法在问题参数固定的情况下，运行时间与样本大小呈多项式关系。

Result: 这是第一个具有接近最优样本复杂度的不可知提升算法，且运行时间为多项式时间。相比之前具有指数运行时间的算法，这是一个重要突破。

Conclusion: 该工作填补了不可知提升算法在高效实现方面的空白，为实际应用提供了可行的解决方案，平衡了样本复杂度和计算效率。

Abstract: Boosting is a powerful method that turns weak learners, which perform only slightly better than random guessing, into strong learners with high accuracy. While boosting is well understood in the classic setting, it is less so in the agnostic case, where no assumptions are made about the data. Indeed, only recently was the sample complexity of agnostic boosting nearly settled arXiv:2503.09384, but the known algorithm achieving this bound has exponential running time. In this work, we propose the first agnostic boosting algorithm with near-optimal sample complexity, running in time polynomial in the sample size when considering the other parameters of the problem fixed.

</details>


### [35] [Metabolomic Biomarker Discovery for ADHD Diagnosis Using Interpretable Machine Learning](https://arxiv.org/abs/2601.11283)
*Nabil Belacel,Mohamed Rachid Boulassel*

Main category: cs.LG

TL;DR: 该研究整合尿液代谢组学与可解释机器学习框架，识别与ADHD相关的生物化学特征，开发了一种基于14种代谢物的高精度诊断模型。


<details>
  <summary>Details</summary>
Motivation: ADHD作为一种常见的神经发育障碍，缺乏客观的诊断工具，迫切需要基于生物学的客观诊断框架来推进精准精神病学的发展。

Method: 使用靶向代谢组学分析52名ADHD患者和46名对照参与者的尿液样本，采用具有嵌入式特征选择的Closest Resemblance（CR）分类器进行数据分析，并与随机森林和K最近邻分类器进行比较。

Result: CR模型在14种代谢物组成的简化面板上表现最佳，AUC > 0.97，优于其他分类器。识别出的关键代谢物包括多巴胺4-硫酸盐、N-乙酰天冬氨酰谷氨酸和瓜氨酸，这些代谢物映射到多巴胺能神经传递和氨基酸代谢通路。

Conclusion: 该研究展示了一个结合代谢组学和可解释机器学习的转化框架，为ADHD提供了客观、生物学信息化的诊断策略，其透明决策边界和低计算成本支持整合到靶向代谢组学检测和未来即时诊断平台中。

Abstract: Attention Deficit Hyperactivity Disorder (ADHD) is a prevalent neurodevelopmental disorder with limited objective diagnostic tools, highlighting the urgent need for objective, biology-based diagnostic frameworks in precision psychiatry. We integrate urinary metabolomics with an interpretable machine learning framework to identify biochemical signatures associated with ADHD. Targeted metabolomic profiles from 52 ADHD and 46 control participants were analyzed using a Closest Resemblance (CR) classifier with embedded feature selection. The CR model outperformed Random Forest and K-Nearest Neighbor classifiers, achieving an AUC > 0.97 based on a reduced panel of 14 metabolites. These metabolites including dopamine 4-sulfate, N-acetylaspartylglutamic acid, and citrulline map to dopaminergic neurotransmission and amino acid metabolism pathways, offering mechanistic insight into ADHD pathophysiology. The CR classifier's transparent decision boundaries and low computational cost support integration into targeted metabolomic assays and future point of care diagnostic platforms. Overall, this work demonstrates a translational framework combining metabolomics and interpretable machine learning to advance objective, biologically informed diagnostic strategies for ADHD.

</details>


### [36] [FORESTLLM: Large Language Models Make Random Forest Great on Few-shot Tabular Learning](https://arxiv.org/abs/2601.11311)
*Zhihan Yang,Jiaqi Wei,Xiang Zhang,Haoyu Dong,Yiwen Wang,Xiaoke Guo,Pengkun Zhang,Yiwei Xu,Chenyu You*

Main category: cs.LG

TL;DR: FORESTLLM：结合决策树结构偏置与LLM语义推理的少样本表格数据学习框架，仅在训练时使用LLM设计轻量级可解释森林模型，测试时无需LLM推理


<details>
  <summary>Details</summary>
Motivation: 解决少样本表格数据学习的关键挑战：传统树方法在有限监督下因统计纯度指标不稳定而容易过拟合，而直接应用LLM常忽略表格固有结构导致性能不佳

Method: 1. 语义分割准则：LLM基于标记和未标记数据评估候选分割的语义连贯性，构建更鲁棒的树结构；2. 一次性上下文推理机制：LLM将决策路径和支持样本提炼为确定性预测，用语义信息输出替代噪声经验估计

Result: 在多样化的少样本分类和回归基准测试中，FORESTLLM实现了最先进的性能

Conclusion: FORESTLLM成功统一了决策森林的结构归纳偏置与LLM的语义推理能力，仅在训练时使用LLM作为离线模型设计器，创建了轻量级、可解释且高性能的少样本表格学习框架

Abstract: Tabular data high-stakes critical decision-making in domains such as finance, healthcare, and scientific discovery. Yet, learning effectively from tabular data in few-shot settings, where labeled examples are scarce, remains a fundamental challenge. Traditional tree-based methods often falter in these regimes due to their reliance on statistical purity metrics, which become unstable and prone to overfitting with limited supervision. At the same time, direct applications of large language models (LLMs) often overlook its inherent structure, leading to suboptimal performance. To overcome these limitations, we propose FORESTLLM, a novel framework that unifies the structural inductive biases of decision forests with the semantic reasoning capabilities of LLMs. Crucially, FORESTLLM leverages the LLM only during training, treating it as an offline model designer that encodes rich, contextual knowledge into a lightweight, interpretable forest model, eliminating the need for LLM inference at test time. Our method is two-fold. First, we introduce a semantic splitting criterion in which the LLM evaluates candidate partitions based on their coherence over both labeled and unlabeled data, enabling the induction of more robust and generalizable tree structures under few-shot supervision. Second, we propose a one-time in-context inference mechanism for leaf node stabilization, where the LLM distills the decision path and its supporting examples into a concise, deterministic prediction, replacing noisy empirical estimates with semantically informed outputs. Across a diverse suite of few-shot classification and regression benchmarks, FORESTLLM achieves state-of-the-art performance.

</details>


### [37] [Unlocking the Potentials of Retrieval-Augmented Generation for Diffusion Language Models](https://arxiv.org/abs/2601.11342)
*Chuanyue Yu,Jiahui Wang,Yuhan Li,Heng Chang,Ge Lan,Qingyun Sun,Jia Li,Jianxin Li,Ziwei Zhang*

Main category: cs.LG

TL;DR: 本文提出SPREAD框架，通过查询相关性引导的去噪策略解决扩散语言模型在检索增强生成中的响应语义漂移问题，显著提升生成精度。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在自然语言处理任务中表现出色，但检索增强生成框架在增强大语言模型方面的潜力尚未在DLMs中得到充分探索。主要障碍在于LLM和DLM解码机制的根本差异，特别是DLMs在RAG框架下存在生成精度有限的问题。

Method: 提出SPREAD（Semantic-Preserving REtrieval-Augmented Diffusion）框架，引入查询相关性引导的去噪策略。该策略通过主动引导去噪轨迹，确保生成内容始终锚定在查询语义上，有效抑制响应语义漂移。

Result: 实验结果表明，SPREAD在RAG框架内显著提升了生成答案的精度，有效缓解了响应语义漂移问题。DLMs结合RAG显示出对上下文信息更强的依赖性，但存在精度限制，而SPREAD成功解决了这一问题。

Conclusion: SPREAD框架通过创新的查询相关性引导去噪策略，成功解决了扩散语言模型在检索增强生成中的响应语义漂移问题，为DLMs在RAG框架中的应用提供了有效解决方案，显著提升了生成精度和语义一致性。

Abstract: Diffusion Language Models (DLMs) have recently demonstrated remarkable capabilities in natural language processing tasks. However, the potential of Retrieval-Augmented Generation (RAG), which shows great successes for enhancing large language models (LLMs), has not been well explored, due to the fundamental difference between LLM and DLM decoding. To fill this critical gap, we systematically test the performance of DLMs within the RAG framework. Our findings reveal that DLMs coupled with RAG show promising potentials with stronger dependency on contextual information, but suffer from limited generation precision. We identify a key underlying issue: Response Semantic Drift (RSD), where the generated answer progressively deviates from the query's original semantics, leading to low precision content. We trace this problem to the denoising strategies in DLMs, which fail to maintain semantic alignment with the query throughout the iterative denoising process. To address this, we propose Semantic-Preserving REtrieval-Augmented Diffusion (SPREAD), a novel framework that introduces a query-relevance-guided denoising strategy. By actively guiding the denoising trajectory, SPREAD ensures the generation remains anchored to the query's semantics and effectively suppresses drift. Experimental results demonstrate that SPREAD significantly enhances the precision and effectively mitigates RSD of generated answers within the RAG framework.

</details>


### [38] [Offline Reinforcement-Learning-Based Power Control for Application-Agnostic Energy Efficiency](https://arxiv.org/abs/2601.11352)
*Akhilesh Raj,Swann Perarnau,Aniruddha Gokhale,Solomon Bekele Abera*

Main category: cs.LG

TL;DR: 离线强化学习用于CPU功耗控制，通过历史数据训练实现能耗优化，避免在线训练风险


<details>
  <summary>Details</summary>
Motivation: 现代计算基础设施设计中能效成为关键因素，CPU功耗控制对系统性能、成本、可扩展性和耐久性有重要影响。虽然强化学习适合设计能效控制系统，但在线训练面临缺乏合适模拟环境、噪声干扰和可靠性等问题

Method: 采用离线强化学习方法设计自主CPU功耗控制器，结合灰盒方法：使用在线应用无关性能数据（如心跳信号）和硬件性能计数器，通过历史状态转换数据集进行训练，避免在线训练问题

Result: 在多种计算密集型和内存密集型基准测试中，通过Intel的Running Average Power Limit控制实时系统功耗，离线训练的智能体能够显著降低能耗，同时保持可接受的性能下降

Conclusion: 离线强化学习为CPU功耗控制提供了一种可行的替代方案，能够在保证科学目标实现的同时，以有限的性能下降为代价，有效提高并行应用的运行时能效

Abstract: Energy efficiency has become an integral aspect of modern computing infrastructure design, impacting the performance, cost, scalability, and durability of production systems. The incorporation of power actuation and sensing capabilities in CPU designs is indicative of this, enabling the deployment of system software that can actively monitor and adjust energy consumption and performance at runtime. While reinforcement learning (RL) would seem ideal for the design of such energy efficiency control systems, online training presents challenges ranging from the lack of proper models for setting up an adequate simulated environment, to perturbation (noise) and reliability issues, if training is deployed on a live system.
  In this paper we discuss the use of offline reinforcement learning as an alternative approach for the design of an autonomous CPU power controller, with the goal of improving the energy efficiency of parallel applications at runtime without unduly impacting their performance. Offline RL sidesteps the issues incurred by online RL training by leveraging a dataset of state transitions collected from arbitrary policies prior to training.
  Our methodology applies offline RL to a gray-box approach to energy efficiency, combining online application-agnostic performance data (e.g., heartbeats) and hardware performance counters to ensure that the scientific objectives are met with limited performance degradation. Evaluating our method on a variety of compute-bound and memory-bound benchmarks and controlling power on a live system through Intel's Running Average Power Limit, we demonstrate that such an offline-trained agent can substantially reduce energy consumption at a tolerable performance degradation cost.

</details>


### [39] [Latent Space Inference via Paired Autoencoders](https://arxiv.org/abs/2601.11397)
*Emma Hart,Bas Peters,Julianne Chung,Matthias Chung*

Main category: cs.LG

TL;DR: 提出基于配对自编码器的数据驱动潜在空间推理框架，用于处理观测不一致性时的反问题求解，通过连接参数空间和观测空间自编码器的潜在空间映射实现正则化反演。


<details>
  <summary>Details</summary>
Motivation: 解决反问题中观测数据不一致性（部分、噪声、分布外数据）的挑战，同时保持与底层物理模型的一致性，提高参数估计的准确性。

Method: 使用两个自编码器分别处理参数空间和观测空间，通过学习的潜在空间映射连接两者，构建正则化反演的替代模型，在低维信息丰富的潜在空间中进行优化。

Result: 相比单独使用配对自编码器和相同架构的端到端编码器-解码器，该方法在数据不一致场景下能产生更准确的重建结果，特别是在医学层析成像和地球物理地震波形反演中表现优异。

Conclusion: 该框架能灵活处理部分、噪声或分布外数据，同时保持物理模型一致性，在科学和工程领域的各种反问题中具有广泛适用性。

Abstract: This work describes a novel data-driven latent space inference framework built on paired autoencoders to handle observational inconsistencies when solving inverse problems. Our approach uses two autoencoders, one for the parameter space and one for the observation space, connected by learned mappings between the autoencoders' latent spaces. These mappings enable a surrogate for regularized inversion and optimization in low-dimensional, informative latent spaces. Our flexible framework can work with partial, noisy, or out-of-distribution data, all while maintaining consistency with the underlying physical models. The paired autoencoders enable reconstruction of corrupted data, and then use the reconstructed data for parameter estimation, which produces more accurate reconstructions compared to paired autoencoders alone and end-to-end encoder-decoders of the same architecture, especially in scenarios with data inconsistencies. We demonstrate our approaches on two imaging examples in medical tomography and geophysical seismic-waveform inversion, but the described approaches are broadly applicable to a variety of inverse problems in scientific and engineering applications.

</details>


### [40] [Factored Value Functions for Graph-Based Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.11401)
*Ahmed Rashwan,Keith Briggs,Chris Budd,Lisa Kreusser*

Main category: cs.LG

TL;DR: 提出扩散价值函数(DVF)用于图马尔可夫决策过程，通过在图结构上扩散奖励来解决多智能体强化学习中的信用分配问题，并基于此开发了DA2C算法和LD-GNN架构。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的信用分配问题在大规模结构化局部交互系统中尤为突出。现有的全局价值函数学习信号弱，局部构造方法在无限时域设置中难以估计且行为不佳，需要一种与图结构对齐的价值函数表示。

Method: 提出扩散价值函数(DVF)，通过在影响图上进行时间折扣和空间衰减的奖励扩散，为每个智能体分配价值分量。基于DVF开发了Diffusion A2C (DA2C)算法和Learned DropEdge GNN (LD-GNN)稀疏消息传递执行器，用于在通信成本约束下学习去中心化算法。

Result: DVF被证明是良定义的，具有Bellman不动点，并通过平均性质分解全局折扣价值。在消防基准测试和三个分布式计算任务（向量图着色和两个发射功率优化问题）中，DA2C始终优于局部和全局批评器基线，平均奖励提升高达11%。

Conclusion: DVF提供了一种与图结构对齐的因子化价值函数，有效解决了GMDP中的信用分配问题。DA2C结合LD-GNN在多个基准测试中表现出色，为大规模结构化多智能体系统提供了一种可扩展的强化学习框架。

Abstract: Credit assignment is a core challenge in multi-agent reinforcement learning (MARL), especially in large-scale systems with structured, local interactions. Graph-based Markov decision processes (GMDPs) capture such settings via an influence graph, but standard critics are poorly aligned with this structure: global value functions provide weak per-agent learning signals, while existing local constructions can be difficult to estimate and ill-behaved in infinite-horizon settings. We introduce the Diffusion Value Function (DVF), a factored value function for GMDPs that assigns to each agent a value component by diffusing rewards over the influence graph with temporal discounting and spatial attenuation. We show that DVF is well-defined, admits a Bellman fixed point, and decomposes the global discounted value via an averaging property. DVF can be used as a drop-in critic in standard RL algorithms and estimated scalably with graph neural networks. Building on DVF, we propose Diffusion A2C (DA2C) and a sparse message-passing actor, Learned DropEdge GNN (LD-GNN), for learning decentralised algorithms under communication costs. Across the firefighting benchmark and three distributed computation tasks (vector graph colouring and two transmit power optimisation problems), DA2C consistently outperforms local and global critic baselines, improving average reward by up to 11%.

</details>


### [41] [Forcing and Diagnosing Failure Modes of Fourier Neural Operators Across Diverse PDE Families](https://arxiv.org/abs/2601.11428)
*Lennon Shikhman*

Main category: cs.LG

TL;DR: 该论文提出了一个系统性的压力测试框架，用于评估傅里叶神经算子（FNO）在分布偏移、长期推演和结构扰动下的鲁棒性，揭示了其在五种不同类型PDE家族中的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 傅里叶神经算子在求解偏微分方程方面表现出色，但其在分布偏移、长期推演和结构扰动下的鲁棒性尚未得到充分理解。需要系统性地评估FNO的失败模式，为算子学习的鲁棒性改进提供依据。

Method: 设计了一个系统性的压力测试框架，针对五种不同类型的PDE家族（色散、椭圆、多尺度流体、金融和混沌系统）进行大规模评估（训练了1000个模型）。测试包括参数偏移、边界或终端条件变化、分辨率外推与谱分析、迭代推演等，以暴露谱偏差、积分误差累积和边界条件过拟合等脆弱性。

Result: 参数或边界条件的分布偏移可使误差增加一个数量级以上；分辨率变化主要导致高频模式误差集中；输入扰动通常不会放大误差，但最坏情况（如局部泊松扰动）仍然具有挑战性。研究揭示了FNO在不同PDE类型中的具体失败模式。

Conclusion: 该研究提供了一个比较性的失败模式图谱和可操作的见解，用于改进算子学习的鲁棒性。压力测试框架有助于识别FNO的脆弱性，为开发更稳健的神经算子模型提供了重要指导。

Abstract: Fourier Neural Operators (FNOs) have shown strong performance in learning solution maps of partial differential equations (PDEs), but their robustness under distribution shifts, long-horizon rollouts, and structural perturbations remains poorly understood. We present a systematic stress-testing framework that probes failure modes of FNOs across five qualitatively different PDE families: dispersive, elliptic, multi-scale fluid, financial, and chaotic systems. Rather than optimizing in-distribution accuracy, we design controlled stress tests--including parameter shifts, boundary or terminal condition changes, resolution extrapolation with spectral analysis, and iterative rollouts--to expose vulnerabilities such as spectral bias, compounding integration errors, and overfitting to restricted boundary regimes. Our large-scale evaluation (1{,}000 trained models) reveals that distribution shifts in parameters or boundary conditions can inflate errors by more than an order of magnitude, while resolution changes primarily concentrate error in high-frequency modes. Input perturbations generally do not amplify error, though worst-case scenarios (e.g., localized Poisson perturbations) remain challenging. These findings provide a comparative failure-mode atlas and actionable insights for improving robustness in operator learning.

</details>


### [42] [When Are Two Scores Better Than One? Investigating Ensembles of Diffusion Models](https://arxiv.org/abs/2601.11444)
*Raphaël Razafindralambo,Rémy Sun,Frédéric Precioso,Damien Garreau,Pierre-Alexandre Mattei*

Main category: cs.LG

TL;DR: 扩散模型集成方法研究：虽然集成能改善分数匹配损失和模型似然，但无法一致提升图像质量指标如FID


<details>
  <summary>Details</summary>
Motivation: 尽管集成方法在监督学习中已被证明有效，但在无条件分数扩散模型中的应用尚未充分探索，本研究旨在探究集成是否能为生成建模带来实际益处

Method: 研究多种集成策略（深度集成、蒙特卡洛Dropout）在CIFAR-10和FFHQ数据集上的表现，分析分数估计与图像质量的关系，并在表格数据上测试随机森林集成，同时提供分数模型求和的理论分析

Result: 集成分数通常能改善分数匹配损失和模型似然，但无法一致提升感知质量指标如FID；在表格数据中发现某些集成策略优于其他方法

Conclusion: 扩散模型集成在理论指标上有益，但在实际图像质量评估中效果有限，这为理解模型集成和组合技术（如引导）提供了理论洞见

Abstract: Diffusion models now generate high-quality, diverse samples, with an increasing focus on more powerful models. Although ensembling is a well-known way to improve supervised models, its application to unconditional score-based diffusion models remains largely unexplored. In this work we investigate whether it provides tangible benefits for generative modelling. We find that while ensembling the scores generally improves the score-matching loss and model likelihood, it fails to consistently enhance perceptual quality metrics such as FID on image datasets. We confirm this observation across a breadth of aggregation rules using Deep Ensembles, Monte Carlo Dropout, on CIFAR-10 and FFHQ. We attempt to explain this discrepancy by investigating possible explanations, such as the link between score estimation and image quality. We also look into tabular data through random forests, and find that one aggregation strategy outperforms the others. Finally, we provide theoretical insights into the summing of score models, which shed light not only on ensembling but also on several model composition techniques (e.g. guidance).

</details>


### [43] [Low-Rank Key Value Attention](https://arxiv.org/abs/2601.11471)
*James O'Neill,Robert Clancy,Mariia Matskevichus,Fergal Reid*

Main category: cs.LG

TL;DR: LRKV是一种通过低秩残差共享KV投影来减少Transformer KV缓存内存占用的注意力机制，在保持全token分辨率的同时实现计算效率提升。


<details>
  <summary>Details</summary>
Motivation: Transformer预训练面临内存和计算资源限制，其中KV缓存成为训练和自回归解码的主要瓶颈。需要一种既能减少KV缓存内存占用，又能保持模型性能的注意力机制。

Method: 提出低秩KV适应（LRKV），在多头注意力中使用共享的全秩KV投影，并添加低秩的、头特定的残差项。这种方法在完全共享和完全独立注意力之间提供连续权衡，是标准多头注意力的直接替代方案。

Result: 在大规模预训练实验中，LRKV相比标准注意力、MQA/GQA和MLA，实现了更快的损失下降、更低的验证困惑度和更强的下游任务性能。在2.5B规模下，LRKV使用约一半的KV缓存就能超越标准注意力性能，达到相同模型质量时减少20-25%的训练计算量。

Conclusion: LRKV通过分析算子空间中的注意力头结构，证明其几乎保留了标准注意力的所有功能头多样性，而更激进的KV共享机制则依赖查询专业化补偿。LRKV成为内存和计算受限条件下扩展Transformer预训练的实用有效注意力机制。

Abstract: Transformer pretraining is increasingly constrained by memory and compute requirements, with the key-value (KV) cache emerging as a dominant bottleneck during training and autoregressive decoding. We propose \textit{low-rank KV adaptation} (LRKV), a simple modification of multi-head attention that reduces KV cache memory by exploiting redundancy across attention heads while preserving full token-level resolution. Each layer uses a shared full-rank KV projection augmented with low-rank, head-specific residuals, yielding a continuous trade-off between complete sharing and fully independent attention.
  LRKV is a drop-in replacement for standard multi-head attention and directly subsumes query-sharing approaches such as multi-query and grouped-query attention, while remaining distinct from latent-compression methods such as multi-latent attention (MLA). Across large-scale pretraining experiments, LRKV consistently achieves faster loss reduction, lower validation perplexity, and stronger downstream task performance than standard attention, MQA/GQA, and MLA. At the 2.5B scale, LRKV outperforms standard attention while using roughly half the KV cache, and reaches equivalent model quality with up to \textbf{20-25\% less training compute} when measured in cumulative FLOPs. To explain these gains, we analyze attention head structure in operator space and show that LRKV preserves nearly all functional head diversity relative to standard attention, whereas more aggressive KV-sharing mechanisms rely on compensatory query specialization. Together, these results establish LRKV as a practical and effective attention mechanism for scaling Transformer pretraining under memory- and compute-constrained regimes.

</details>


### [44] [Extractive summarization on a CMOS Ising machine](https://arxiv.org/abs/2601.11491)
*Ziqing Zeng,Abhimanyu Kumar,Chris H. Kim,Ulya R. Karpuzcu,Sachin S. Sapatnekar*

Main category: cs.LG

TL;DR: 该论文探索在低功耗CMOS耦合振荡器伊辛机上实现McDonald式抽取式摘要，通过硬件感知的伊辛公式化、随机舍入和分解策略，在CNN/DailyMail数据集上实现3-4.5倍加速和2-3个数量级的能耗降低。


<details>
  <summary>Details</summary>
Motivation: 现代抽取式摘要系统虽然使用强大的神经模型实现高精度，但通常依赖CPU或GPU基础设施，这些设备能耗高且不适合资源受限环境中的实时推理。本研究旨在探索在低功耗CMOS耦合振荡器伊辛机上实现抽取式摘要的可行性。

Method: 1. 提出硬件感知的伊辛公式化方法，减少局部场和耦合项之间的尺度不平衡，提高对系数量化的鲁棒性；2. 开发完整的抽取式摘要流水线，包括随机舍入和迭代细化以补偿精度损失；3. 采用分解策略将大型摘要问题划分为可在COBI上高效求解的较小伊辛子问题。

Result: 在CNN/DailyMail数据集上，该流水线仅使用有限精度的整数耦合伊辛硬件就能生成高质量摘要。COBI相比暴力方法实现3-4.5倍运行时间加速（与软件Tabu搜索相当），能耗降低2-3个数量级，同时保持有竞争力的摘要质量。

Conclusion: 这些结果突显了CMOS伊辛求解器在边缘设备上实现实时、低能耗文本摘要的潜力，为资源受限环境中的高效摘要系统提供了新途径。

Abstract: Extractive summarization (ES) aims to generate a concise summary by selecting a subset of sentences from a document while maximizing relevance and minimizing redundancy. Although modern ES systems achieve high accuracy using powerful neural models, their deployment typically relies on CPU or GPU infrastructures that are energy-intensive and poorly suited for real-time inference in resource-constrained environments. In this work, we explore the feasibility of implementing McDonald-style extractive summarization on a low-power CMOS coupled oscillator-based Ising machine (COBI) that supports integer-valued, all-to-all spin couplings. We first propose a hardware-aware Ising formulation that reduces the scale imbalance between local fields and coupling terms, thereby improving robustness to coefficient quantization: this method can be applied to any problem formulation that requires k of n variables to be chosen. We then develop a complete ES pipeline including (i) stochastic rounding and iterative refinement to compensate for precision loss, and (ii) a decomposition strategy that partitions a large ES problem into smaller Ising subproblems that can be efficiently solved on COBI and later combined. Experimental results on the CNN/DailyMail dataset show that our pipeline can produce high-quality summaries using only integer-coupled Ising hardware with limited precision. COBI achieves 3-4.5x runtime speedups compared to a brute-force method, which is comparable to software Tabu search, and two to three orders of magnitude reductions in energy, while maintaining competitive summary quality. These results highlight the potential of deploying CMOS Ising solvers for real-time, low-energy text summarization on edge devices.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [45] [A numerical study on the effect of rolling friction on clogging of pores in particle-laden flows](https://arxiv.org/abs/2601.11121)
*Sagar G. Nayak,Zhenjiang You,Yuchen Dai,Geoff Wang,Prapanch Nair*

Main category: physics.flu-dyn

TL;DR: 该研究通过直接数值模拟探究了滚动阻力对多孔介质中致密悬浮液堵塞行为的影响，开发了DEM-IBM耦合方法进行孔隙尺度模拟。


<details>
  <summary>Details</summary>
Motivation: 流体注入多孔储层时，颗粒物质会因孔隙堵塞而损害渗透性。颗粒在孔隙喉道处体积分数增加时，颗粒间接触力学决定了其堵塞行为。虽然滚动阻力系数常用于表征颗粒刚性、形状、润滑和流体介导阻力，但其对堵塞行为的直接影响在文献中尚未得到充分研究。

Method: 开发了离散元法（DEM）库并与开源浸没边界法（IBM）求解器耦合，进行孔隙和颗粒分辨的直接数值模拟（DNS）。进行了多个3D验证，研究了滚动阻力对孔隙入口处堵塞行为的影响。

Result: 研究展示了DEM库和DEM-IBM耦合的多个3D验证结果，并系统分析了滚动阻力对孔隙入口处堵塞行为的具体影响。

Conclusion: 该研究通过孔隙尺度直接数值模拟，首次系统揭示了滚动阻力对致密悬浮液在多孔介质中堵塞行为的重要影响，为理解颗粒-流体相互作用机制提供了新的见解。

Abstract: Particulate matter in a fluid injected into a porous reservoir impairs its permeability spatio-temporally due to pore clogging. As particle volume fraction increases near the pore throats, inter-particle contact mechanics determine their jamming and subsequent pore clogging behavior. During contact of particles submerged in a fluid, in addition to sliding friction, a rolling resistance develops due to a several micromechanical and hydrodynamic factors. A coefficient of rolling friction is often used as a lumped parameter to characterize particle rigidity, particle shape, lubrication and fluid mediated resistance, however its direct influence on the clogging behavior is not well studied in literature. We study the effect of rolling resistance on the clogging behavior of a dense suspension at pore scale using direct numerical simulations (DNS). A discrete element method (DEM) library is developed and coupled with an open-source immersed boundary method (IBM) based solver to perform pore and particle resolved simulations. Several 3D validations are presented for the DEM library and the DEM-IBM coupling and the effect of rolling resistance on clogging at a pore entry is studied.

</details>


### [46] [Scale-resolving simulations and data-driven modal analysis of turbulent transonic buffet cells on infinite swept wings](https://arxiv.org/abs/2601.11137)
*David J. Lusher,Andrea Sansica*

Main category: physics.flu-dyn

TL;DR: 该研究通过隐式大涡模拟和模态分析，首次在展弦比达3的无限翼展机翼上研究了后掠效应对跨音速翼型抖振的影响，揭示了抖振由二维激波运动和三维分离驱动的不稳定性叠加而成，平均流动分离是主导三维抖振动力学的必要条件。


<details>
  <summary>Details</summary>
Motivation: 以往跨音速翼型抖振的尺度解析模拟受计算成本限制，仅限于窄机翼，无法充分研究实验和低精度模拟中报告的三维抖振单元不稳定性。本研究旨在通过模拟更大展弦比机翼并考虑后掠效应，深入理解三维抖振动力学的形成机制。

Method: 采用隐式大涡模拟（ILES）和模态分析方法，首次在展弦比达3的无限翼展机翼上研究后掠效应。考察两种流动条件：激波位置处最小分离和大幅分离的平均流动。使用谱本征正交分解分析流动模态。

Result: 最小分离情况下，激波动力学基本保持展向均匀（准二维），只有微弱且间歇的分离单元局限于后缘区域，与激波相互作用可忽略。而增加平均分离会导致明显的三维抖振单元出现，特征展向波长为1-1.5c。后掠使先前在无后掠机翼上识别的静止低频三维分离模态转变为展向传播模态，频率单调增加到中等范围（St=0.06-0.35）。二维激波模态对后掠基本不敏感，而三维模态的频率和能量随后掠增加，波长保持不变。

Conclusion: 跨音速抖振源于相互耦合但不同的二维激波运动和三维分离驱动不稳定性的叠加。激波位置处的平均流动分离是主导三维抖振动力学出现的必要条件。后掠效应会改变三维模态的特性，使其从静止模态转变为传播模态并增加频率，但对二维激波模态影响较小。

Abstract: Transonic airfoil buffet is a class of shock-wave/boundary-layer interaction (SBLI) known to exhibit self-sustained two-dimensional (2D) chordwise shock wave oscillations (Strouhal number St=0.05-0.1), and three-dimensional (3D) spanwise-modulated flow separation/reattachment (St=0.2-0.4). Due to computational cost, scale-resolving simulations of span-periodic configurations to date have been limited to narrow airfoils, insufficient to accommodate the 3D buffet cell instability reported in low-fidelity simulations and experiments. In this work, implicit large-eddy simulations (ILES) and modal analysis are performed on infinite wings up to AR=3 with sweep effects for the first time. Two flow conditions are examined, corresponding to minimally and largely separated mean flow at the shock location. For the minimally separated case, the shock dynamics remain essentially spanwise-uniform (quasi-2D), with only weak and intermittent separation cells confined to the trailing-edge region and exhibiting negligible interaction with the shock. In contrast, increased mean separation leads to the emergence of pronounced 3D buffet cells with a characteristic spanwise wavelength: 1-1.5c. Spectral proper orthogonal decomposition reveals that a stationary low-frequency 3D separation mode previously identified on unswept wings (St=0.02) becomes a spanwise travelling mode as sweep is imposed, shifting monotonically to intermediate frequencies (St=0.06-0.35). The 2D shock mode is largely insensitive to sweep, whereas the frequency and energy content of the 3D mode increase with sweep while its wavelength remains unchanged. The results demonstrate that transonic buffet arises from the superposition of distinct but coupled 2D shock motion and separation-driven 3D instabilities, with mean flow separation at the shock identified as a necessary condition for dominant 3D buffet dynamics to emerge.

</details>


### [47] [Inertial Self-Caging: Dynamics of Macroscopic Swimmers at Moderate Reynolds Number Sustaining Chemical Wake Resonance](https://arxiv.org/abs/2601.11264)
*Alessandro Foradori,Paolo Bettotti*

Main category: physics.flu-dyn

TL;DR: 该研究探索了在中等雷诺数（100-200）惯性流态下化学驱动宏观水凝胶游泳者的运动特性，发现了在受限几何中稳定的共振状态，以及从共振振荡到随机"停走"行为的临界转变。


<details>
  <summary>Details</summary>
Motivation: 传统自推进泳体研究主要关注层流区域，其低速使得惯性效应可忽略且轨迹高度可预测。本研究旨在解决惯性流态下的推进挑战，探索在中等雷诺数下流体动力学非线性特性如何影响化学驱动游泳者的运动。

Method: 使用化学驱动的宏观水凝胶作为研究对象，通过实验和建模相结合的方法，在受限几何条件下研究游泳者的运动特性。重点关注游泳者与自身持久化学尾迹的相互作用。

Result: 发现了稳定的共振状态：游泳者循环运动时与自身化学尾迹相互作用，产生化学自反馈机制，形成复杂的稳定运动，表现为普遍的指数速度衰减叠加显著的周期性速度振荡。识别了临界阈值速度，系统在此速度下从共振振荡状态突然转变为随机的"停走"行为。

Conclusion: 这些发现为理解化学场、流体动力学惯性和受限几何如何耦合决定高速活性物质运动特性提供了基础性认识，揭示了在惯性流态下化学驱动游泳者的复杂动力学行为。

Abstract: Self-propelled phoretic swimmers are generally studied in the laminar flow regime, where their low speed renders inertial effects negligible and trajectories highly predictable. This research tackles the challenge of propulsion in the inertial regime, at moderate Reynolds numbers (100 < Re < 200), where fluid dynamics becomes non-linear. By using a chemically driven macroscopic hydrogel this work demonstrates, through experiments and modeling, the existence of stable resonant states under confined geometry: as the swimmer circles, it interacts with its own lasting chemical wake. This chemical self-feedback creates a complex, stable motion characterized by both universal exponential speed decay with superimposed significant periodic speed oscillations. Furthermore, a critical threshold speed is identified, where the system abruptly transitions from the resonant oscillatory regime to a stochastic stop & go behavior. These findings provide a fundamental understanding of how chemical fields, hydrodynamic inertia, and confinement couple to determine the motion properties of high-speed active matter.

</details>


### [48] [Analytical Solutions of the Minimal Nonlinear Equation for the Yaw Response of Tail Fins and Wind Vanes](https://arxiv.org/abs/2601.11349)
*Mohamed M. Hammam,David H. Wood*

Main category: physics.flu-dyn

TL;DR: 该论文推导了小型风力机尾翼和风向标偏航响应的解析解，适用于任意翼型和初始释放角γ₀，扩展了现有线性模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有线性模型仅适用于小|γ₀|和低展弦比翼型，无法准确描述尾翼和风向标的非线性偏航响应。需要建立更通用的解析模型来考虑非线性阻尼效应。

Method: 采用摄动技术分析偏航角γ的二阶最小方程。使用Krylov-Bogoliubov-Mitropolskii平均法获得截断级数解，并与Beecham和Titchener(1971)的另一种平均方法对比，后者可得到振幅衰减率和相位角变化率的紧凑解。

Result: 推导出小|γ₀|和大|γ₀|两种极限情况的解析解。高Kv值对尾翼在大|γ₀|时的快速振幅衰减至关重要。风向标的高展弦比可减少非线性以最小化偏航误差。当sin(πγ₀)≈πγ₀时出现与Kv无关的线性响应。

Conclusion: 该研究提供了尾翼和风向标偏航响应的通用解析解框架，能够准确描述非线性阻尼效应。小角度解析解可用于从实验数据识别模型参数，并为高γ情况的风向标建模提供扩展基础。

Abstract: Analytical solutions for the yaw response of tail fins for small wind turbines, and wind vanes for wind direction measurement, are derived for any planform and any release angle $γ_0$. This extends current linear models limited to small $|γ_0|$ and low aspect ratio planforms. The equation studied here is the minimal form of the general second order equation for the yaw angle, $γ$, derived by Hammam and Wood (2023). The nonlinear damping is controlled by a small parameter that depends on the vortex flow coefficient, $K_v$, which is absent from all linear models. The minimal equation is analysed using perturbation techniques. A truncated series solution from the Krylov-Bogoliubov-Mitropolskii averaging method compares favourably with a numerical solution apart from some small deviations at large time. Another form of averaging due to Beecham and Titchener (1971) yields a compact solution in terms of the rate of amplitude decay, and the rate of change of phase angle. This allows the identification of an equivalent linear system with equivalent frequency and damping ratio. Two limiting analytic solutions for small and large $|γ_0|$ are obtained. The former is used to identify the model parameters from experimental data. Both approximate solutions showed that high $K_v$ is important for fast decay of yaw amplitude for tail fins at high $|γ_0|$. High aspect ratios for wind vanes would reduce the nonlinearity to minimize yaw error. Linear response that is independent of $K_v$ occurs whenever $\sin{(πγ_0)\approx πγ_0}$. Further, the low angle analytical solution allows an exact identification of the nonlinearity which could be used to extend the modelling of wind vanes to high $γ$.

</details>


### [49] [Differential geometry of particle motion in Stokesian regime](https://arxiv.org/abs/2601.11377)
*Sumedh R. Risbud*

Main category: physics.flu-dyn

TL;DR: 论文提出了一个微分几何框架，用于描述非布朗粒子在静止流体中固定障碍物周围的确定性斯托克斯运动，证明物理轨迹是耗散缩放度规的测地线而非纯阻力度规的测地线。


<details>
  <summary>Details</summary>
Motivation: 赫尔姆霍兹最小耗散定理表明流体阻力张量可作为流体域的黎曼度规，但实际观察发现恒定外力驱动的粒子轨迹并非该纯阻力度规的测地线，存在几何漂移现象，需要建立统一的几何形式来解释这一现象。

Method: 引入统一的几何形式，证明物理轨迹是共形缩放度规 $\tilde{g}_{ij} = \mathcal{D}(\mathbf{x})R_{ij}$ 的测地线，其中 $\mathcal{D}$ 是局部功率耗散。该框架将轨迹的仿射参数与累积能量耗散对应起来。

Result: 理论应用于球形粒子被固定障碍物散射的情况，证明先前推导的粒子轨迹是该耗散缩放流形曲率的直接结果，验证了框架的有效性。

Conclusion: 建立了描述非布朗粒子在斯托克斯流体中运动的微分几何框架，揭示了物理轨迹是耗散缩放度规而非纯阻力度规的测地线，为理解流体中粒子运动提供了新的几何视角。

Abstract: We present a differential geometric framework for the motion of a non-Brownian particle in the presence of fixed obstacles in a quiescent fluid, in the deterministic Stokesian regime. While the Helmholtz Minimum Dissipation Theorem suggests that the hydrodynamic resistance tensor $R_{ij}$ acts as the natural Riemannian metric of the fluid domain, we demonstrate that particle trajectories driven by constant external forces are \emph{not} geodesics of this pure resistance metric. Instead, they experience a geometric drift perpendicular to the geodesic path due to the manifold's curvature. To reconcile this, we introduce a unified geometric formalism, proving that physical trajectories are geodesics of a conformally scaled metric, $\tilde{g}_{ij} = \mathcal{D}(\mathbf{x})R_{ij}$, where $\mathcal{D}$ is the local power dissipation. This framework establishes that the affine parameter along the trajectory corresponds to the cumulative energy dissipated. We apply this theory to the scattering of a spherical particle by a fixed obstacle, showing that the previously derived trajectory of the particle is recovered as a direct consequence of the curvature of this dissipation-scaled manifold.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [50] [CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems](https://arxiv.org/abs/2601.10738)
*Percy Jardine*

Main category: cs.AI

TL;DR: 提出约束时间分层架构（CTHA），通过结构化流形投影和仲裁机制解决多时间尺度智能体架构中的层间冲突和协调稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 多时间尺度智能体架构虽然提升了性能，但破坏了统一智能体系统的协调稳定性，导致层间冲突、错误传播无界和可扩展性受限等问题。

Method: 提出约束时间分层架构（CTHA），包含三个关键约束：消息契约约束（通过类型化摘要、计划和策略包形式化层间信息流）、权威流形约束（根据时间范围限定各层决策空间）、仲裁器解析约束（保证多层决策的无冲突组合）。

Result: 实验表明CTHA在复杂任务执行中有效，相比无约束分层基线减少47%的故障级联，提升2.3倍样本效率，并具有更优的可扩展性。

Conclusion: CTHA作为时间分层架构的原则性扩展，有助于深入理解多智能体协调，并为稳健自主系统的演进提供有前景的方向。

Abstract: Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.

</details>


### [51] [Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration](https://arxiv.org/abs/2601.10744)
*Sen Wang,Bangwei Liu,Zhenkun Gao,Lizhuang Ma,Xuhong Wang,Yuan Xie,Xin Tan*

Main category: cs.AI

TL;DR: LMEE框架通过统一探索认知与决策行为促进具身智能终身学习，提出MemoryExplorer方法增强记忆检索与主动探索能力


<details>
  <summary>Details</summary>
Motivation: 现有一次性具身任务主要关注任务完成结果，忽视了探索过程和记忆利用这一关键环节，无法支持终身学习能力

Method: 提出LMEE框架统一探索认知与决策行为；构建LMEE-Bench数据集和基准测试；提出MemoryExplorer方法，通过强化学习微调多模态大语言模型，采用包含动作预测、前沿选择和问答的多任务奖励函数

Result: 在长时程具身任务中相比最先进的具身探索模型取得显著优势，证明了主动记忆查询和探索的有效性

Conclusion: LMEE框架通过统一探索与决策、增强记忆检索能力，有效促进了具身智能的终身学习，为长时程复杂任务处理提供了新思路

Abstract: An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks.

</details>


### [52] [Optimisation of complex product innovation processes based on trend models with three-valued logic](https://arxiv.org/abs/2601.10768)
*Nina Bočková,Barbora Volná,Mirko Dohnal*

Main category: cs.AI

TL;DR: 使用基于启发式的趋势模型分析复杂产品创新过程，通过简单趋势（增加、减少、恒定）作为最小信息量化器，避免依赖数值或粗糙集


<details>
  <summary>Details</summary>
Motivation: 研究复杂产品创新过程需要简化但有效的建模方法，避免传统数值模型的复杂性，同时保持对系统行为的描述能力

Method: 基于启发式构建趋势模型，每个启发式表达为简单趋势（增加/减少/恒定），定义场景集合和场景间转移图作为模型解

Result: 提出了一种通过转移图表示系统所有可能未来或过去行为的方法，系统行为可描述为图中的路径

Conclusion: 趋势模型为复杂产品创新过程分析提供了简洁有效的框架，避免了数值复杂性，同时保持了系统行为描述的完整性

Abstract: This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.

</details>


### [53] [ARC Prize 2025: Technical Report](https://arxiv.org/abs/2601.10904)
*François Chollet,Mike Knoop,Gregory Kamradt,Bryan Landers*

Main category: cs.AI

TL;DR: ARC-AGI-2竞赛显示AI在抽象推理方面进展有限，最高得分仅24%，但涌现了精炼循环方法，前沿AI实验室开始将ARC-AGI作为行业标准基准。


<details>
  <summary>Details</summary>
Motivation: 分析ARC-AGI-2竞赛结果，研究精炼循环方法在AGI进展中的作用，探讨当前AI推理能力的根本限制（知识覆盖依赖），并预览下一代ARC-AGI-3基准。

Method: 对Kaggle竞赛（1,455个团队，15,154个提交）和90篇论文进行调查研究，分析顶级方法（特别是精炼循环方法），包括进化程序合成方法、商业AI系统的应用层精炼，以及零预训练深度学习方法。

Result: ARC-AGI-2最高得分仅24%，显示AI在抽象推理方面仍有巨大差距。精炼循环方法成为2025年主导主题，前沿AI实验室（Anthropic、Google DeepMind、OpenAI、xAI）开始将ARC-AGI作为行业标准基准，但当前AI推理能力仍受限于知识覆盖，导致新的基准污染形式。

Conclusion: 当前前沿AI推理性能仍受知识覆盖限制，需要新的基准来评估更复杂的推理能力。ARC-AGI-3将引入需要探索、规划、记忆、目标获取和对齐能力的交互式推理挑战，以推动AGI发展。

Abstract: The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities.

</details>


### [54] [What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge](https://arxiv.org/abs/2601.10922)
*Yosub Shin,Michael Buriek,Boris Sobolev,Pavel Bushuyeu,Vikas Kumar,Haoyang Xu,Samuel Watson,Igor Molybog*

Main category: cs.AI

TL;DR: 该研究通过NeurIPS 2025 DCVLR挑战赛探索多模态推理的数据策展，发现基于难度的样本选择是性能提升的主要因素，而数据集大小增加主要减少方差而非提升平均准确率。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在多模态推理任务中，当模型和训练协议固定时，如何通过数据策展（数据集选择）来优化性能。通过DCVLR挑战赛这一隔离变量设置，专门研究数据选择对多模态推理的影响。

Method: 主要方法包括：1）使用基于Walton多模态冷启动数据集的紧凑策展数据集；2）采用基于难度的样本选择策略；3）在固定训练方案下进行数据集大小、多样性和合成增强等消融实验。

Result: 研究结果显示：1）基于对齐基础数据集的难度样本选择是性能提升的主要驱动因素；2）增加数据集大小不能可靠提高平均准确率，但能减少运行间的方差；3）常用的多样性和合成增强启发式方法没有额外益处，反而可能降低性能。

Conclusion: 结论表明DCVLR是一个饱和状态评估场景，强调了数据对齐和难度在多模态推理数据效率中的核心作用，为数据策展提供了实用指导。

Abstract: We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.

</details>


### [55] [ReCreate: Reasoning and Creating Domain Agents Driven by Experience](https://arxiv.org/abs/2601.11100)
*Zhezheng Hao,Hong Wang,Jian Luo,Jianqing Zhang,Yuyan Zhou,Qiang Lin,Can Wang,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: ReCreate：基于经验驱动的自动领域智能体创建框架，通过智能体交互历史学习成功失败原因，实现高效智能体生成与优化


<details>
  <summary>Details</summary>
Motivation: 当前大多数实用智能体仍依赖人工设计，任务差异大导致构建成本高；现有自动化方法将智能体生成视为黑盒过程，仅依赖最终性能指标，忽略了成功/失败的关键证据且计算成本高

Method: 提出ReCreate框架，采用智能体即优化器范式，包含三个核心组件：1) 经验存储与检索机制，支持按需检查；2) 推理-创建协同管道，将执行经验映射为脚手架编辑；3) 分层更新，将实例级细节抽象为可重用领域模式

Result: 在多个领域实验中，ReCreate始终优于人工设计的智能体和现有自动化智能体生成方法，即使从最小种子脚手架开始也能取得良好效果

Conclusion: ReCreate通过系统利用智能体交互历史中的具体信号，解决了现有自动化智能体生成方法的局限性，实现了高效、可解释的领域智能体自动创建与适应

Abstract: Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.

</details>


### [56] [Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems](https://arxiv.org/abs/2601.11147)
*Zixu Wang,Bingbing Xu,Yige Yuan,Huawei Shen,Xueqi Cheng*

Main category: cs.AI

TL;DR: SCALE框架通过任务级工作流生成和自预测评估，在保持性能的同时大幅降低token使用量


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的多智能体系统在任务级或查询级生成工作流，但两者的相对成本和效益不明确，且执行式任务级评估token成本高且不可靠

Method: 提出SCALE框架：通过少量样本校准的自预测优化器进行任务级工作流生成，替代昂贵的完整验证执行

Result: SCALE在多个数据集上平均性能仅下降0.61%，同时将总体token使用量减少高达83%

Conclusion: 查询级工作流生成并非总是必要，任务级工作流生成结合自预测评估可以在保持性能的同时显著降低成本

Abstract: Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \textbf{SCALE}, which means \underline{\textbf{S}}elf prediction of the optimizer with few shot \underline{\textbf{CAL}}ibration for \underline{\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\%.

</details>


### [57] [TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech](https://arxiv.org/abs/2601.11178)
*Girish A. Koushik,Helen Treharne,Diptesh Kanojia*

Main category: cs.AI

TL;DR: TANDEM是一个统一框架，将视听仇恨检测从二元分类任务转变为结构化推理问题，通过串联强化学习实现跨模态上下文优化，显著提升目标识别和时间定位性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中长格式多模态内容日益增多，有害叙事通过音频、视觉和文本线索的复杂交互构建。现有自动化系统虽然能高精度标记仇恨言论，但往往作为"黑箱"运行，无法提供人类在环审核所需的细粒度、可解释证据（如精确时间戳和目标身份）。

Method: 提出TANDEM框架，采用新颖的串联强化学习策略，其中视觉-语言和音频-语言模型通过自约束跨模态上下文相互优化，在不需要密集帧级监督的情况下稳定长时序序列的推理。

Result: 在三个基准数据集上的实验表明，TANDEM显著优于零样本和上下文增强基线，在HateMM数据集上目标识别F1达到0.73（比最先进方法提升30%），同时保持精确的时间定位。二元检测稳健，但在多类设置中区分冒犯性和仇恨内容仍具挑战性。

Conclusion: 即使在复杂多模态环境中，结构化、可解释的对齐也是可实现的，为下一代透明且可操作的在线安全审核工具提供了蓝图。

Abstract: Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as "black boxes" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.

</details>


### [58] [XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making](https://arxiv.org/abs/2601.11286)
*Weihong Qi,Fan Huang,Rasika Muralidharan,Jisun An,Haewoon Kwak*

Main category: cs.AI

TL;DR: XChoice是一个可解释的框架，用于评估约束决策中AI与人类的对齐度，超越传统准确性指标，通过机制建模分析决策因素、约束敏感性和权衡关系。


<details>
  <summary>Details</summary>
Motivation: 现有AI评估主要关注结果一致性（如准确率、F1分数），但缺乏对决策机制的深入理解，无法诊断AI与人类在约束决策中的根本对齐差异。

Method: XChoice将基于机制的决策模型拟合到人类数据和LLM生成的决策中，恢复可解释参数（决策因素相对重要性、约束敏感性、隐含权衡），通过比较参数向量评估对齐度。

Result: 在美国时间分配研究中，发现模型和活动之间存在异质性对齐，黑人和已婚群体中存在显著不对齐；通过不变性分析验证了鲁棒性，RAG干预实现了针对性缓解。

Conclusion: XChoice提供基于机制的度量标准，能够诊断不对齐并支持超越表面结果匹配的知情改进，为AI-人类对齐评估提供了更深入的框架。

Abstract: We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.

</details>


### [59] [AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems](https://arxiv.org/abs/2601.11354)
*Weiyi Wang,Xinchi Chen,Jingjing Gong,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: AstroReason-Bench是一个用于评估智能体在空间规划问题中规划能力的基准测试，该基准整合了多种调度机制，发现当前智能体在物理约束下的表现远不如专用求解器。


<details>
  <summary>Details</summary>
Motivation: 现有智能体基准主要关注符号化或弱接地环境，缺乏对物理约束现实领域性能的评估，需要建立一个具有严格物理约束、异质目标和长时程决策的高风险问题基准。

Method: 提出了AstroReason-Bench基准，整合了地面站通信和敏捷地球观测等多种调度机制，提供了统一的智能体导向交互协议，并评估了多种最先进的开源和闭源智能体LLM系统。

Result: 当前智能体在空间规划问题中的表现显著低于专用求解器，揭示了在现实约束下通用规划器的关键局限性。

Conclusion: AstroReason-Bench为未来智能体研究提供了一个具有挑战性和诊断性的测试平台，有助于推动智能体在物理约束现实领域的发展。

Abstract: Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.

</details>


### [60] [Hyperparameter Optimization of Constraint Programming Solvers](https://arxiv.org/abs/2601.11389)
*Hedieh Haddad,Thibault Falque,Pierre Talbot,Pascal Bouvry*

Main category: cs.AI

TL;DR: 提出"探测与求解"两阶段框架，用于约束规划求解器的自动超参数优化，通过贝叶斯优化显著提升求解性能


<details>
  <summary>Details</summary>
Motivation: 约束规划求解器的性能高度依赖于超参数配置，手动调参需要专业知识且耗时，需要自动化方法来优化求解器配置

Method: 提出两阶段框架：探测阶段使用可配置的超参数优化方法（贝叶斯优化和汉明距离搜索）探索不同超参数集，求解阶段使用最佳配置在剩余时间内解决问题；集成到CPMpy库中

Result: 在114个组合问题实例上评估，贝叶斯优化优于默认配置：ACE在25.4%实例中提升质量，57.9%持平；Choco在38.6%实例中表现更优；贝叶斯优化始终优于汉明距离搜索

Conclusion: "探测与求解"算法提供了实用、资源感知的约束求解器调优方法，在多种问题类型上实现稳健改进，模型化探索优于简单局部搜索

Abstract: The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.
  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.
  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.

</details>


### [61] [Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs](https://arxiv.org/abs/2601.11468)
*Alessandro Padella,Massimiliano de Leoni,Marlon Dumas*

Main category: cs.AI

TL;DR: 本文扩展了基于LLM的预测性过程监控框架，从仅关注总时间预测扩展到全面评估其通用性、语义利用和推理机制，涵盖多个关键绩效指标。在数据稀缺场景下，LLM在总时间和活动发生预测方面超越了基准方法。


<details>
  <summary>Details</summary>
Motivation: 预测性过程监控旨在预测进行中过程的结果，传统方法使用机器学习和深度学习架构。本文旨在扩展先前基于LLM的框架，全面评估其在多个关键绩效指标上的通用性、语义利用能力和推理机制，特别是在数据稀缺环境下的表现。

Method: 扩展了基于LLM的预测性过程监控框架，从仅通过提示进行总时间预测扩展到更全面的评估。在三个不同事件日志上进行实证评估，涵盖总时间和活动发生两个关键绩效指标。特别关注数据稀缺设置（仅100条轨迹）下的性能表现。

Result: 在数据稀缺设置（仅100条轨迹）下，LLM在总时间和活动发生预测方面超越了基准方法。实验表明LLM利用了其先验知识和训练轨迹间的内部相关性。模型不仅复制现有预测方法，而是执行高阶推理来生成预测。

Conclusion: 基于LLM的预测性过程监控框架在数据稀缺环境下表现出色，能够利用先验知识和内部相关性进行高阶推理，超越了传统基准方法。这证明了LLM在过程监控领域的潜力和通用性。

Abstract: Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.

</details>


### [62] [Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning](https://arxiv.org/abs/2601.11479)
*Yohai Trabelsi,Guojun Xiong,Fentabil Getnet,Stéphane Verguet,Milind Tambe*

Main category: cs.AI

TL;DR: 提出LEG框架，结合LLM和扩展贪心算法，在资源有限条件下优化埃塞俄比亚卫生站升级优先级，平衡人口覆盖与专家偏好


<details>
  <summary>Details</summary>
Motivation: 埃塞俄比亚卫生部升级卫生站以改善基本医疗服务可及性，但资源有限需要优先选择升级设施。传统优化方法需要明确量化目标，而利益相关者偏好常以自然语言表达难以形式化，需要桥接专家知识与优化技术

Method: 开发LEG（大型语言模型与扩展贪心）框架，结合可证明近似算法（人口覆盖优化）与LLM驱动的迭代精炼，通过人机对齐确保解决方案反映专家定性指导同时保持覆盖保证

Result: 在埃塞俄比亚三个地区的真实数据上进行实验，证明该框架的有效性，展示了其支持公平、数据驱动的卫生系统规划的潜力

Conclusion: LEG框架成功整合专家知识与优化技术，为资源有限环境下的卫生设施升级优先级决策提供了系统方法，平衡了人口覆盖最大化与利益相关者偏好

Abstract: Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [63] [Collaborative Continuum Robots: A Survey](https://arxiv.org/abs/2601.10721)
*Xinyu Li,Qian Tang,Guoxin Yin,Gang Zheng,Jessica Burgner-Kahrs,Cesare Stefanini,Ke Wu*

Main category: cs.RO

TL;DR: 该综述论文系统回顾了协作连续体机器人(CCRs)的研究进展，从系统架构层面提供了清晰的研究框架，包括三种协作模式的分类、结构设计、建模、运动规划与控制等方面的总结，并讨论了当前挑战和未来机遇。


<details>
  <summary>Details</summary>
Motivation: 连续体机器人因其紧凑结构、固有柔顺性和灵活变形能力已在多个领域广泛应用。通过协调多个连续体机器人形成协作连续体机器人系统，可以进一步提高任务适应性、工作空间、灵活性、负载能力和操作稳定性，具有显著优势。近年来该新兴领域在连续体机器人社区中关注度持续增长，相关出版物稳步增加，需要系统性的综述来梳理研究进展。

Method: 论文采用系统性综述方法，从不同系统架构层面提供全面概述。首先将CCRs分为三种协作模式：分离协作、辅助协作和并行协作，并给出明确定义。接着系统总结了每种模式在结构设计、建模、运动规划和控制方面的研究进展。最后通过综合分析讨论当前挑战和未来机遇。

Result: 该综述为CCRs研究提供了清晰框架，系统梳理了三种协作模式的技术发展现状。在分离协作模式中，多个CRs独立工作但协同完成任务；辅助协作模式中一个CR辅助另一个执行任务；并行协作模式中多个CRs物理连接形成复合结构。论文总结了各模式在机械设计、运动学/动力学建模、路径规划和控制策略等方面的具体进展。

Conclusion: 协作连续体机器人系统具有显著优势和应用潜力，但面临协调控制、实时建模、安全性和标准化等挑战。未来研究方向包括智能协同算法、自适应控制策略、新型材料应用、人机交互接口和标准化框架开发等，这些进展将推动CCRs在医疗、制造、勘探等领域的更广泛应用。

Abstract: Continuum robots (CRs), owing to their compact structure, inherent compliance, and flexible deformation, have been widely applied in various fields. By coordinating multiple CRs to form collaborative continuum robots (CCRs), task adaptability, workspace, flexibility, load capacity, and operational stability can be further improved, thus offering significant advantages. In recent years, interest in this emerging field has grown steadily within the continuum-robotics community, accompanied by a consistent rise in related publications. By presenting a comprehensive overview of recent progress from different system-architecture levels, this survey provides a clear framework for research on CCRs. First, CCRs are classified into the three collaboration modes of separated collaboration, assistance collaboration, and parallel collaboration, with definitions provided. Next, advances in structural design, modeling, motion planning, and control for each mode are systematically summarized. Finally, current challenges and future opportunities for CCRs are discussed.

</details>


### [64] [A Survey of Real-Time Support, Analysis, and Advancements in ROS 2](https://arxiv.org/abs/2601.10722)
*Daniel Casini,Jian-Jia Chen,Jing Li,Federico Reghenzani,Harun Teper*

Main category: cs.RO

TL;DR: ROS 2实时性研究综述：分析ROS 2内部调度机制、通信架构，总结单/多线程执行器时序分析、DDS通信延迟边界、实时GPU管理、micro-ROS等增强技术，提出分类体系指导ROS 2实时能力改进。


<details>
  <summary>Details</summary>
Motivation: ROS 2作为机器人应用的重要中间件框架，近年来在实时系统领域和工业界受到广泛关注。随着机器人系统对实时性要求的提高，需要对ROS 2的实时执行能力进行系统性的分析和增强，以满足实际应用需求。

Method: 1. 详细分析ROS 2内部调度机制和分层架构，包括与DDS通信和其他中间件的交互；2. 综述文献中的关键贡献，涵盖单线程和多线程执行器的时序分析、响应时间、反应时间、数据年龄等指标；3. 分析社区驱动的ROS 2运行时增强，包括新的执行器算法设计、实时GPU管理和micro-ROS微控制器支持；4. 总结DDS通信延迟边界技术、消息过滤器和分析工具；5. 提出分类体系对现有工作进行系统化分类。

Result: 1. 提供了ROS 2实时性研究的全面概述；2. 识别了ROS 2在实时执行方面的关键挑战和解决方案；3. 建立了系统化的分类体系来组织现有研究成果；4. 总结了各种增强技术对ROS 2实时能力的改进效果；5. 为研究者和实践者提供了理解和改进ROS 2实时能力的指导框架。

Conclusion: ROS 2的实时能力研究已取得显著进展，通过执行器优化、通信延迟边界分析、硬件支持扩展等技术手段，显著提升了ROS 2的实时性能。提出的分类体系有助于系统化理解这一领域的发展，为未来的研究和应用提供了明确方向，使ROS 2能够更好地满足机器人系统对实时性的严格要求。

Abstract: The Robot Operating System 2 (ROS~2) has emerged as a relevant middleware framework for robotic applications, offering modularity, distributed execution, and communication. In the last six years, ROS~2 has drawn increasing attention from the real-time systems community and industry. This survey presents a comprehensive overview of research efforts that analyze, enhance, and extend ROS~2 to support real-time execution. We first provide a detailed description of the internal scheduling mechanisms of ROS~2 and its layered architecture, including the interaction with DDS-based communication and other communication middleware. We then review key contributions from the literature, covering timing analysis for both single- and multi-threaded executors, metrics such as response time, reaction time, and data age, and different communication modes. The survey also discusses community-driven enhancements to the ROS~2 runtime, including new executor algorithm designs, real-time GPU management, and microcontroller support via micro-ROS. Furthermore, we summarize techniques for bounding DDS communication delays, message filters, and profiling tools that have been developed to support analysis and experimentation. To help systematize this growing body of work, we introduce taxonomies that classify the surveyed contributions based on different criteria. This survey aims to guide both researchers and practitioners in understanding and improving the real-time capabilities of ROS~2.

</details>


### [65] [Adaptive Sliding Mode Control for Vehicle Platoons with State-Dependent Friction Uncertainty](https://arxiv.org/abs/2601.10724)
*Rishabh Dev Yadav*

Main category: cs.RO

TL;DR: 提出一种用于轮式移动机器人车辆编队的新型自适应滑模控制器，能够处理未知复杂的摩擦力，无需先验知识


<details>
  <summary>Details</summary>
Motivation: 多机器人编队控制在车辆编队、有效载荷运输和监视等领域有广泛应用。维持编队需要设计合适的控制方案来处理外部干扰和不确定系统参数，同时保持预定义的安全距离。关键挑战在于处理轮地之间未知/不确定的摩擦力，这些力随路面条件、轮胎磨损和车辆速度而变化。现有自适应控制器虽然能处理先验有界的不确定性，但难以准确建模和识别摩擦力，这些力通常是状态依赖且无法先验有界的。

Method: 提出新型自适应滑模控制器，采用自适应滑模控制技术调节编队速度并保持预定义机器人间距。采用两阶段过程：首先，运动学控制器基于期望轨迹计算期望速度；其次，动力学模型生成实现期望运动的指令。通过分离机器人的运动学和动力学，简化控制问题，实现更高效鲁棒的轮式移动机器人控制。

Result: 该方法能够处理未知复杂的摩擦力行为，无需先验知识其参数和结构。控制器即使在存在外部干扰和不确定系统参数的情况下，也能调节编队速度并保持预定义机器人间距。

Conclusion: 提出的自适应滑模控制器为轮式移动机器人车辆编队提供了一种有效解决方案，能够处理未知复杂的摩擦力，提高编队控制的鲁棒性和效率。

Abstract: Multi-robot formation control has various applications in domains such as vehicle troops, platoons, payload transportation, and surveillance. Maintaining formation in a vehicle platoon requires designing a suitable control scheme that can tackle external disturbances and uncertain system parameters while maintaining a predefined safe distance between the robots. A crucial challenge in this context is dealing with the unknown/uncertain friction forces between wheels and the ground, which vary with changes in road surface, wear in tires, and speed of the vehicle. Although state-of-the-art adaptive controllers can handle a priori bounded uncertainties, they struggle with accurately modeling and identifying frictional forces, which are often state-dependent and cannot be a priori bounded.
  This thesis proposes a new adaptive sliding mode controller for wheeled mobile robot-based vehicle platoons that can handle the unknown and complex behavior of frictional forces without prior knowledge of their parameters and structures. The controller uses the adaptive sliding mode control techniques to regulate the platoon's speed and maintain a predefined inter-robot distance, even in the presence of external disturbances and uncertain system parameters. This approach involves a two-stage process: first, the kinematic controller calculates the desired velocities based on the desired trajectory; and second, the dynamics model generates the commands to achieve the desired motion. By separating the kinematics and dynamics of the robot, this approach can simplify the control problem and allow for more efficient and robust control of the wheeled mobile robot.

</details>


### [66] [Multi-Agent Formation Navigation Using Diffusion-Based Trajectory Generation](https://arxiv.org/abs/2601.10725)
*Hieu Do Quang,Chien Truong-Quoc,Quoc Van Tran*

Main category: cs.RO

TL;DR: 提出基于扩散策略的领导者-跟随者编队控制方法，用于杂乱环境中的多智能体编队规划


<details>
  <summary>Details</summary>
Motivation: 解决杂乱环境中多智能体编队控制的轨迹生成问题，传统方法在复杂障碍物环境中可能难以生成平滑运动轨迹

Method: 使用扩散策略生成两个领导者中点轨迹（作为平面刚性杆），定义领导者期望运动路径；跟随者使用基于局部坐标相对位置的距约束编队控制器跟踪领导者并形成期望几何形状

Result: 方法产生平滑运动和低跟踪误差，大多数失败发生在狭窄无障碍空间或训练数据集中未包含的障碍物配置中；仿真结果展示了扩散模型在可靠多智能体编队规划中的潜力

Conclusion: 扩散模型在多智能体编队规划中具有应用潜力，能够生成平滑轨迹并实现低跟踪误差，但在处理狭窄空间和未见障碍物配置时仍需改进

Abstract: This paper introduces a diffusion-based planner for leader--follower formation control in cluttered environments. The diffusion policy is used to generate the trajectory of the midpoint of two leaders as a rigid bar in the plane, thereby defining their desired motion paths in a planar formation. While the followers track the leaders and form desired foramtion geometry using a distance-constrained formation controller based only on the relative positions in followers' local coordinates. The proposed approach produces smooth motions and low tracking errors, with most failures occurring in narrow obstacle-free space, or obstacle configurations that are not in the training data set. Simulation results demonstrate the potential of diffusion models for reliable multi-agent formation planning.

</details>


### [67] [Bidirectional Human-Robot Communication for Physical Human-Robot Interaction](https://arxiv.org/abs/2601.10796)
*Junxiang Wang,Cindy Wang,Rana Soltani Zarrin,Zackory Erickson*

Main category: cs.RO

TL;DR: BRIDGE系统通过自然语言实现人机双向通信，允许用户实时修改机器人轨迹（位置、速度、力），并使用大语言模型解释指令，同时提供语音反馈，显著提升了交互性和透明度。


<details>
  <summary>Details</summary>
Motivation: 有效的物理人机交互不仅需要系统适应用户偏好，还需要其行为具有透明度。当前系统在实时双向通信和自然语言交互方面存在不足，特别是缺乏对机器人动作的透明解释和用户指令的即时反馈。

Method: BRIDGE系统利用大语言模型（LLM）在计划运动轨迹和对话历史的上下文中解释用户自然语言指令所隐含的轨迹修改（位置、速度、力）。系统提供双向反馈：要么确认修改结果，要么提出澄清问题。在三个辅助任务中对18名老年人进行了用户研究。

Result: 参与者成功使用系统实时修改轨迹。与无语音反馈的消融实验和基线相比，双向反馈显著提高了交互性和透明度的评分，证明机器人的语音响应对于更直观的用户体验至关重要。

Conclusion: BRIDGE系统通过自然语言实现双向人机通信，结合LLM解释和语音反馈，显著提升了物理辅助交互的直观性和透明度，为老年人等用户群体提供了更有效的交互体验。

Abstract: Effective physical human-robot interaction requires systems that are not only adaptable to user preferences but also transparent about their actions. This paper introduces BRIDGE, a system for bidirectional human-robot communication in physical assistance. Our method allows users to modify a robot's planned trajectory -- position, velocity, and force -- in real time using natural language. We utilize a large language model (LLM) to interpret any trajectory modifications implied by user commands in the context of the planned motion and conversation history. Importantly, our system provides verbal feedback in response to the user, either assuring any resulting changes or posing a clarifying question. We evaluated our method in a user study with 18 older adults across three assistive tasks, comparing BRIDGE to an ablation without verbal feedback and a baseline. Results show that participants successfully used the system to modify trajectories in real time. Moreover, the bidirectional feedback led to significantly higher ratings of interactivity and transparency, demonstrating that the robot's verbal response is critical for a more intuitive user experience. Videos and code can be found on our project website: https://bidir-comm.github.io/

</details>


### [68] [Approximately Optimal Global Planning for Contact-Rich SE(2) Manipulation on a Graph of Reachable Sets](https://arxiv.org/abs/2601.10827)
*Simin Liu,Tong Zhao,Bernhard Paus Graesdal,Peter Werner,Jiuguang Wang,John Dolan,Changliu Liu,Tao Pang*

Main category: cs.RO

TL;DR: 提出一种新的接触丰富操作规划范式，通过离线构建可达集图和在线规划，实现近似最优的全局优化操作，相比现有方法显著提升效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 当前基于模型的接触丰富操作规划器主要关注可行性而非最优性，限制了充分利用接触丰富操作优势的能力。人类操作中利用整个操作器表面接触物体比仅使用末端执行器更高效自然，需要开发能实现全局优化的规划方法。

Method: 采用两阶段方法：离线阶段构建互达集图，每个集合包含从起始物体姿态和抓握可达的所有物体朝向；在线阶段在该图上进行规划，通过计算和排序局部规划来实现全局优化的运动。

Result: 在具有挑战性的接触丰富任务中，该方法比领先规划器减少61%的任务成本，在250个查询中达到91%的成功率，并保持亚分钟级的查询时间。

Conclusion: 全局优化的接触丰富操作现已具备实际应用可行性，能够显著提升操作效率和成功率，为真实世界任务提供了实用解决方案。

Abstract: If we consider human manipulation, it is clear that contact-rich manipulation (CRM)-the ability to use any surface of the manipulator to make contact with objects-can be far more efficient and natural than relying solely on end-effectors (i.e., fingertips). However, state-of-the-art model-based planners for CRM are still focused on feasibility rather than optimality, limiting their ability to fully exploit CRM's advantages. We introduce a new paradigm that computes approximately optimal manipulator plans. This approach has two phases. Offline, we construct a graph of mutual reachable sets, where each set contains all object orientations reachable from a starting object orientation and grasp. Online, we plan over this graph, effectively computing and sequencing local plans for globally optimized motion. On a challenging, representative contact-rich task, our approach outperforms a leading planner, reducing task cost by 61%. It also achieves a 91% success rate across 250 queries and maintains sub-minute query times, ultimately demonstrating that globally optimized contact-rich manipulation is now practical for real-world tasks.

</details>


### [69] [Is open robotics innovation a threat to international peace and security?](https://arxiv.org/abs/2601.10877)
*Ludovic Righetti,Vincent Boulanin*

Main category: cs.RO

TL;DR: 论文提出机器人学领域需要制定专门的负责任研究指导原则和监管框架，以应对开源带来的双重用途风险，并提出了包含教育、风险评估激励、高风险材料传播管控和红线制定的四步路线图。


<details>
  <summary>Details</summary>
Motivation: 机器人学领域的开放获取（出版物、软件、硬件）虽然促进了科学进步和系统开发，但也加剧了双重用途风险，使得国家和非国家行为者更容易将机器人技术用于军事和有害目的。与其他存在双重用途风险的工程领域相比，机器人学缺乏专门的监管和负责任研究指导。

Method: 论文提出机器人学界应制定行业特定的指导原则和可能的监管框架，为此提出了包含四个实践步骤的路线图：1）负责任机器人教育；2）激励风险评估；3）管控高风险材料传播；4）制定红线标准。

Result: 论文提出了一个系统性的框架来应对机器人学领域的双重用途风险，强调需要行业自律和专门监管相结合，为机器人学界制定负责任研究实践提供了具体可行的路径。

Conclusion: 机器人学界需要主动制定行业特定的负责任研究指导原则和监管框架，通过教育、风险评估、材料管控和红线制定等措施，在保持开放科学传统的同时有效管理双重用途风险。

Abstract: Open access to publication, software and hardware is central to robotics: it lowers barriers to entry, supports reproducible science and accelerates reliable system development. However, openness also exacerbates the inherent dual-use risks associated with research and innovation in robotics. It lowers barriers for states and non-state actors to develop and deploy robotics systems for military use and harmful purposes. Compared to other fields of engineering where dual-use risks are present - e.g., those that underlie the development of weapons of mass destruction (chemical, biological, radiological, and nuclear weapons) and even the field of AI, robotics offers no specific regulation and little guidance as to how research and innovation may be conducted and disseminated responsibly. While other fields can be used for guidance, robotics has its own needs and specificities which have to be taken into account. The robotics community should therefore work toward its own set of sector-specific guidance and possibly regulation. To that end, we propose a roadmap focusing on four practices: a) education in responsible robotics; b) incentivizing risk assessment; c) moderating the diffusion of high-risk material; and d) developing red lines.

</details>


### [70] [Where to Touch, How to Contact: Hierarchical RL-MPC Framework for Geometry-Aware Long-Horizon Dexterous Manipulation](https://arxiv.org/abs/2601.10930)
*Zhixian Xie,Yu Xiang,Michael Posa,Wanxin Jin*

Main category: cs.RO

TL;DR: 提出分层RL-MPC框架解决灵巧操作问题：高层RL预测接触意图，底层接触隐式MPC优化接触模式，实现数据高效、鲁棒性强、零样本仿真到真实迁移


<details>
  <summary>Details</summary>
Motivation: 接触丰富的灵巧操作需要联合推理几何、运动学约束和复杂的非光滑接触动力学。端到端视觉运动策略需要大量数据、仿真到真实迁移差、跨任务/体现泛化弱。灵巧操作本质上是分层的：高层决定接触位置和物体运动，底层通过接触动力学实现计划。

Method: 提出分层RL-MPC框架：1) 高层RL策略预测接触意图（物体表面接触位置和接触后物体级子目标姿态）；2) 底层接触隐式模型预测控制（MPC）基于接触意图优化局部接触模式，通过接触动力学重新规划生成机器人动作，鲁棒地驱动物体朝向每个子目标。

Result: 在非抓取任务（几何泛化推动和物体3D重定向）上评估，实现接近100%成功率，数据需求大幅减少（比端到端基线少10倍），高度鲁棒性能，零样本仿真到真实迁移。

Conclusion: 通过将灵巧操作分解为高层几何/运动学规划和底层接触动力学优化，提出的分层RL-MPC框架解决了端到端方法的局限性，实现了数据高效、鲁棒性强、可迁移的灵巧操作。

Abstract: A key challenge in contact-rich dexterous manipulation is the need to jointly reason over geometry, kinematic constraints, and intricate, nonsmooth contact dynamics. End-to-end visuomotor policies bypass this structure, but often require large amounts of data, transfer poorly from simulation to reality, and generalize weakly across tasks/embodiments. We address those limitations by leveraging a simple insight: dexterous manipulation is inherently hierarchical - at a high level, a robot decides where to touch (geometry) and move the object (kinematics); at a low level it determines how to realize that plan through contact dynamics. Building on this insight, we propose a hierarchical RL--MPC framework in which a high-level reinforcement learning (RL) policy predicts a contact intention, a novel object-centric interface that specifies (i) an object-surface contact location and (ii) a post-contact object-level subgoal pose. Conditioned on this contact intention, a low-level contact-implicit model predictive control (MPC) optimizes local contact modes and replans with contact dynamics to generate robot actions that robustly drive the object toward each subgoal. We evaluate the framework on non-prehensile tasks, including geometry-generalized pushing and object 3D reorientation. It achieves near-100% success with substantially reduced data (10x less than end-to-end baselines), highly robust performance, and zero-shot sim-to-real transfer.

</details>


### [71] [Crane Lowering Guidance Using a Attachable Camera Module for Driver Vision Support](https://arxiv.org/abs/2601.11026)
*HyoJae Kang,SunWoo Ahn,InGyu Choi,GeonYeong Go,KunWoo Son,Min-Sung Kang*

Main category: cs.RO

TL;DR: 提出基于可附着摄像头模块的起重机吊装视觉引导系统，解决负载遮挡视线问题


<details>
  <summary>Details</summary>
Motivation: 起重机在吊装下降阶段，负载会遮挡操作员对落点的视线，传统依赖地面人员口头或手势指令的方式存在安全隐患

Method: 设计可附着摄像头模块（含单板计算机、电池和紧凑型摄像头），通过吸盘直接安装在负载上，实时采集和处理负载正下方地面图像，生成安装引导信息并传输至主机计算机

Result: 初步实验将模块附着在测试物体上，证实了实时图像采集和传输的可行性

Conclusion: 该系统有潜力通过为起重机操作员提供隐藏落点的即时视觉参考，显著提高施工现场安全性

Abstract: Cranes have long been essential equipment for lifting and placing heavy loads in construction projects. This study focuses on the lowering phase of crane operation, the stage in which the load is moved to the desired location. During this phase, a constant challenge exists: the load obstructs the operator's view of the landing point. As a result, operators traditionally have to rely on verbal or gestural instructions from ground personnel, which significantly impacts site safety. To alleviate this constraint, the proposed system incorporates a attachable camera module designed to be attached directly to the load via a suction cup. This module houses a single-board computer, battery, and compact camera. After installation, it streams and processes images of the ground directly below the load in real time to generate installation guidance. Simultaneously, this guidance is transmitted to and monitored by a host computer. Preliminary experiments were conducted by attaching this module to a test object, confirming the feasibility of real-time image acquisition and transmission. This approach has the potential to significantly improve safety on construction sites by providing crane operators with an instant visual reference of hidden landing zones.

</details>


### [72] [H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning](https://arxiv.org/abs/2601.11063)
*Haishan Zeng,Peng Li*

Main category: cs.RO

TL;DR: H-AIM是一个用于异构机器人团队执行长期任务的层次化自主智能多机器人规划框架，通过LLM解析指令生成PDDL问题描述，结合经典规划器优化动作序列，并编译为行为树进行反应式控制，显著提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 在具身人工智能中，异构机器人团队执行高级指令的长期任务仍面临挑战。大型语言模型在指令解析和初步规划方面有潜力，但在长期推理和动态多机器人协调方面存在局限，需要更有效的规划框架。

Method: 提出H-AIM框架，采用三级级联架构：1) 利用LLM解析指令并生成PDDL问题描述；2) 结合LLM语义推理和经典规划器搜索能力生成优化动作序列；3) 将规划结果编译为行为树进行反应式控制。通过共享黑板机制支持动态规模的异构机器人团队通信和状态同步。

Result: 在MACE-THOR基准数据集（包含8种不同家庭布局的42个复杂任务）上验证，H-AIM将任务成功率从12%提升至55%，目标条件召回率从32%提升至72%，相比最强基线LaMMA-P有显著改进。

Conclusion: H-AIM框架通过结合LLM的语义理解能力和经典规划器的搜索优化，有效解决了异构机器人团队长期任务规划问题，显著提升了任务执行性能，为具身AI中的多机器人协调提供了有效解决方案。

Abstract: In embodied artificial intelligence, enabling heterogeneous robot teams to execute long-horizon tasks from high-level instructions remains a critical challenge. While large language models (LLMs) show promise in instruction parsing and preliminary planning, they exhibit limitations in long-term reasoning and dynamic multi-robot coordination. We propose Hierarchical Autonomous Intelligent Multi-Robot Planning(H-AIM), a novel embodied multi-robot task planning framework that addresses these issues through a three-stage cascaded architecture: 1) It leverages an LLM to parse instructions and generate Planning Domain Definition Language (PDDL) problem descriptions, thereby transforming commands into formal planning problems; 2) It combines the semantic reasoning of LLMs with the search capabilities of a classical planner to produce optimized action sequences; 3) It compiles the resulting plan into behavior trees for reactive control. The framework supports dynamically sized heterogeneous robot teams via a shared blackboard mechanism for communication and state synchronization. To validate our approach, we introduce the MACE-THOR benchmark dataset, comprising 42 complex tasks across 8 distinct household layouts. Experimental results demonstrate that H-AIM achieves a remarkable performance improvement, elevating the task success rate from 12% to 55% and boosting the goal condition recall from 32% to 72% against the strongest baseline, LaMMA-P.

</details>


### [73] [A3D: Adaptive Affordance Assembly with Dual-Arm Manipulation](https://arxiv.org/abs/2601.11076)
*Jiaqi Liang,Yue Chen,Qize Yu,Yan Shen,Haipeng Zhang,Hao Dong,Ruihai Wu*

Main category: cs.RO

TL;DR: A3D框架通过学习自适应可供性来优化家具装配中的双臂协作，能够识别零件上的最佳支撑和稳定位置，并适应不同几何形状和装配状态


<details>
  <summary>Details</summary>
Motivation: 家具装配对机器人来说是关键但具有挑战性的任务，需要精确的双臂协调，其中一只手臂操作零件，另一只提供协作支撑和稳定。机器人需要在长时间装配过程中主动适应支撑策略，并泛化到不同的零件几何形状

Method: 提出A3D框架，学习自适应可供性来识别家具零件上的最佳支撑和稳定位置。方法采用密集点级几何表示来建模零件交互模式，实现跨不同几何形状的泛化。引入自适应模块，利用交互反馈在装配过程中基于先前交互动态调整支撑策略

Result: 建立了包含8种家具类型50个不同零件的仿真环境，用于双臂协作评估。实验表明，该框架在仿真和真实世界设置中都能有效泛化到不同的零件几何形状和家具类别

Conclusion: A3D框架通过自适应可供性学习和动态策略调整，有效解决了家具装配中双臂协作的挑战，实现了对多样化零件几何形状和装配状态的泛化能力

Abstract: Furniture assembly is a crucial yet challenging task for robots, requiring precise dual-arm coordination where one arm manipulates parts while the other provides collaborative support and stabilization. To accomplish this task more effectively, robots need to actively adapt support strategies throughout the long-horizon assembly process, while also generalizing across diverse part geometries. We propose A3D, a framework which learns adaptive affordances to identify optimal support and stabilization locations on furniture parts. The method employs dense point-level geometric representations to model part interaction patterns, enabling generalization across varied geometries. To handle evolving assembly states, we introduce an adaptive module that uses interaction feedback to dynamically adjust support strategies during assembly based on previous interactions. We establish a simulation environment featuring 50 diverse parts across 8 furniture types, designed for dual-arm collaboration evaluation. Experiments demonstrate that our framework generalizes effectively to diverse part geometries and furniture categories in both simulation and real-world settings.

</details>


### [74] [VLAgents: A Policy Server for Efficient VLA Inference](https://arxiv.org/abs/2601.11250)
*Tobias Jülg,Khaled Gamal,Nisarga Nilavadi,Pierre Krack,Seongjin Bien,Michael Krawez,Florian Walter,Wolfram Burgard*

Main category: cs.RO

TL;DR: VLAgents是一个模块化的策略服务器，通过统一的Gymnasium风格协议抽象视觉-语言-动作模型推理，支持零拷贝共享内存和压缩流式传输，在本地和远程通信基准测试中优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型在机器人领域发展迅速，但部署复杂，存在接口碎片化和分布式设置中的通信延迟问题，需要统一的解决方案。

Method: 提出VLAgents模块化策略服务器架构，采用统一的Gymnasium风格协议抽象VLA推理，通信层透明适配上下文，支持零拷贝共享内存（高速仿真）和压缩流式传输（远程硬件）。

Result: 成功集成7种策略（包括OpenVLA和Pi Zero），在本地和远程通信基准测试中，性能优于OpenVLA、OpenPi和LeRobot的默认策略服务器。

Conclusion: VLAgents通过统一的协议和自适应通信层有效解决了VLA模型部署的复杂性和延迟问题，为机器人控制提供了高效、灵活的解决方案。

Abstract: The rapid emergence of Vision-Language-Action models (VLAs) has a significant impact on robotics. However, their deployment remains complex due to the fragmented interfaces and the inherent communication latency in distributed setups. To address this, we introduce VLAgents, a modular policy server that abstracts VLA inferencing behind a unified Gymnasium-style protocol. Crucially, its communication layer transparently adapts to the context by supporting both zero-copy shared memory for high-speed simulation and compressed streaming for remote hardware. In this work, we present the architecture of VLAgents and validate it by integrating seven policies -- including OpenVLA and Pi Zero. In a benchmark with both local and remote communication, we further demonstrate how it outperforms the default policy servers provided by OpenVLA, OpenPi, and LeRobot. VLAgents is available at https://github.com/RobotControlStack/vlagents

</details>


### [75] [Distributed Control Barrier Functions for Safe Multi-Vehicle Navigation in Heterogeneous USV Fleets](https://arxiv.org/abs/2601.11335)
*Tyler Paine,Brendan Long,Jeremy Wenger,Michael DeFilippo,James Usevitch,Michael Benjamin*

Main category: cs.RO

TL;DR: 论文提出了一种用于异构无人船队碰撞避免的分布式安全控制滤波器方法，结合控制屏障函数理论和COLREGS规则，在模拟和真实实验中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 异构无人船队碰撞避免面临挑战：不同平台的决策过程和控制器存在差异，实时共享轨迹和控制值受限，需要处理包括有人驾驶船只在内的其他接触物的最坏情况行为。

Method: 为每个自主车辆添加控制滤波器，假设其他接触物（包括有人驾驶船只）采取最坏情况行为。使用控制屏障函数理论开发分布式安全控制滤波器，并与基于COLREGS规则的行为方法进行比较。

Result: 在模拟遭遇中比较了最坏情况CBF方法和COLREGS行为方法。使用三种不同无人船和有人驾驶船只进行真实世界实验，验证了该方法在不同平台上的有效性，并对人类操作员的不合作行为具有鲁棒性。

Conclusion: 结合CBF方法和COLREGS行为能够实现最佳的安全性和效率，为异构无人船队提供了一种实用且可解释的碰撞避免解决方案。

Abstract: Collision avoidance in heterogeneous fleets of uncrewed vessels is challenging because the decision-making processes and controllers often differ between platforms, and it is further complicated by the limitations on sharing trajectories and control values in real-time. This paper presents a pragmatic approach that addresses these issues by adding a control filter on each autonomous vehicle that assumes worst-case behavior from other contacts, including crewed vessels. This distributed safety control filter is developed using control barrier function (CBF) theory and the application is clearly described to ensure explainability of these safety-critical methods. This work compares the worst-case CBF approach with a Collision Regulations (COLREGS) behavior-based approach in simulated encounters. Real-world experiments with three different uncrewed vessels and a human operated vessel were performed to confirm the approach is effective across a range of platforms and is robust to uncooperative behavior from human operators. Results show that combining both CBF methods and COLREGS behaviors achieves the best safety and efficiency.

</details>


### [76] [ACoT-VLA: Action Chain-of-Thought for Vision-Language-Action Models](https://arxiv.org/abs/2601.11404)
*Linqing Zhong,Yi Liu,Yifei Wei,Ziyu Xiong,Maoqing Yao,Si Liu,Guanghui Ren*

Main category: cs.RO

TL;DR: 提出ACoT-VLA架构，将推理过程直接建模为动作空间中的结构化序列，通过显式和隐式动作推理器共同指导最终策略学习


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型通常依赖多模态输入直接转换为动作，或通过语言子任务预测、视觉目标图像合成等间接推理方式。但这些中间推理往往间接且难以传达精确动作执行所需的完整粒度信息。作者认为最有效的推理形式应该直接在动作空间中进行思考。

Method: 提出ACoT-VLA架构，包含两个互补组件：显式动作推理器（EAR）提出粗粒度参考轨迹作为显式动作级推理步骤；隐式动作推理器（IAR）从多模态输入的内部表示中提取潜在动作先验。两者共同形成动作思维链（ACoT），为下游动作头提供条件，实现接地气的策略学习。

Result: 在真实世界和仿真环境中进行广泛实验，在LIBERO上达到98.5%，LIBERO-Plus上达到84.1%，VLABench上达到47.4%的性能表现。

Conclusion: ACoT-VLA通过直接在动作空间中进行结构化推理，克服了传统间接推理方法的局限性，显著提升了机器人操作任务的性能，验证了动作思维链范式的有效性。

Abstract: Vision-Language-Action (VLA) models have emerged as essential generalist robot policies for diverse manipulation tasks, conventionally relying on directly translating multimodal inputs into actions via Vision-Language Model (VLM) embeddings. Recent advancements have introduced explicit intermediary reasoning, such as sub-task prediction (language) or goal image synthesis (vision), to guide action generation. However, these intermediate reasoning are often indirect and inherently limited in their capacity to convey the full, granular information required for precise action execution. Instead, we posit that the most effective form of reasoning is one that deliberates directly in the action space. We introduce Action Chain-of-Thought (ACoT), a paradigm where the reasoning process itself is formulated as a structured sequence of coarse action intents that guide the final policy. In this paper, we propose ACoT-VLA, a novel architecture that materializes the ACoT paradigm. Specifically, we introduce two complementary components: an Explicit Action Reasoner (EAR) and Implicit Action Reasoner (IAR). The former proposes coarse reference trajectories as explicit action-level reasoning steps, while the latter extracts latent action priors from internal representations of multimodal input, co-forming an ACoT that conditions the downstream action head to enable grounded policy learning. Extensive experiments in real-world and simulation environments demonstrate the superiority of our proposed method, which achieves 98.5%, 84.1%, and 47.4% on LIBERO, LIBERO-Plus and VLABench, respectively.

</details>


### [77] [The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents](https://arxiv.org/abs/2601.11421)
*Ziyu Wang,Chenyuan Liu,Yushun Xiang,Runhao Zhang,Qingbo Hao,Hongliang Lu,Houyu Chen,Zhizhong Feng,Kaiyue Zheng,Dehao Ye,Xianchao Zeng,Xinyu Zhou,Boran Wen,Jiaxin Li,Mingyu Zhang,Kecheng Zheng,Qian Zhu,Ran Cheng,Yong-Lu Li*

Main category: cs.RO

TL;DR: GM-100是首个机器人学习"奥林匹克"基准，包含100个精心设计的任务，涵盖广泛交互和长尾行为，旨在全面评估机器人智能体能力并促进任务设计多样性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人学习和模仿学习的数据集与任务设计缺乏系统性和原则性，无法准确反映不同方法在多样化任务上的性能差异，需要建立更全面、系统的评估基准。

Method: 通过系统分析现有任务设计，结合人-物交互基元和物体可供性理论，设计并扩展出100个多样化任务；在不同机器人平台上收集大量轨迹数据，并评估多个基线模型。

Result: 实验结果表明：1) GM-100任务具有可执行性；2) 任务具有足够挑战性，能够有效区分当前视觉语言动作(VLA)模型的性能差异。

Conclusion: GM-100作为机器人学习奥林匹克的第一步，提供了多样化且具有挑战性的任务集，能够全面评估机器人智能体能力，促进机器人数据集任务设计的多样性和复杂性发展。

Abstract: Recently, with the rapid development of robot learning and imitation learning, numerous datasets and methods have emerged. However, these datasets and their task designs often lack systematic consideration and principles. This raises important questions: Do the current datasets and task designs truly advance the capabilities of robotic agents? Do evaluations on a few common tasks accurately reflect the differentiated performance of various methods proposed by different teams and evaluated on different tasks? To address these issues, we introduce the Great March 100 (\textbf{GM-100}) as the first step towards a robot learning Olympics. GM-100 consists of 100 carefully designed tasks that cover a wide range of interactions and long-tail behaviors, aiming to provide a diverse and challenging set of tasks to comprehensively evaluate the capabilities of robotic agents and promote diversity and complexity in robot dataset task designs. These tasks are developed through systematic analysis and expansion of existing task designs, combined with insights from human-object interaction primitives and object affordances. We collect a large amount of trajectory data on different robotic platforms and evaluate several baseline models. Experimental results demonstrate that the GM-100 tasks are 1) feasible to execute and 2) sufficiently challenging to effectively differentiate the performance of current VLA models. Our data and code are available at https://rhos.ai/research/gm-100.

</details>
