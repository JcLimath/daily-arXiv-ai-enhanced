<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 10]
- [cs.RO](#cs.RO) [Total: 13]
- [cs.LG](#cs.LG) [Total: 37]
- [math.CV](#math.CV) [Total: 2]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 7]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)
*Hongjia Wu,Shuai Zhou,Hongxin Zhang,Wei Chen*

Main category: cs.AI

TL;DR: Doc2AHP：一个基于AHP原则的结构化推理框架，利用LLM的泛化能力与决策理论的严谨性相结合，无需标注数据即可从文档构建高质量决策模型


<details>
  <summary>Details</summary>
Motivation: LLMs在语义理解方面表现出色，但在需要严格逻辑的复杂决策任务中难以保证结构一致性和推理可靠性；传统决策理论（如AHP）依赖领域专家知识，存在"专家瓶颈"问题，限制了在通用场景下的可扩展性

Method: 提出Doc2AHP框架：1）利用AHP的结构原则作为约束，指导LLM在非结构化文档空间中进行受限搜索，强制父子节点间的逻辑蕴含关系；2）引入多智能体加权机制与自适应一致性优化策略，确保权重分配的数字一致性

Result: 实验结果表明，Doc2AHP不仅使非专家用户能够从零开始构建高质量决策模型，而且在逻辑完整性和下游任务准确性方面显著优于直接生成基线方法

Conclusion: Doc2AHP成功弥合了LLMs的泛化能力与决策理论严谨性之间的差距，提供了一种无需大量标注数据或人工干预的结构化推理框架，有效解决了专家瓶颈问题

Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.

</details>


### [2] [SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care](https://arxiv.org/abs/2601.16529)
*Dongshen Peng,Yi Wang,Carl Preiksaitis,Christian Rose*

Main category: cs.AI

TL;DR: SycoEval-EM框架通过多智能体模拟评估LLM在急诊医学中面对患者不当请求时的抗压能力，发现模型顺从率差异巨大且能力与稳健性不相关。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在临床决策支持中展现潜力，但存在因患者压力而同意不当医疗请求的风险，需要评估其在对抗性社会压力下的稳健性。

Method: 引入SycoEval-EM多智能体模拟框架，在三个Choosing Wisely场景中，通过对抗性患者说服策略测试20个LLM在1,875次医疗接触中的表现。

Result: 模型顺从率从0%到100%不等，对影像检查请求的脆弱性（38.8%）高于阿片类药物处方（25.0%），模型能力与稳健性相关性差，所有说服策略效果相似（30.0-36.0%）。

Conclusion: 静态基准测试无法充分预测临床AI在社交压力下的安全性，需要多轮对抗性测试作为临床AI认证的必要组成部分。

Abstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.

</details>


### [3] [LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification](https://arxiv.org/abs/2601.16549)
*Meet Raval,Tejul Pandit,Dhvani Upadhyay*

Main category: cs.AI

TL;DR: 传统机器学习模型在医学分类任务中表现最佳，LoRA微调的Gemma变体表现最差，而零样本LLM/VLM在图像任务中表现有竞争力。


<details>
  <summary>Details</summary>
Motivation: 评估多模态视觉语言模型（VLMs）和大语言模型（LLMs）在医学分类任务中的实际效果，与传统机器学习方法进行系统对比，为医学AI应用提供实证依据。

Method: 使用四个公开可用的文本和图像数据集（涵盖二元和多元分类复杂度），对比三类模型：传统机器学习（LR、LightGBM、ResNet-50）、基于提示的LLMs/VLMs（Gemini 2.5）和微调的PEFT模型（LoRA适配的Gemma3变体）。所有实验采用一致的数据划分和评估指标。

Result: 传统机器学习模型在大多数医学分类任务中表现最佳，尤其在结构化文本数据集上表现优异。LoRA微调的Gemma变体在所有文本和图像实验中表现最差，无法从最小微调中泛化。零样本LLM/VLM管道（Gemini 2.5）在文本任务上表现不佳，但在多元图像分类任务中表现出竞争力，与传统ResNet-50基线相当。

Conclusion: 在许多医学分类场景中，成熟的机器学习模型仍然是最可靠的选择。基础模型并非普遍优越，参数高效微调（PEFT）的效果高度依赖于适应策略，本研究中的最小微调证明是有害的。

Abstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.

</details>


### [4] [LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents](https://arxiv.org/abs/2601.16649)
*Amin Rakhsha,Thomas Hehn,Pietro Mazzaglia,Fabio Valerio Massoli,Arash Behboodi,Tribhuvanesh Orekondy*

Main category: cs.AI

TL;DR: 该研究通过开发一个oracle反事实框架，在程序生成的游戏式任务中评估不同AI能力（如规划、状态跟踪）对多轮次、长视野智能体任务的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在孤立任务上表现良好，但在需要规划、状态跟踪和长上下文处理等多轮次、长视野智能体问题上仍然存在困难。研究旨在更好地理解这些底层能力对于此类任务成功的重要性。

Method: 开发了一个oracle反事实框架，通过程序生成具有可调复杂度的游戏式任务套件。在这些受控环境中提供精确的oracle干预（如完美规划或无错误状态跟踪），从而隔离每个oracle的贡献而不受现实基准中混杂效应的影响。

Result: 结果显示，某些干预（如规划）在各种设置中持续提升性能，而其他技能的有用性则取决于环境和语言模型的特性。不同能力的重要性在不同情境下存在差异。

Conclusion: 该研究揭示了多轮次智能体环境中的挑战，为未来AI智能体和语言模型的发展提供了指导。通过受控实验环境，能够更精确地评估不同能力对智能体性能的关键性。

Abstract: Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models.

</details>


### [5] [AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning](https://arxiv.org/abs/2601.16685)
*Suzhong Fu,Jingqi Dong,Xuan Ding,Rui Sun,Yiming Yang,Shuguang Cui,Zhen Li*

Main category: cs.AI

TL;DR: 提出AgentsEval多智能体流推理框架，用于评估医学影像报告生成的临床正确性和推理保真度，通过模拟放射科医生协作诊断流程提供结构化评估。


<details>
  <summary>Details</summary>
Motivation: 现有医学影像报告生成评估方法无法捕捉放射学解释背后的结构化诊断逻辑，导致评估不可靠且临床相关性有限，需要更透明和临床基础的评估框架。

Method: AgentsEval多智能体流推理框架，将评估过程分为可解释步骤：标准定义、证据提取、对齐和一致性评分，模拟放射科医生协作诊断工作流程，提供明确推理轨迹和结构化临床反馈。

Result: 实验结果表明AgentsEval提供临床对齐、语义忠实且可解释的评估，在释义、语义和风格扰动下保持稳健，构建了覆盖五个医学报告数据集的多领域扰动基准。

Conclusion: 该框架代表了向医学报告生成系统透明和临床基础评估迈出的一步，促进大语言模型在临床实践中的可信集成。

Abstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.

</details>


### [6] [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chen Gao,Chen Zhang,Chengcheng Han,Chenhui Yang,Chuyu Zhang,Cong Chen,Cunguang Wang,Daoru Pan,Defei Bu,Dengchang Zhao,Di Xiu,Dishan Liu,Dongyu Ru,Dunwei Tu,Fan Wu,Fengcheng Yuan,Fengcun Li,Gang Xu,Guanyu Wu,Guoyuan Lin,Haibin Wang,Hansi Yang,Hao Yang,Haonan Yan,Haoxiang Ma,Haoxing Wen,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiacheng Zhang,Jiahong Zhou,Jiahuan Li,Jiaming Wang,Jian Yang,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiapeng Zhu,Jiaqi Sun,Jiarong Shi,Jiarui Zhao,Jingang Wang,Jinluan Yang,Jinrui Ding,Jinwei Xiao,Jiyuan He,Juncan Xu,Kefeng Zhang,Keheng Wang,Li Wei,Lianhui Ma,Lin Qiu,Lingbing Kong,Lingchuan Liu,Linsen Guo,Mengshen Zhu,Mengxia Shen,Mingyang Zhu,Peiguang Li,Peng Pei,Pengcheng Jia,Pengtao Zhang,Peng Zhao,Qi Gu,Qiong Huang,Qiyuan Duan,Quanchi Weng,Rongxiang Weng,Rongzhi Zhang,Rumei Li,Shanglin Lei,Shengnan An,Shijun Dai,Shuaikang Liu,Shuang Zhou,Shuo Wang,Songyuan Zhao,Tao Liang,Tianhao Hu,Tianze Chen,Wei Liu,Wei Shi,Wei Wang,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Wentao Chen,Wentao Shi,Xi Su,Xiangcheng Liu,Xiandi Ma,Xiangyu Xi,Xiangyuan Liu,Xiangzhou Huang,Xiao Liu,Xiaodong Cai,Xiaolong Chen,Xiaowei Shi,Xiaoyu Li,Xin Chen,Xingchen Liu,Xuan Huang,Xuezhi Cao,Xunliang Cai,Yan Chen,Yang Bai,Yang Liu,Yang Yang,Yang Zheng,Yaoming Wang,Yaoming Zhu,Yaqi Huo,Yanyu Chen,Yaorui Shi,Yerui Sun,Yi Zhang,Yihao Chen,Yi-Kai Zhang,Yifan Lu,Yifan Zhao,Yitao Zhai,Yongjing Yin,Yongwei Zhou,Youshao Xiao,Yuchuan Dai,Yuchen Xie,Yuchen Yu,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunfan Liang,Yunke Zhao,Yuwei Jiang,Yuxin Bian,Yuxin Chen,Yuxin Liu,Yue Xu,Yueqing Sun,Zeyang Yu,Zhao Yang,Zhengsheng Huang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhimin Lin,Zhiyuan Yao,Zhuofan Chen,Zhuowen Han,Zijian Zhang,Ziran Li,Ziwen Wang,Ziyuan Zhuang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking-2601是一个5600亿参数的开源MoE推理模型，在多种智能体基准测试中达到SOTA，具备强大的工具使用泛化能力和噪声环境鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发一个具备卓越智能体推理能力的开源模型，能够处理复杂工具交互、多轮智能体交互，并在噪声现实环境中保持鲁棒性，以解决现有模型在真实世界应用中的局限性。

Method: 采用统一的训练框架，结合领域并行专家训练与后续融合；系统扩展异步强化学习框架DORA用于大规模多环境训练；分析现实噪声模式并设计针对性训练程序；引入Heavy Thinking模式进行测试时扩展。

Result: 在智能体搜索、智能体工具使用和工具集成推理等基准测试中达到开源模型的最先进性能；在复杂工具交互中表现出强大的泛化能力；在噪声现实环境中保持鲁棒行为。

Conclusion: LongCat-Flash-Thinking-2601通过创新的训练框架、环境扩展、噪声鲁棒性设计和测试时扩展技术，实现了卓越的智能体推理能力，为现实世界应用提供了强大的开源解决方案。

Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.

</details>


### [7] [An Efficient Insect-inspired Approach for Visual Point-goal Navigation](https://arxiv.org/abs/2601.16806)
*Lu Yihe,Barbara Webb*

Main category: cs.AI

TL;DR: 提出一种受昆虫启发的视觉点目标导航智能体，结合昆虫大脑的联想学习和路径整合机制，在Habitat点目标导航任务中达到与SOTA模型相当的性能，但计算成本低数个数量级。


<details>
  <summary>Details</summary>
Motivation: 受昆虫在发现食物位置与巢穴之间学习并优化视觉引导路径能力的启发，开发计算效率高的视觉点目标导航智能体。昆虫能够在复杂环境中高效导航，这为开发低计算成本的导航算法提供了生物灵感。

Method: 结合两种昆虫大脑结构的抽象模型：一种负责联想学习，另一种负责路径整合。将Habitat点目标导航任务形式化基准与昆虫的视觉路径学习能力进行类比，构建简单的昆虫启发智能体。

Result: 昆虫启发智能体在Habitat点目标导航任务中表现出与近期SOTA模型相当的性能，但计算成本低数个数量级。在更真实的模拟环境中测试表明，该方法对扰动具有鲁棒性。

Conclusion: 简单的昆虫启发智能体能够实现高效的点目标导航，证明了生物启发方法在降低计算成本方面的潜力，为开发更实用的机器人导航系统提供了新思路。

Abstract: In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations.

</details>


### [8] [Reasoning Promotes Robustness in Theory of Mind Tasks](https://arxiv.org/abs/2601.16853)
*Ian B. de Haan,Peter van der Putten,Max van Duijn*

Main category: cs.AI

TL;DR: 该论文研究了通过强化学习与可验证奖励训练的推理型大语言模型在心理理论任务中的表现，发现这些模型对提示变化和任务扰动具有更强的鲁棒性，但这种提升主要源于寻找正确解决方案的鲁棒性增强，而非新的心理理论推理形式。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在心理理论测试中表现出色引发了对其底层能力性质的争议，同时通过强化学习与可验证奖励训练的推理型模型在多个基准测试中取得了显著改进。本研究旨在探究这类推理模型在心理理论任务中的行为表现。

Method: 采用新颖的机器心理学实验改编方法和已建立的基准测试结果，分析推理型大语言模型在心理理论任务中的表现。通过比较模型对提示变化和任务扰动的鲁棒性来评估其能力。

Result: 推理模型在心理理论任务中表现出对提示变化和任务扰动的一致增强鲁棒性。分析表明，观察到的性能提升更可能归因于寻找正确解决方案的鲁棒性增加，而不是形成了新的心理理论推理形式。

Conclusion: 评估大语言模型的社会认知行为时，需要区分真正的心理理论推理能力和通过增强鲁棒性实现的表面性能提升。研究结果对如何准确评估语言模型的社会认知能力具有重要意义。

Abstract: Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.

</details>


### [9] [MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion](https://arxiv.org/abs/2601.16886)
*Chi Yu,Hongyu Yuan,Zhiyi Duan*

Main category: cs.AI

TL;DR: MAGE-KT：基于多智能体图增强的知识追踪框架，通过多视图异构图构建和紧凑子图检索解决现有图KT方法中概念关系挖掘不足和全图编码计算成本高、噪声多的问题


<details>
  <summary>Details</summary>
Motivation: 现有基于图的知识追踪方法存在两个主要问题：1) 对概念间关系挖掘不足，通常仅从交互序列推断；2) 全图编码计算成本高且易受噪声影响，导致注意力扩散到与学生无关的区域，降低概念间关系保真度

Method: 提出MAGE-KT框架：1) 构建多视图异构图，结合多智能体概念关系提取器和学生-问题交互图，捕捉互补的语义和行为信号；2) 基于目标学生历史检索紧凑高价值子图；3) 使用非对称交叉注意力融合模块集成子图信息，避免注意力扩散和不相关计算

Result: 在三个广泛使用的KT数据集上的实验表明，该方法在概念关系准确性和下一问题预测方面相比现有方法有显著提升

Conclusion: MAGE-KT通过多视图异构图构建和条件化子图检索，有效解决了图KT中的概念关系挖掘不足和计算效率问题，为知识追踪提供了更精确和高效的方法

Abstract: Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods.

</details>


### [10] [Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians](https://arxiv.org/abs/2601.16967)
*Bernes Lorier Atabonfack,Ahmed Tahiru Issah,Mohammed Hardi Abdul Baaki,Clemence Ingabire,Tolulope Olusuyi,Maruf Adewole,Udunna C. Anazodo,Timothy X Brown*

Main category: cs.AI

TL;DR: 开发AI支持平台辅助中低收入国家医疗设备维护，通过LLM提供实时故障诊断和维修指导，减少设备停机时间


<details>
  <summary>Details</summary>
Motivation: 中低收入国家医疗诊断设备因缺乏及时维护、技术专家支持不足而利用率低，导致设备停机时间长、诊断延迟和患者护理质量下降

Method: 开发集成大型语言模型的AI支持平台，包含用户友好的Web界面，允许技术人员输入错误代码或症状获取逐步故障排除指导，并建立全球同行讨论论坛；使用Philips HDI 5000超声设备进行概念验证

Result: 概念验证在错误代码解释方面达到100%精确度，在建议纠正措施方面达到80%准确率，证明了AI驱动系统支持医疗设备维护的可行性

Conclusion: AI驱动系统有潜力支持医疗设备维护，减少资源受限环境中的设备停机时间，改善医疗服务提供

Abstract: In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [11] [Scalable Screw-Theoretic Synthesis for PDE-Based Dynamic Modeling of Multibody Flexible Manipulators](https://arxiv.org/abs/2601.16242)
*S. Yaqubi,J. Mattila*

Main category: cs.RO

TL;DR: 提出一种基于旋量理论的PDE多体合成框架，用于三维空间中任意数量柔性连杆串联机械臂的动力学建模，具有无限可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有柔性机械臂动力学建模方法在可扩展性、数学严谨性和计算可行性方面存在局限，需要一种系统化的框架来处理任意数量柔性连杆的复杂动力学问题。

Method: 采用旋量理论系统构建单个柔性连杆的PDE模型，通过相互作用力严格实施完整关节约束；使用三组体固定坐标系中的对偶旋量描述动力学；应用变分原理推导统一动力学方程；将模型表述为半显式指数-1微分代数系统和抽象柯西问题。

Result: 建立了无限可扩展的多体表示，能够同时捕获局部（子系统级）和全局（系统级）动力学；显式恢复所有动态状态；证明了所得系统的适定性。

Conclusion: 该框架为柔性机械臂动力学建模提供了数学严谨、计算可行且无限可扩展的解决方案，为复杂柔性多体系统的分析和控制奠定了基础。

Abstract: This paper presents a novel and scalable screw-theoretic multibody synthesis framework for PDE-based dynamic modeling of serial robotic manipulators with an arbitrary number of flexible links in three-dimensional space. The proposed approach systematically constructs screw-theoretic PDE models for individual flexible links and rigorously enforces holonomic joint constraints through interaction forces. The dynamics of each link are formulated using a set of dual screws expressed in body-fixed coordinates: one describing the motion of the body-fixed frame relative to the inertial frame, a second relating the body-fixed frame to the undeformed configuration, and a third capturing elastic deformations. By expressing the system energy and applying variational principles, the governing dynamics of each link had been previously derived in a unified manner. Synthesizing the individual link models yields an infinitely scalable multibody representation capable of capturing both local (subsystem-level) and global (system-level) dynamics. The framework explicitly recovers all dynamic states, including the motion of each body-fixed frame and the distributed deformation fields of the flexible links. For computational tractability and mathematical rigor, the resulting governing equations are formulated as a semi-explicit index-1 differential-algebraic system. Furthermore, by applying separation of variables, the PDE model is recast as an abstract Cauchy problem, and well-posedness of the resulting system is established.

</details>


### [12] [DMV-AVP: Distributed Multi-Vehicle Autonomous Valet Parking using Autoware](https://arxiv.org/abs/2601.16327)
*Zubair Islam,Mohamed El-Darieby*

Main category: cs.RO

TL;DR: 本文提出了DMV-AVP系统，一种分布式多车辆自主代客泊车仿真系统，基于分布式多车辆架构实现同步多主机执行，解决了现有集中式仿真的可扩展性限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有自主代客泊车仿真大多采用集中式或非分布式设计，限制了系统的可扩展性和完全自主控制能力，需要一种分布式架构来支持多车辆协同泊车仿真。

Method: 基于分布式多车辆架构开发了两个核心模块：1) 多车辆AVP节点，负责状态协调、排队和预约管理；2) Unity集成的YOLOv5停车位检测模块，在AWSIM Labs中提供实时视觉感知。系统采用Zenoh通信层确保低延迟主题同步和跨主机协调行为。

Result: 在双主机和三主机配置上的实验表明，系统实现了确定性协调、无冲突泊车行为，并在分布式Autoware实例间展现出可扩展性能。系统支持协同AVP仿真，为未来真实世界和硬件在环验证奠定了基础。

Conclusion: 提出的分布式多车辆AVP系统成功解决了集中式仿真的可扩展性限制，通过分布式架构实现了多车辆协同泊车，为实际应用和硬件验证提供了可靠基础。

Abstract: This paper presents the DMV-AVP System, a distributed simulation of Multi-Vehicle Autonomous Valet Parking (AVP). The system was implemented as an application of the Distributed Multi-Vehicle Architecture (DMAVA) for synchronized multi-host execution. Most existing simulation approaches rely on centralized or non-distributed designs that constrain scalability and limit fully autonomous control. This work introduces two modules built on top of the DMAVA: 1) a Multi-Vehicle AVP Node that performs state-based coordination, queuing, and reservation management across multiple vehicles, and 2) a Unity-Integrated YOLOv5 Parking Spot Detection Module that provides real-time, vision-based perception within AWSIM Labs. Both modules integrate seamlessly with the DMAVA and extend it specifically for multi-vehicle AVP operation, supported by a Zenoh-based communication layer that ensures low-latency topic synchronization and coordinated behavior across hosts. Experiments conducted on two- and three-host configurations demonstrate deterministic coordination, conflict-free parking behavior, and scalable performance across distributed Autoware instances. The results confirm that the proposed Distributed Multi-Vehicle AVP System supports cooperative AVP simulation and establishes a foundation for future real-world and hardware-in-the-loop validation. Demo videos and source code are available at https://github.com/zubxxr/multi-vehicle-avp

</details>


### [13] [DMAVA: Distributed Multi-Autonomous Vehicle Architecture Using Autoware](https://arxiv.org/abs/2601.16336)
*Zubair Islam,Mohamed El-Darieby*

Main category: cs.RO

TL;DR: 提出分布式多自动驾驶车辆架构DMAVA，支持多物理主机间的实时同步仿真，每辆车独立运行完整AV栈，通过低延迟通信层实现协调，基于ROS 2、Autoware、AWSIM和Zenoh构建


<details>
  <summary>Details</summary>
Motivation: 现有仿真架构大多局限于单车辆操作或依赖集中式控制，难以有效模拟和验证多自动驾驶车辆间的协调，需要分布式实时同步仿真解决方案

Method: 设计分布式多自动驾驶车辆架构DMAVA，每辆车在独立物理主机上运行完整Autoware栈，通过Zenoh低延迟数据通信层实现同步，集成ROS 2 Humble、Autoware Universe、AWSIM Labs和Unity环境

Result: 多主机配置实验显示稳定的定位、可靠的主机间通信和完全同步的闭环控制，架构支持多车辆自主代客泊车等高级协同自主功能

Conclusion: DMAVA成功实现了分布式多自动驾驶车辆的实时同步仿真，为多车协同自主系统提供了可扩展的基础平台，支持更复杂的高级协同自主应用开发

Abstract: Simulating and validating coordination among multiple autonomous vehicles (AVs) is a challenging task as most existing simulation architectures are limited to single-vehicle operation or rely on centralized control. This paper presents a Distributed Multi-AV Architecture (DMAVA) that enables synchronized, real-time autonomous driving simulation across multiple physical hosts. Each vehicle runs its own complete AV stack and operates independently from other AVs. The vehicles in the simulation maintain synchronized coordination through a low-latency data-centric communication layer. The proposed system integrates ROS 2 Humble, Autoware Universe, AWSIM Labs, and Zenoh to support concurrent execution of multiple Autoware stacks within a shared Unity-based environment. Experiments conducted on multiple-host configurations demonstrate stable localization, reliable inter-host communication, and fully synchronized closed-loop control. The DMAVA also serves as a foundation for Multi-Vehicle Autonomous Valet Parking, demonstrating its extensibility toward higher-level cooperative autonomy. Demo videos and source code are available at: https://github.com/zubxxr/distributed-multi-autonomous-vehicle-architecture.

</details>


### [14] [GNSS-based Lunar Orbit and Clock Estimation With Stochastic Cloning UD Filter](https://arxiv.org/abs/2601.16393)
*Keidai Iiyama,Grace Gao*

Main category: cs.RO

TL;DR: 提出一种基于地面GNSS的月球导航卫星轨道与钟差估计框架，采用随机克隆UD分解滤波器和延迟状态平滑器处理TDCP测量，实现米级轨道精度和亚毫米/秒速度精度。


<details>
  <summary>Details</summary>
Motivation: 为满足未来月球增强导航服务(LANS)的严格空间信号误差要求，需要解决月球距离下低可观测性条件下的高精度轨道与钟差估计问题。

Method: 开发随机克隆UD分解滤波器和延迟状态平滑器处理时间差分载波相位(TDCP)测量；建立综合动力学与测量模型，考虑相对论轨道-钟态耦合、月球时标变换、电离层/等离子层/夏皮罗效应等传播延迟。

Result: 通过高保真蒙特卡洛仿真验证，结合无电离层伪距和TDCP测量可实现米级轨道精度和亚毫米/秒速度精度，满足LANS信号空间误差要求。

Conclusion: 所提框架能有效解决月球距离下的低可观测性问题，为未来月球导航服务提供高精度轨道与钟差估计解决方案。

Abstract: This paper presents a terrestrial GNSS-based orbit and clock estimation framework for lunar navigation satellites. To enable high-precision estimation under the low-observability conditions encountered at lunar distances, we develop a stochastic-cloning UD-factorized filter and delayed-state smoother that provide enhanced numerical stability when processing precise time-differenced carrier phase (TDCP) measurements. A comprehensive dynamics and measurement model is formulated, explicitly accounting for relativistic coupling between orbital and clock states, lunar time-scale transformations, and signal propagation delays including ionospheric, plasmaspheric, and Shapiro effects. The proposed approach is evaluated using high-fidelity Monte-Carlo simulations incorporating realistic multi-constellation GNSS geometry, broadcast ephemeris errors, lunar satellite dynamics, and ionospheric and plasmaspheric delay computed from empirical electron density models. Simulation results demonstrate that combining ionosphere-free pseudorange and TDCP measurements achieves meter-level orbit accuracy and sub-millimeter-per-second velocity accuracy, satisfying the stringent signal-in-space error requirements of future Lunar Augmented Navigation Services (LANS).

</details>


### [15] [RENEW: Risk- and Energy-Aware Navigation in Dynamic Waterways](https://arxiv.org/abs/2601.16424)
*Mingi Jeong,Alberto Quattrini Li*

Main category: cs.RO

TL;DR: RENEW是一个用于自主水面航行器(ASV)的全局路径规划器，在动态环境和外部干扰(如水流)下，通过统一的风险和能量感知策略确保安全，采用分层架构结合约束三角剖分和轨迹优化。


<details>
  <summary>Details</summary>
Motivation: 自主水面航行器在动态海洋环境中面临外部干扰(如水流)的挑战，需要确保安全的同时考虑能量效率。现有方法缺乏对自适应不可航行区域识别和拓扑路径多样性的联合处理。

Method: 采用分层架构：高层使用约束三角剖分生成拓扑多样的路径，低层在安全走廊内进行轨迹优化。引入统一的风险和能量感知策略，动态识别不可航行区域并强制执行自适应安全约束。受海事应急规划启发，采用尽力而为策略在不利条件下保持控制。

Result: 使用真实海洋数据验证，RENEW是首个同时解决自适应不可航行性和拓扑路径多样性问题的框架，能够在动态环境中实现鲁棒的海事导航。

Conclusion: RENEW为自主水面航行器在动态环境中的全局路径规划提供了一个有效的解决方案，通过统一的风险和能量感知策略确保安全，同时考虑拓扑多样性以增强鲁棒性。

Abstract: We present RENEW, a global path planner for Autonomous Surface Vehicle (ASV) in dynamic environments with external disturbances (e.g., water currents). RENEW introduces a unified risk- and energy-aware strategy that ensures safety by dynamically identifying non-navigable regions and enforcing adaptive safety constraints. Inspired by maritime contingency planning, it employs a best-effort strategy to maintain control under adverse conditions. The hierarchical architecture combines high-level constrained triangulation for topological diversity with low-level trajectory optimization within safe corridors. Validated with real-world ocean data, RENEW is the first framework to jointly address adaptive non-navigability and topological path diversity for robust maritime navigation.

</details>


### [16] [Zero-Shot MARL Benchmark in the Cyber-Physical Mobility Lab](https://arxiv.org/abs/2601.16578)
*Julius Beerwerth,Jianye Xu,Simon Schäfer,Fynn Belderink,Bassam Alrifaee*

Main category: cs.RO

TL;DR: 提出一个用于评估多智能体强化学习在网联自动驾驶车辆中仿真到真实迁移的可复现基准平台，基于Cyber-Physical Mobility Lab，集成仿真、高保真数字孪生和物理测试床，支持零样本评估。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统评估多智能体强化学习在网联自动驾驶车辆中仿真到真实迁移的可复现基准，需要结构化平台来分析仿真到真实的性能退化来源。

Method: 基于Cyber-Physical Mobility Lab构建集成平台，包含仿真环境、高保真数字孪生和物理测试床三个层次，采用SigmaRL训练的多智能体强化学习策略进行零样本部署评估。

Result: 部署SigmaRL训练的策略揭示了两种互补的性能退化来源：仿真与硬件控制栈之间的架构差异，以及环境真实性增加导致的仿真到真实差距。

Conclusion: 该开源平台为在多智能体强化学习中系统分析仿真到真实挑战提供了现实且可复现的条件，有助于理解性能退化的根本原因并改进仿真到真实迁移方法。

Abstract: We present a reproducible benchmark for evaluating sim-to-real transfer of Multi-Agent Reinforcement Learning (MARL) policies for Connected and Automated Vehicles (CAVs). The platform, based on the Cyber-Physical Mobility Lab (CPM Lab) [1], integrates simulation, a high-fidelity digital twin, and a physical testbed, enabling structured zero-shot evaluation of MARL motion-planning policies. We demonstrate its use by deploying a SigmaRL-trained policy [2] across all three domains, revealing two complementary sources of performance degradation: architectural differences between simulation and hardware control stacks, and the sim-to-real gap induced by increasing environmental realism. The open-source setup enables systematic analysis of sim-to-real challenges in MARL under realistic, reproducible conditions.

</details>


### [17] [A Unified Calibration Framework for High-Accuracy Articulated Robot Kinematics](https://arxiv.org/abs/2601.16638)
*Philip Tobuschat,Simon Duenser,Markus Bambach,Ivo Aschwanden*

Main category: cs.RO

TL;DR: 提出了一种统一的工业机器人静态标定方法，通过单个简单实验同时识别几何和非几何误差源，显著提高了定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有工业机器人工具定位误差补偿方法通常需要针对不同误差源进行单独的专业实验、模型和识别程序，过程复杂且效率低下。

Method: 采用统一标定方法，通过虚拟关节扩展运动学链来建模几何和非几何效应（柔性弯曲、热变形、齿轮传动误差），使用带解析梯度的Gauss-Newton优化进行参数识别，仅需单个简单实验收集数据。

Result: 在KUKA KR30工业机器人上，该方法将平均位置误差从纯几何标定的102.3μm降低到26.8μm，Fisher信息谱显示估计条件良好且参数化接近最小，系统时间交叉验证和模型消融实验证明了模型识别的鲁棒性。

Conclusion: 该方法提供了一种高效、统一的工业机器人标定解决方案，通过单个实验同时识别多种误差源，显著提高了定位精度和标定过程的实用性。

Abstract: Researchers have identified various sources of tool positioning errors for articulated industrial robots and have proposed dedicated compensation strategies. However, these typically require individual, specialized experiments with separate models and identification procedures. This article presents a unified approach to the static calibration of industrial robots that identifies a robot model, including geometric and non-geometric effects (compliant bending, thermal deformation, gear transmission errors), using only a single, straightforward experiment for data collection. The model augments the kinematic chain with virtual joints for each modeled effect and realizes the identification using Gauss-Newton optimization with analytic gradients. Fisher information spectra show that the estimation is well-conditioned and the parameterization near-minimal, whereas systematic temporal cross-validation and model ablations demonstrate robustness of the model identification. The resulting model is very accurate and its identification robust, achieving a mean position error of 26.8 $μm$ on a KUKA KR30 industrial robot compared to 102.3 $μm$ for purely geometric calibration.

</details>


### [18] [ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance](https://arxiv.org/abs/2601.16667)
*Zhuohao Li,Yinghao Li,Jian-Jian Jiang,Lang Zhou,Tianyu Zhang,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: ReViP提出了一种新的视觉-语言-动作模型框架，通过视觉-本体感知再平衡机制解决模态不平衡问题，减少状态主导偏差和虚假完成任务完成，提升视觉基础能力和抗干扰鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型将本体感知信号直接与VLM编码的视觉-语言特征融合，导致状态主导偏差和虚假完成任务完成（即使执行失败也预测成功）。这源于模态不平衡问题：策略过度依赖内部状态而未能充分利用视觉证据。

Method: 提出ReViP框架，核心是引入辅助任务感知环境先验来自适应调节语义感知与本体感知动态的耦合。使用外部VLM作为任务阶段观察器，从视觉观察中提取实时任务中心视觉线索，驱动视觉-本体感知特征线性调制，增强环境感知并减少状态驱动错误。同时构建首个虚假完成任务完成基准测试套件。

Result: 在LIBERO、RoboTwin 2.0和真实世界评估中，ReViP有效降低了虚假完成任务完成率，提高了成功率，优于现有VLA基线模型。

Conclusion: ReViP通过视觉-本体感知再平衡机制解决了VLA模型中的模态不平衡问题，增强了视觉基础能力和鲁棒性，为机器人操作任务提供了更可靠的解决方案。

Abstract: Vision-Language-Action (VLA) models have advanced robotic manipulation by combining vision, language, and proprioception to predict actions. However, previous methods fuse proprioceptive signals directly with VLM-encoded vision-language features, resulting in state-dominant bias and false completions despite visible execution failures. We attribute this to modality imbalance, where policies over-rely on internal state while underusing visual evidence. To address this, we present ReViP, a novel VLA framework with Vision-Proprioception Rebalance to enhance visual grounding and robustness under perturbations. The key insight is to introduce auxiliary task-aware environment priors to adaptively modulate the coupling between semantic perception and proprioceptive dynamics. Specifically, we use an external VLM as a task-stage observer to extract real-time task-centric visual cues from visual observations, which drive a Vision-Proprioception Feature-wise Linear Modulation to enhance environmental awareness and reduce state-driven errors. Moreover, to evaluate false completion, we propose the first False-Completion Benchmark Suite built on LIBERO with controlled settings such as Object-Drop. Extensive experiments show that ReViP effectively reduces false-completion rates and improves success rates over strong VLA baselines on our suite, with gains extending to LIBERO, RoboTwin 2.0, and real-world evaluations.

</details>


### [19] [Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation](https://arxiv.org/abs/2601.16677)
*Lucía Güitta-López,Lionel Güitta-López,Jaime Boal,Álvaro Jesús López-López*

Main category: cs.RO

TL;DR: 提出基于StyleID-CycleGAN的域适应方法，将虚拟观测转换为真实合成图像，实现DRL策略的零样本迁移，在工业机器人拾放任务中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在工业应用中的样本效率问题限制了其实际部署，虚拟环境训练成本低但存在sim-to-real差距，需要实现零样本迁移以提高实用价值。

Method: 提出StyleID-CycleGAN模型，基于CycleGAN框架将原始虚拟观测转换为真实合成图像，创建混合域用于训练DRL智能体，结合虚拟动力学与真实视觉输入。

Result: 虚拟环境中智能体成功率90-100%，真实部署实现零样本迁移，大多数工作区域准确率超过95%，能够泛化到不同颜色和形状的真实物体。

Conclusion: 所提方法为sim-to-real问题提供了高效、可扩展的解决方案，通过域适应实现DRL策略的零样本迁移，具有实际工业应用价值。

Abstract: The sample efficiency challenge in Deep Reinforcement Learning (DRL) compromises its industrial adoption due to the high cost and time demands of real-world training. Virtual environments offer a cost-effective alternative for training DRL agents, but the transfer of learned policies to real setups is hindered by the sim-to-real gap. Achieving zero-shot transfer, where agents perform directly in real environments without additional tuning, is particularly desirable for its efficiency and practical value. This work proposes a novel domain adaptation approach relying on a Style-Identified Cycle Consistent Generative Adversarial Network (StyleID-CycleGAN or SICGAN), an original Cycle Consistent Generative Adversarial Network (CycleGAN) based model. SICGAN translates raw virtual observations into real-synthetic images, creating a hybrid domain for training DRL agents that combines virtual dynamics with real-like visual inputs. Following virtual training, the agent can be directly deployed, bypassing the need for real-world training. The pipeline is validated with two distinct industrial robots in the approaching phase of a pick-and-place operation. In virtual environments agents achieve success rates of 90 to 100\%, and real-world deployment confirms robust zero-shot transfer (i.e., without additional training in the physical environment) with accuracies above 95\% for most workspace regions. We use augmented reality targets to improve the evaluation process efficiency, and experimentally demonstrate that the agent successfully generalizes to real objects of varying colors and shapes, including LEGO\textsuperscript{\textregistered}~cubes and a mug. These results establish the proposed pipeline as an efficient, scalable solution to the sim-to-real problem.

</details>


### [20] [Adaptive Reinforcement and Model Predictive Control Switching for Safe Human-Robot Cooperative Navigation](https://arxiv.org/abs/2601.16686)
*Ning Liu,Sen Shen,Zheng Li,Matthew D'Souza,Jen Jen Chung,Thomas Braunl*

Main category: cs.RO

TL;DR: ARMS是一个混合学习-控制框架，用于移动协作机器人的人导导航，通过自适应神经切换器在强化学习和模型预测控制之间进行上下文感知的软动作融合。


<details>
  <summary>Details</summary>
Motivation: 解决移动协作机器人在同时满足接近度调节和安全约束条件下的人导导航挑战，特别是在部分可观测性和非平稳人类运动环境中的鲁棒感知问题。

Method: 提出ARMS混合框架：集成PPO训练的强化学习跟随器和作为安全过滤器的单步MPC二次规划；采用解耦感知架构（LSTM时间编码器处理人机相对状态，空间编码器处理360度LiDAR扫描）；核心是学习的自适应神经切换器，根据上下文在两种控制器间进行软动作融合。

Result: 在高度杂乱环境中达到82.5%的成功率，比DWA和纯RL方法分别提高7.1%和3.1%；计算延迟降低33%至5.2毫秒；Gazebo仿真和初步实际部署验证了实用性和鲁棒性。

Conclusion: ARMS通过自适应控制器切换实现了安全高效的人机协作，在保持计算效率的同时提高了导航性能，为实际部署提供了可行方案。

Abstract: This paper addresses the challenge of human-guided navigation for mobile collaborative robots under simultaneous proximity regulation and safety constraints. We introduce Adaptive Reinforcement and Model Predictive Control Switching (ARMS), a hybrid learning-control framework that integrates a reinforcement learning follower trained with Proximal Policy Optimization (PPO) and an analytical one-step Model Predictive Control (MPC) formulated as a quadratic program safety filter. To enable robust perception under partial observability and non-stationary human motion, ARMS employs a decoupled sensing architecture with a Long Short-Term Memory (LSTM) temporal encoder for the human-robot relative state and a spatial encoder for 360-degree LiDAR scans. The core contribution is a learned adaptive neural switcher that performs context-aware soft action fusion between the two controllers, favoring conservative, constraint-aware QP-based control in low-risk regions while progressively shifting control authority to the learned follower in highly cluttered or constrained scenarios where maneuverability is critical, and reverting to the follower action when the QP becomes infeasible. Extensive evaluations against Pure Pursuit, Dynamic Window Approach (DWA), and an RL-only baseline demonstrate that ARMS achieves an 82.5 percent success rate in highly cluttered environments, outperforming DWA and RL-only approaches by 7.1 percent and 3.1 percent, respectively, while reducing average computational latency by 33 percent to 5.2 milliseconds compared to a multi-step MPC baseline. Additional simulation transfer in Gazebo and initial real-world deployment results further indicate the practicality and robustness of ARMS for safe and efficient human-robot collaboration. Source code and a demonstration video are available at https://github.com/21ning/ARMS.git.

</details>


### [21] [Creating a biologically more accurate spider robot to study active vibration sensing](https://arxiv.org/abs/2601.16691)
*Siyuan Sun,Eugene H. Lin,Nathan Brown,Hsin-Yi Hung,Andrew Gordus,Jochen Mueller,Chen Li*

Main category: cs.RO

TL;DR: 研究人员开发了一个新的八足蜘蛛机器人，具有更接近真实蜘蛛的腿部形态和更深的蹲伏运动范围，用于研究蜘蛛如何通过腿部蹲伏行为增强蛛网上的振动感知。


<details>
  <summary>Details</summary>
Motivation: 圆蛛通过腿关节的振动传感器检测蛛网上的猎物，它们常在感知猎物时动态蹲伏腿部，这很可能是一种主动感知策略。然而，由于在行为动物中测量系统振动很困难，腿部蹲伏如何增强感知的机制尚不清楚。

Method: 开发新的蜘蛛机器人，具有八条腿，每条腿有四个关节，更好地近似蜘蛛腿部形态。腿部外骨骼采用3D打印，关节刚度通过集成硅胶模具和可变材料/几何形状进行调节。肌腱驱动机构允许身体内的电机像真实蜘蛛一样深度蹲伏所有八条腿，同时腿关节处的加速度计记录腿部振动。

Result: 新蜘蛛机器人再现了先前机器人观察到的关键振动特征，同时提高了生物学准确性。该机器人为研究腿部行为如何调节蛛网上的振动感知提供了更准确的生物物理模型。

Conclusion: 新开发的蜘蛛机器人提供了一个生物学上更准确的机器人物理模型，可用于研究蜘蛛如何通过腿部蹲伏行为来调节蛛网上的振动感知能力。

Abstract: Orb-weaving spiders detect prey on a web using vibration sensors at leg joints. They often dynamically crouch their legs during prey sensing, likely an active sensing strategy. However, how leg crouching enhances sensing is poorly understood, because measuring system vibrations in behaving animals is difficult. We use robophysical modeling to study this problem. Our previous spider robot had only four legs, simplified leg morphology, and a shallow crouching range of motion. Here, we developed a new spider robot, with eight legs, each with four joints that better approximated spider leg morphology. Leg exoskeletons were 3-D printed and joint stiffness was tuned using integrated silicone molding with variable materials and geometry. Tendon-driven actuation allowed a motor in the body to crouch all eight legs deeply as spiders do, while accelerometers at leg joints record leg vibrations. Experiments showed that our new spider robot reproduced key vibration features observed in the previous robot while improving biological accuracy. Our new robot provides a biologically more accurate robophysical model for studying how leg behaviors modulate vibration sensing on a web.

</details>


### [22] [Boosting Deep Reinforcement Learning with Semantic Knowledge for Robotic Manipulators](https://arxiv.org/abs/2601.16866)
*Lucía Güitta-López,Vincenzo Suriani,Jaime Boal,Álvaro J. López-López,Daniele Nardi*

Main category: cs.RO

TL;DR: 将知识图谱嵌入与深度强化学习结合，通过语义知识提升机器人控制的学习效率，减少60%学习时间并提高15%任务准确率


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在机器人控制中需要大量经验数据，导致高计算和时间成本，限制了实际部署。需要利用语义知识来提升学习效率。

Method: 提出将知识图谱嵌入与深度强化学习集成的新架构，将KGEs与视觉观察结合，使智能体能够在训练中利用环境知识。

Result: 在具有固定和随机目标属性的机器人操作环境中验证，方法减少60%学习时间，提高约15个百分点的任务准确率，且不增加训练时间或计算复杂度。

Conclusion: 语义知识能够显著降低样本复杂度，提升深度强化学习在机器人应用中的有效性，展示了知识增强型强化学习的潜力。

Abstract: Deep Reinforcement Learning (DRL) is a powerful framework for solving complex sequential decision-making problems, particularly in robotic control. However, its practical deployment is often hindered by the substantial amount of experience required for learning, which results in high computational and time costs. In this work, we propose a novel integration of DRL with semantic knowledge in the form of Knowledge Graph Embeddings (KGEs), aiming to enhance learning efficiency by providing contextual information to the agent. Our architecture combines KGEs with visual observations, enabling the agent to exploit environmental knowledge during training. Experimental validation with robotic manipulators in environments featuring both fixed and randomized target attributes demonstrates that our method achieves up to {60}{\%} reduction in learning time and improves task accuracy by approximately 15 percentage points, without increasing training time or computational complexity. These results highlight the potential of semantic knowledge to reduce sample complexity and improve the effectiveness of DRL in robotic applications.

</details>


### [23] [A Multimodal Data Collection Framework for Dialogue-Driven Assistive Robotics to Clarify Ambiguities: A Wizard-of-Oz Pilot Study](https://arxiv.org/abs/2601.16870)
*Guangping Liu,Nicholas Hawkins,Billy Madden,Tipu Sultan,Flavio Esposito,Madi Babaiasl*

Main category: cs.RO

TL;DR: 提出一个用于收集轮椅及轮椅机械臂多模态交互数据的数据采集框架，通过对话式交互协议和双房间Wizard-of-Oz设置来模拟机器人自主性并获取自然用户行为，以解决现有数据集中缺乏自然人机交互特别是对话驱动控制中模糊性数据的问题。


<details>
  <summary>Details</summary>
Motivation: 轮椅和轮椅机械臂的集成控制对严重运动障碍用户具有重要价值，但现有接口缺乏灵活性，难以实现直观的辅助交互。虽然数据驱动的AI方法前景广阔，但进展受到缺乏捕捉自然人机交互（特别是对话驱动控制中的模糊性）的多模态数据集的限制。

Method: 提出多模态数据采集框架，采用基于对话的交互协议和双房间Wizard-of-Oz设置来模拟机器人自主性，同时激发自然用户行为。框架记录五种同步模态：RGB-D视频、对话音频、惯性测量单元信号、末端执行器笛卡尔位姿和全身关节状态，覆盖五个辅助任务。

Result: 使用该框架收集了来自五名参与者的53次试验的试点数据集，通过运动平滑度分析和用户反馈验证了数据质量。结果显示框架能有效捕捉多种模糊性类型，支持自然的对话驱动交互，证明其适合扩展为更大规模的数据集。

Conclusion: 该数据采集框架为学习、基准测试和评估具有模糊性感知的辅助控制提供了合适的基础，能够支持更大规模数据集的构建，从而推动轮椅和轮椅机械臂集成控制中AI方法的发展。

Abstract: Integrated control of wheelchairs and wheelchair-mounted robotic arms (WMRAs) has strong potential to increase independence for users with severe motor limitations, yet existing interfaces often lack the flexibility needed for intuitive assistive interaction. Although data-driven AI methods show promise, progress is limited by the lack of multimodal datasets that capture natural Human-Robot Interaction (HRI), particularly conversational ambiguity in dialogue-driven control. To address this gap, we propose a multimodal data collection framework that employs a dialogue-based interaction protocol and a two-room Wizard-of-Oz (WoZ) setup to simulate robot autonomy while eliciting natural user behavior. The framework records five synchronized modalities: RGB-D video, conversational audio, inertial measurement unit (IMU) signals, end-effector Cartesian pose, and whole-body joint states across five assistive tasks. Using this framework, we collected a pilot dataset of 53 trials from five participants and validated its quality through motion smoothness analysis and user feedback. The results show that the framework effectively captures diverse ambiguity types and supports natural dialogue-driven interaction, demonstrating its suitability for scaling to a larger dataset for learning, benchmarking, and evaluation of ambiguity-aware assistive control.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [24] [Ordering-based Causal Discovery via Generalized Score Matching](https://arxiv.org/abs/2601.16249)
*Vy Vo,He Zhao,Trung Le,Edwin V. Bonilla,Dinh Phung*

Main category: cs.LG

TL;DR: 本文提出了一种基于离散评分函数的因果发现方法，扩展了连续数据的评分匹配框架，通过新的叶节点判别准则从离散观测数据中推断因果顺序。


<details>
  <summary>Details</summary>
Motivation: 从纯观测数据学习有向无环图（DAG）结构是跨科学领域的长期挑战。现有基于数据分布评分的因果发现方法主要针对连续数据，缺乏对离散数据的有效处理框架。

Method: 扩展评分匹配框架至离散数据，引入基于离散评分函数的叶节点判别准则。首先通过叶节点检测识别底层DAG的拓扑顺序，然后进行边剪枝完成图恢复。

Result: 模拟和真实世界实验表明，该方法能够从观测离散数据中准确推断真实因果顺序，且识别出的顺序能显著提升现有因果发现基线的准确性，在几乎所有设置中都有效。

Conclusion: 提出的基于离散评分函数的因果发现框架成功解决了从离散观测数据学习DAG结构的挑战，为离散数据的因果推断提供了有效方法。

Abstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.

</details>


### [25] [Student Mental Health Screening via Fitbit Data Collected During the COVID-19 Pandemic](https://arxiv.org/abs/2601.16324)
*Rebecca Lopez,Avantika Shrestha,ML Tlachac,Kevin Hickey,Xingtong Guo,Shichao Liu,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 使用Fitbit可穿戴设备数据通过机器学习模型筛查大学生抑郁、焦虑和压力，研究验证了心率和睡眠等生理模态在心理健康监测中的潜力


<details>
  <summary>Details</summary>
Motivation: 大学生面临多种压力源导致高水平的焦虑和抑郁，当前研究在心理测量工具多样性、生理模态和时间序列参数方面存在局限，需要探索可穿戴设备在心理健康早期检测中的应用潜力

Method: 收集疫情期间大学生的StudentMEH Fitbit数据集，使用预测性机器学习模型评估不同Fitbit模态（如心率和睡眠）在抑郁、焦虑和压力筛查中的能力

Result: 生理模态如心率和睡眠在心理健康筛查中表现出潜力：焦虑筛查F1分数最高达0.79，压力筛查中心率模态达0.77，抑郁筛查中睡眠模态达0.78

Conclusion: 可穿戴设备在持续心理健康监测中具有潜力，识别最佳数据聚合水平和适当模态对于筛查不同心理健康问题至关重要

Abstract: College students experience many stressors, resulting in high levels of anxiety and depression. Wearable technology provides unobtrusive sensor data that can be used for the early detection of mental illness. However, current research is limited concerning the variety of psychological instruments administered, physiological modalities, and time series parameters. In this research, we collect the Student Mental and Environmental Health (StudentMEH) Fitbit dataset from students at our institution during the pandemic. We provide a comprehensive assessment of the ability of predictive machine learning models to screen for depression, anxiety, and stress using different Fitbit modalities. Our findings indicate potential in physiological modalities such as heart rate and sleep to screen for mental illness with the F1 scores as high as 0.79 for anxiety, the former modality reaching 0.77 for stress screening, and the latter modality achieving 0.78 for depression. This research highlights the potential of wearable devices to support continuous mental health monitoring, the importance of identifying best data aggregation levels and appropriate modalities for screening for different mental ailments.

</details>


### [26] [Efficient Gaussian process learning via subspace projections](https://arxiv.org/abs/2601.16332)
*Felipe Tobar,Elsa Cazelles*

Main category: cs.LG

TL;DR: 提出了一种用于高斯过程的新训练目标——投影似然，通过数据低维线性投影构建，在中等规模数据集上比精确GP训练和变分稀疏GP方法在精度和计算效率上更优。


<details>
  <summary>Details</summary>
Motivation: 传统高斯过程在大规模数据集上计算复杂度高，现有稀疏近似方法如变分自由能存在精度损失。需要一种既能保持精度又能提高计算效率的新方法。

Method: 提出投影似然训练目标，使用数据的低维线性投影构建高斯过程。推导了投影似然信息损失的闭式表达式，并证明通过单位球上的随机投影可以减少这种损失。

Result: 在多个优化器、核函数和中等规模数据集上的实验表明，投影似然方法在精度和计算效率上均优于精确GP训练和变分自由能稀疏GP方法。

Conclusion: 投影似然为高斯过程提供了一种有效且计算高效的训练框架，特别适用于中等规模数据集，平衡了模型精度和计算复杂度。

Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.

</details>


### [27] [A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning](https://arxiv.org/abs/2601.16399)
*Sihan Zeng,Sujay Bhatt,Sumitra Ganesh,Alec Koppel*

Main category: cs.LG

TL;DR: 提出一种单循环一阶actor-critic算法，通过基于惩罚的重构解决结构化双层优化问题，其中上层目标函数平滑，下层是MDP中的策略优化问题


<details>
  <summary>Details</summary>
Motivation: 现有双层优化和RL方法需要二阶信息、对下层施加强正则化，或通过嵌套循环过程低效使用样本。需要开发更高效的单循环一阶方法来解决上层决策变量参数化下层MDP奖励的双层优化问题

Method: 提出单循环一阶actor-critic算法，通过惩罚重构优化双层目标。在下层RL目标中引入衰减熵正则化，实现渐近无偏的上层超梯度估计，无需精确求解无正则化RL问题

Result: 建立了算法在原始无正则化双层优化问题平稳点上的有限时间和有限样本收敛性，通过特殊类型Polyak-Lojasiewicz条件下的新颖下层残差分析证明。在GridWorld目标位置问题和通过RLHF的快乐推文生成实验中验证了方法性能

Conclusion: 该方法通过衰减熵正则化和惩罚重构，实现了高效的单循环一阶双层优化，避免了现有方法的二阶信息需求、强正则化要求和样本低效问题，在理论和实验上均表现出色

Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).

</details>


### [28] [Towards a Theoretical Understanding to the Generalization of RLHF](https://arxiv.org/abs/2601.16403)
*Zhaochun Li,Mingyang Yi,Yue Wang,Shisheng Cui,Yong Liu*

Main category: cs.LG

TL;DR: 该论文建立了基于线性奖励模型的LLM RLHF泛化理论，通过算法稳定性框架证明了在特征覆盖条件下，策略模型的泛化界为O(n^{-1/2})，为RLHF的实证泛化提供了理论依据。


<details>
  <summary>Details</summary>
Motivation: 虽然RLHF及其变体已成为对齐大型语言模型与人类意图的主要方法，且实证有效，但这些方法在高维设置下的理论泛化特性尚未得到充分探索。现有工作主要基于奖励模型最大似然估计的一致性，而实际应用采用端到端学习框架，两者存在差异。

Method: 在线性奖励模型假设下，通过算法稳定性框架构建RLHF的泛化理论。分析采用端到端学习框架，证明在关键特征覆盖条件下，策略模型的经验最优解具有O(n^{-1/2})的泛化界。结果可推广到梯度上升(GA)和随机梯度上升(SGA)等梯度基学习算法获得的参数。

Result: 在特征覆盖条件下，策略模型的经验最优解具有O(n^{-1/2})的泛化界。该理论结果可推广到梯度基优化算法获得的参数，为RLHF后LLM的实证泛化观察提供了新的理论证据。

Conclusion: 该研究建立了RLHF在LLM中的理论泛化框架，通过算法稳定性分析证明了在特征覆盖条件下可获得O(n^{-1/2})的泛化界，为RLHF的实证有效性提供了理论支持，并填补了高维设置下理论分析的空白。

Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\mathcal{O}(n^{-\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.

</details>


### [29] [Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction](https://arxiv.org/abs/2601.16406)
*Vitaly Bulgakov,Alexander Turchin*

Main category: cs.LG

TL;DR: LPCORP是一个两阶段框架，通过推理增强预测和基于置信度的结果校正来解决罕见事件预测中的类别不平衡问题，无需重采样即可将高度不平衡数据转换为平衡分布。


<details>
  <summary>Details</summary>
Motivation: 在医疗、金融、可靠性工程、客户支持、航空安全等领域，罕见事件预测至关重要，但极端类别不平衡会导致传统模型偏向多数类预测，限制了召回率、校准性和实际应用价值。

Method: LPCORP采用两阶段框架：第一阶段使用推理模型从叙事输入生成增强预测；第二阶段使用轻量级逻辑回归分类器评估并选择性校正这些输出，以减轻流行度驱动的偏差。

Result: 该方法成功将高度不平衡设置转换为平衡设置，同时保留原始样本数量且不应用任何重采样策略。测试集评估显示性能显著提升，特别是在低流行度数据中通常较弱的精确度方面。成本降低分析显示在某些情况下可减少超过50%的费用。

Conclusion: LPCORP框架有效解决了罕见事件预测中的类别不平衡问题，通过推理增强预测和选择性校正，在不使用重采样的情况下显著提升了模型性能，并在实际应用中展示了显著的成本节约潜力。

Abstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.

</details>


### [30] [A Refinement of Vapnik--Chervonenkis' Theorem](https://arxiv.org/abs/2601.16411)
*A. Iosevich,A. Vagharshakyan,E. Wyman*

Main category: cs.LG

TL;DR: 论文改进了VC定理的经典证明，用带Berry-Esseen误差控制的中心极限定理替代Hoeffding不等式，得到了更精确的中偏差估计。


<details>
  <summary>Details</summary>
Motivation: 经典VC定理的证明在最后一步使用Hoeffding不等式，作者希望改进这一概率分析部分以获得更精确的收敛速率估计。

Method: 重新审视VC定理的概率分析部分，使用带Berry-Esseen误差控制的中心极限定理（正态近似）替代传统的Hoeffding不等式。

Result: 得到了比传统VC估计更精确的中偏差估计，当ε√n较大时，主导指数项中增加了(ε√n)^{-1}阶的因子。

Conclusion: 通过改进概率分析工具，获得了VC定理的更精确估计，为经验概率与理论概率的一致收敛提供了更精细的速率分析。

Abstract: Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.
  We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\varepsilon\sqrt{n})^{-1}$ in the leading exponential term when $\varepsilon\sqrt{n}$ is large.

</details>


### [31] [PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning](https://arxiv.org/abs/2601.16414)
*John Wu,Yongda Fan,Zhenbang Wu,Paul Landes,Eric Schrock,Sayeed Sajjad Razin,Arjun Chatterjee,Naveen Baskaran,Joshua Steier,Andrea Fitzpatrick,Bilal Arif,Rian Atri,Jathurshan Pradeepkumar,Siddhartha Laghuvarapu,Junyi Gao,Adam R. Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: PyHealth 2.0是一个增强的临床深度学习工具包，旨在通过统一框架、优化性能和建立活跃社区来降低临床AI研究的门槛，实现仅用7行代码即可进行预测建模。


<details>
  <summary>Details</summary>
Motivation: 临床AI研究面临基线难以复现、计算成本高、需要领域专业知识等持续障碍，这些因素限制了研究的可及性和可重复性。

Method: 开发PyHealth 2.0工具包，提供三个核心贡献：1) 统一框架整合15+数据集、20+临床任务、25+模型、5+可解释性方法和不确定性量化；2) 面向可及性设计，支持多模态数据，优化计算性能；3) 建立400+成员的活跃开源社区，提供多语言支持。

Result: 工具包实现了高达39倍的加速处理和20倍的内存使用降低，支持从16GB笔记本电脑到生产系统的不同计算资源，显著降低了临床AI研究的门槛。

Conclusion: PyHealth 2.0建立了一个开源基础和社区，推动可访问、可重复的医疗AI研究，为临床AI研究提供了统一、高效、易用的解决方案。

Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.

</details>


### [32] [Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance](https://arxiv.org/abs/2601.16425)
*Huchen Yang,Xinghao Dong,Jin-Long Wu*

Main category: cs.LG

TL;DR: 该论文比较了贝叶斯实验设计（BED）中两种效用函数准则：Kullback-Leibler（KL）散度和Wasserstein距离。研究发现KL散度在无模型失配时收敛更快，而Wasserstein距离在存在模型失配时提供更稳健的序贯BED结果。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯实验设计（BED）为科学发现提供了原则性的信息框架，但效用函数的选择一直是一个活跃的研究课题。虽然KL散度是最常见的选择，但最近的研究提出了Wasserstein距离作为替代。本文旨在系统比较这两种准则，阐明它们在不同条件下的表现差异，为实际应用提供指导。

Method: 首先通过一个玩具示例说明Wasserstein距离的问题：固定形状的后验分布，其Wasserstein距离值取决于其主要质量在支撑集中的相对位置，可能产生与信息增益无关的虚假奖励，特别是在使用非信息先验（如均匀分布）时。然后通过BED文献中的经典源反演问题，系统比较这两种准则的性能。

Result: 研究发现：1）Wasserstein距离对后验分布的位置敏感，可能产生与信息增益无关的虚假奖励；2）在无模型失配的情况下，KL散度倾向于导致更快的收敛；3）如果模型失配不可忽略，Wasserstein度量提供更稳健的序贯BED结果。

Conclusion: 该研究阐明了KL散度和Wasserstein度量作为效用函数的权衡关系，为实际BED应用中选择合适的准则提供了指导。KL散度在理想条件下收敛更快，而Wasserstein距离在存在模型失配时更加稳健。

Abstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the selection of utility functions in BED is a long-standing and active topic, where different criteria emphasize different notions of information. Although Kullback--Leibler (KL) divergence has been one of the most common choices, recent studies have proposed Wasserstein distance as an alternative. In this work, we first employ a toy example to illustrate an issue of Wasserstein distance - the value of Wasserstein distance of a fixed-shape posterior depends on the relative position of its main mass within the support and can exhibit false rewards unrelated to information gain, especially with a non-informative prior (e.g., uniform distribution). We then further provide a systematic comparison between these two criteria through a classical source inversion problem in the BED literature, revealing that the KL divergence tends to lead to faster convergence in the absence of model discrepancy, while Wasserstein metrics provide more robust sequential BED results if model discrepancy is non-negligible. These findings clarify the trade-offs between KL divergence and Wasserstein metrics for the utility function and provide guidelines for selecting suitable criteria in practical BED applications.

</details>


### [33] [On the Expressive Power of Floating-Point Transformers](https://arxiv.org/abs/2601.16450)
*Sejun Park,Yeachan Park,Geonho Hwang*

Main category: cs.LG

TL;DR: 研究浮点Transformer的表达能力，发现与精确运算下的理论结果不同：浮点Transformer即使没有位置编码也能表示非置换等变函数，在序列长度有限时可表示所有置换等变函数，但序列长度大时则不能。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer表达能力研究基于实数参数和精确运算，但实际计算机实现使用有限浮点数和含舍入误差的机器运算。需要研究浮点参数和浮点运算下Transformer的真实表达能力。

Method: 分析使用浮点参数和浮点运算的Transformer（浮点Transformer）的表示能力。通过理论证明探讨其在有无位置编码情况下的表达能力，特别关注置换等变性和序列长度的影响。

Result: 1. 浮点Transformer即使没有位置编码也能表示一类非置换等变函数；2. 序列长度有限时，浮点Transformer能表示所有置换等变函数；3. 序列长度大时，浮点Transformer不能表示所有置换等变函数；4. 发现了浮点Transformer中的最小等变结构；5. 所有非平凡加法位置编码都会损害浮点Transformer的表示能力。

Conclusion: 浮点运算的有限精度特性显著改变了Transformer的理论表达能力，使其与理想实数模型存在本质差异。实际实现中的数值限制影响了模型的等变性和表示能力，位置编码的设计需要重新考虑浮点运算的影响。

Abstract: The study on the expressive power of transformers shows that transformers are permutation equivariant, and they can approximate all permutation-equivariant continuous functions on a compact domain. However, these results are derived under real parameters and exact operations, while real implementations on computers can only use a finite set of numbers and inexact machine operations with round-off errors. In this work, we investigate the representability of floating-point transformers that use floating-point parameters and floating-point operations. Unlike existing results under exact operations, we first show that floating-point transformers can represent a class of non-permutation-equivariant functions even without positional encoding. Furthermore, we prove that floating-point transformers can represent all permutation-equivariant functions when the sequence length is bounded, but they cannot when the sequence length is large. We also found the minimal equivariance structure in floating-point transformers, and show that all non-trivial additive positional encoding can harm the representability of floating-point transformers.

</details>


### [34] [On the Effects of Adversarial Perturbations on Distribution Robustness](https://arxiv.org/abs/2601.16464)
*Yipei Wang,Zhaoying Pan,Xiaoqian Wang*

Main category: cs.LG

TL;DR: 论文分析了对抗鲁棒性和分布鲁棒性之间的权衡关系，发现对抗训练可能增加对虚假特征的依赖，损害分布鲁棒性，但在特定条件下（适度偏置数据和特征可分性高时）对抗扰动反而能提升分布鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 虽然对抗鲁棒性和分布鲁棒性都旨在确保模型可靠性能，但先前研究发现两者存在权衡：对抗训练可能增加对虚假特征的依赖，从而损害分布鲁棒性，特别是在某些代表性不足的子群体上。本文旨在深入理解这种权衡关系及其背后的机制。

Method: 通过理论分析，研究在扰动数据上训练的模型，为每步对抗训练提供一个可处理的替代方法。分析重点关注ℓ∞扰动对数据偏置的影响，以及特征可分性在权衡关系中的作用。

Result: 发现对抗鲁棒性和分布鲁棒性之间存在权衡，但进一步识别了一个微妙现象：在适度偏置的数据上，ℓ∞扰动可以提升分布鲁棒性。当特征可分性高（核心特征更易分离）时，即使在高度偏斜的数据上，分布鲁棒性的增益仍然存在。

Conclusion: 理论分析扩展了对对抗鲁棒性和分布鲁棒性权衡的理解，强调了特征可分性在权衡关系中的关键作用。尽管在许多情况下权衡仍然存在，但忽视特征可分性的作用可能导致对鲁棒性的误导性结论。

Abstract: Adversarial robustness refers to a model's ability to resist perturbation of inputs, while distribution robustness evaluates the performance of the model under data shifts. Although both aim to ensure reliable performance, prior work has revealed a tradeoff in distribution and adversarial robustness. Specifically, adversarial training might increase reliance on spurious features, which can harm distribution robustness, especially the performance on some underrepresented subgroups. We present a theoretical analysis of adversarial and distribution robustness that provides a tractable surrogate for per-step adversarial training by studying models trained on perturbed data. In addition to the tradeoff, our work further identified a nuanced phenomenon that $\ell_\infty$ perturbations on data with moderate bias can yield an increase in distribution robustness. Moreover, the gain in distribution robustness remains on highly skewed data when simplicity bias induces reliance on the core feature, characterized as greater feature separability. Our theoretical analysis extends the understanding of the tradeoff by highlighting the interplay of the tradeoff and the feature separability. Despite the tradeoff that persists in many cases, overlooking the role of feature separability may lead to misleading conclusions about robustness.

</details>


### [35] [A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study](https://arxiv.org/abs/2601.16467)
*Maxwell Reynolds,Chaitanya Srinivasan,Vijay Cherupally,Michael Leone,Ke Yu,Li Sun,Tigmanshu Chaudhary,Andreas Pfenning,Kayhan Batmanghelich*

Main category: cs.LG

TL;DR: R-NCE自监督学习框架从结构MRI中提取优于传统FreeSurfer特征的AD生物标志物，在疾病分类、转化预测和生物学相关性方面表现优异


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期检测需要敏感且生物学基础的生物标志物。结构MRI广泛可用但依赖手工特征（如皮质厚度或体积）。现有自监督学习方法在疾病分类、转化预测和淀粉样蛋白状态预测方面表现不如FreeSurfer特征。

Method: 提出残差噪声对比估计（R-NCE）自监督学习框架，整合辅助FreeSurfer特征同时最大化增强不变性信息。通过脑年龄差（BAG）测量和全基因组关联研究评估生物学相关性。

Result: R-NCE在多个基准测试中优于传统特征和现有自监督学习方法，包括AD转化预测。R-NCE-BAG显示高遗传性，与MAPT和IRAG1基因关联，在星形胶质细胞和少突胶质细胞中富集，表明对神经退行性和脑血管过程的敏感性。

Conclusion: R-NCE自监督学习框架能够从结构MRI中发现比传统手工特征更强大的AD生物标志物，这些标志物具有生物学相关性，对神经退行性和脑血管过程敏感，为AD早期检测和监测提供了新方法。

Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.

</details>


### [36] [Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning](https://arxiv.org/abs/2601.16491)
*Shenghong Cai,Yiqun Zhang,Xiaopeng Luo,Yiu-Ming Cheung,Hong Jia,Peng Liu*

Main category: cs.LG

TL;DR: 提出MCDC方法，通过多粒度竞争惩罚学习(MGCPL)和基于编码的聚类聚合(CAME)解决分类数据聚类中的嵌套粒度簇效应问题


<details>
  <summary>Details</summary>
Motivation: 分类数据在隐式离散距离空间中普遍存在嵌套粒度簇效应，即数据对象在空间或子空间中重叠形成小紧凑簇，相似小簇又形成更大簇。由于分类数据的定性特性，无法像欧氏距离那样明确定义距离空间，这给分类数据的聚类分析带来巨大挑战。

Method: 设计多粒度竞争惩罚学习(MGCPL)算法，让潜在簇在不同阶段以不同数量的自然紧凑簇进行交互式自我调整和收敛。基于MGCPL提出聚类聚合策略(CAME)，首先根据学习到的多粒度分布对数据对象进行编码，然后在嵌入空间执行最终聚类，形成完整的MCDC方法。

Result: MCDC能够自动探索多粒度簇的嵌套分布，对各种领域的分类数据集具有高度鲁棒性。得益于其线性时间复杂度，MCDC可扩展到大规模数据集，在预分区数据集或计算节点以提升分布式计算性能方面具有潜力。大量实验统计证据表明其在各种真实公共数据集上优于现有最先进方法。

Conclusion: 提出的MCDC方法通过MGCPL和CAME策略有效解决了分类数据聚类中的嵌套粒度簇效应问题，实现了自动多粒度聚类探索，具有高鲁棒性、可扩展性和实际应用价值。

Abstract: Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data objects frequently overlap in space or subspace to form small compact clusters, and similar small clusters often form larger clusters. However, the distance space cannot be well-defined like the Euclidean distance due to the qualitative categorical data values, which brings great challenges to the cluster analysis of categorical data. In view of this, we design a Multi-Granular Competitive Penalization Learning (MGCPL) algorithm to allow potential clusters to interactively tune themselves and converge in stages with different numbers of naturally compact clusters. To leverage MGCPL, we also propose a Cluster Aggregation strategy based on MGCPL Encoding (CAME) to first encode the data objects according to the learned multi-granular distributions, and then perform final clustering on the embeddings. It turns out that the proposed MGCPL-guided Categorical Data Clustering (MCDC) approach is competent in automatically exploring the nested distribution of multi-granular clusters and highly robust to categorical data sets from various domains. Benefiting from its linear time complexity, MCDC is scalable to large-scale data sets and promising in pre-partitioning data sets or compute nodes for boosting distributed computing. Extensive experiments with statistical evidence demonstrate its superiority compared to state-of-the-art counterparts on various real public data sets.

</details>


### [37] [Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario](https://arxiv.org/abs/2511.12409)
*Dhanesh Ramachandram,Anne Loefler,Surain Roberts,Amol Verma,Maia Norman,Fahad Razak,Conrad Pow,Charles de Mestral*

Main category: cs.LG

TL;DR: 提出CRISPNAM-FG模型，一种内在可解释的竞争风险生存模型，结合神经加法模型结构和Fine-Gray公式，在保持高预测性能的同时提供透明可审计的预测。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在生存分析中预测性能优秀但缺乏可解释性，这阻碍了其在临床实践中的应用。特别是在竞争风险场景下，模型透明度对于建立AI安全性和临床医生信任至关重要。

Method: 基于神经加法模型结构，为每个风险使用独立的投影向量，采用Fine-Gray公式预测累积发生率函数，实现内在可解释性。通过形状函数和特征重要性图提供透明度。

Result: 在多个基准数据集上验证，并在29家安大略省医院（2016-2023）的糖尿病患者足部并发症预测中应用。与其他深度生存模型相比具有竞争力的性能，同时提供可解释性。

Conclusion: CRISPNAM-FG模型成功平衡了预测性能和可解释性，为临床实践中的竞争风险生存分析提供了透明、可审计的解决方案，有助于促进AI在医疗领域的可信集成。

Abstract: Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.

</details>


### [38] [BoostFGL: Boosting Fairness in Federated Graph Learning](https://arxiv.org/abs/2601.16496)
*Zekai Chen,Kairui Yang,Xunkai Li,Henan Sun,Zhihan Zhang,Jia Li,Qiangqiang Dai,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: BoostFGL是一个联邦图学习框架，通过客户端节点增强、拓扑增强和服务器端模型增强三种机制，解决联邦图学习中因标签倾斜、拓扑混淆和聚合稀释导致的群体公平性问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦图学习方法虽然整体准确率高，但会掩盖弱势节点群体的严重性能退化。这种不公平性源于三个耦合因素：标签向多数模式倾斜、消息传播中的拓扑混淆，以及困难客户端更新的聚合稀释。

Method: BoostFGL采用增强式框架，包含三个协调机制：1) 客户端节点增强：重塑本地训练信号，强调系统性服务不足的节点；2) 客户端拓扑增强：重新分配传播重点，偏向可靠但未充分利用的结构，同时减弱误导性邻域；3) 服务器端模型增强：执行难度和可靠性感知的聚合，保留困难客户端的有效更新，同时稳定全局模型。

Result: 在9个数据集上的广泛实验表明，BoostFGL实现了显著的公平性提升，将Overall-F1提高了8.43%，同时在整体性能上保持与强基线联邦图学习方法相当的竞争力。

Conclusion: BoostFGL通过协调的增强机制有效解决了联邦图学习中的公平性问题，在提升弱势群体性能的同时保持了整体性能，为公平感知的联邦图学习提供了有效框架。

Abstract: Federated graph learning (FGL) enables collaborative training of graph neural networks (GNNs) across decentralized subgraphs without exposing raw data. While existing FGL methods often achieve high overall accuracy, we show that this average performance can conceal severe degradation on disadvantaged node groups. From a fairness perspective, these disparities arise systematically from three coupled sources: label skew toward majority patterns, topology confounding in message propagation, and aggregation dilution of updates from hard clients. To address this, we propose \textbf{BoostFGL}, a boosting-style framework for fairness-aware FGL. BoostFGL introduces three coordinated mechanisms: \ding{182} \emph{Client-side node boosting}, which reshapes local training signals to emphasize systematically under-served nodes; \ding{183} \emph{Client-side topology boosting}, which reallocates propagation emphasis toward reliable yet underused structures and attenuates misleading neighborhoods; and \ding{184} \emph{Server-side model boosting}, which performs difficulty- and reliability-aware aggregation to preserve informative updates from hard clients while stabilizing the global model. Extensive experiments on 9 datasets show that BoostFGL delivers substantial fairness gains, improving Overall-F1 by 8.43\%, while preserving competitive overall performance against strong FGL baselines.

</details>


### [39] [kNN-Graph: An adaptive graph model for $k$-nearest neighbors](https://arxiv.org/abs/2601.16509)
*Jiaye Li,Gang Chen,Hang Xu,Shichao Zhang*

Main category: cs.LG

TL;DR: 提出一种自适应图模型，通过将HNSW图与预计算投票机制结合，将邻居选择和加权的计算负担完全转移到训练阶段，实现推理延迟与计算复杂度的解耦，显著加速kNN推理速度而不损失分类精度。


<details>
  <summary>Details</summary>
Motivation: kNN算法在大规模应用中面临推理速度与精度之间的计算权衡问题。现有的近似最近邻解决方案虽然加速了检索，但通常会降低分类精度，并且缺乏选择最优邻域大小(k)的自适应性。

Method: 提出自适应图模型，集成分层可导航小世界(HNSW)图与预计算投票机制。该框架将邻居选择和加权的计算负担完全转移到训练阶段。在拓扑结构中，高层图实现快速导航，低层图编码精确的节点特定决策边界并具有自适应邻居数量。

Result: 在六个不同数据集上对八个最先进的基线方法进行基准测试，结果表明该架构显著加速了推理速度，实现了实时性能，同时没有损害分类精度。

Conclusion: 该研究为kNN长期存在的推理瓶颈问题提供了可扩展、鲁棒的解决方案，建立了基于图的非参数学习的新结构范式。

Abstract: The k-nearest neighbors (kNN) algorithm is a cornerstone of non-parametric classification in artificial intelligence, yet its deployment in large-scale applications is persistently constrained by the computational trade-off between inference speed and accuracy. Existing approximate nearest neighbor solutions accelerate retrieval but often degrade classification precision and lack adaptability in selecting the optimal neighborhood size (k). Here, we present an adaptive graph model that decouples inference latency from computational complexity. By integrating a Hierarchical Navigable Small World (HNSW) graph with a pre-computed voting mechanism, our framework completely transfers the computational burden of neighbor selection and weighting to the training phase. Within this topological structure, higher graph layers enable rapid navigation, while lower layers encode precise, node-specific decision boundaries with adaptive neighbor counts. Benchmarking against eight state-of-the-art baselines across six diverse datasets, we demonstrate that this architecture significantly accelerates inference speeds, achieving real-time performance, without compromising classification accuracy. These findings offer a scalable, robust solution to the long-standing inference bottleneck of kNN, establishing a new structural paradigm for graph-based nonparametric learning.

</details>


### [40] [Finite-Time Analysis of Gradient Descent for Shallow Transformers](https://arxiv.org/abs/2601.16514)
*Enes Arda,Semih Cayci,Atilla Eryilmaz*

Main category: cs.LG

TL;DR: 分析浅层Transformer在核机制下的优化特性，发现其宽度仅需与样本量对数相关，优化误差与序列长度无关，但内存需求随序列长度增长。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer为何表现优异仍然具有挑战性，因为其优化空间是非凸的。本研究旨在分析浅层Transformer在核机制下的优化特性，以揭示其与循环架构的本质差异。

Method: 采用投影梯度下降法在核机制下训练具有m个独立头的浅层Transformer，进行理论分析，并在师生设置中进行数值验证。

Result: 发现两个主要结果：(1) 非渐近保证所需的宽度仅与样本量n呈对数关系；(2) 优化误差与序列长度T无关。这与循环架构形成鲜明对比，后者的优化误差可能随T指数增长。代价是内存需求随序列长度增长。

Conclusion: Transformer在优化方面具有显著优势：宽度需求对数缩放，优化误差与序列长度无关，这解释了其优于循环架构的原因，但需要权衡内存需求随序列长度增长的问题。

Abstract: Understanding why Transformers perform so well remains challenging due to their non-convex optimization landscape. In this work, we analyze a shallow Transformer with $m$ independent heads trained by projected gradient descent in the kernel regime. Our analysis reveals two main findings: (i) the width required for nonasymptotic guarantees scales only logarithmically with the sample size $n$, and (ii) the optimization error is independent of the sequence length $T$. This contrasts sharply with recurrent architectures, where the optimization error can grow exponentially with $T$. The trade-off is memory: to keep the full context, the Transformer's memory requirement grows with the sequence length. We validate our theoretical results numerically in a teacher-student setting and confirm the predicted scaling laws for Transformers.

</details>


### [41] [DANCE: Dynamic, Available, Neighbor-gated Condensation for Federated Text-Attributed Graphs](https://arxiv.org/abs/2601.16519)
*Zekai Chen,Haodong Lu,Xunkai Li,Henan Sun,Jia Li,Hongchao Qin,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: DANCE是一种新的文本属性图联邦学习范式，通过引入图压缩技术减少LLM处理开销，采用轮次式模型内循环压缩刷新提升性能，并保留可追溯的证据包增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前文本属性图联邦学习方法面临三个主要挑战：1) LLM处理长文本的高开销；2) 一次性图压缩导致性能次优；3) LLM压缩过程缺乏可解释性，难以追溯预测来源。

Method: 提出DANCE框架：1) 引入图压缩减少计算负载；2) 采用轮次式、模型内循环的压缩刷新机制，使用最新全局模型动态更新压缩核心；3) 保留可本地检查的证据包，追踪预测到具体邻居和源文本片段。

Result: 在8个TAG数据集上，DANCE在8%压缩比下将准确率提升2.33%，同时比基线方法减少33.42%的token使用量。

Conclusion: DANCE有效解决了TAG-FGL中的开销、次优性能和可解释性问题，通过动态压缩刷新和可追溯证据包实现了高效、高性能且可解释的文本属性图联邦学习。

Abstract: Federated graph learning (FGL) enables collaborative training on graph data across multiple clients. With the rise of large language models (LLMs), textual attributes in FGL graphs are gaining attention. Text-attributed graph federated learning (TAG-FGL) improves FGL by explicitly leveraging LLMs to process and integrate these textual features. However, current TAG-FGL methods face three main challenges: \textbf{(1) Overhead.} LLMs for processing long texts incur high token and computation costs. To make TAG-FGL practical, we introduce graph condensation (GC) to reduce computation load, but this choice also brings new issues. \textbf{(2) Suboptimal.} To reduce LLM overhead, we introduce GC into TAG-FGL by compressing multi-hop texts/neighborhoods into a condensed core with fixed LLM surrogates. However, this one-shot condensation is often not client-adaptive, leading to suboptimal performance. \textbf{(3) Interpretability.} LLM-based condensation further introduces a black-box bottleneck: summaries lack faithful attribution and clear grounding to specific source spans, making local inspection and auditing difficult. To address the above issues, we propose \textbf{DANCE}, a new TAG-FGL paradigm with GC. To improve \textbf{suboptimal} performance, DANCE performs round-wise, model-in-the-loop condensation refresh using the latest global model. To enhance \textbf{interpretability}, DANCE preserves provenance by storing locally inspectable evidence packs that trace predictions to selected neighbors and source text spans. Across 8 TAG datasets, DANCE improves accuracy by \textbf{2.33\%} at an \textbf{8\%} condensation ratio, with \textbf{33.42\%} fewer tokens than baselines.

</details>


### [42] [Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs](https://arxiv.org/abs/2601.16527)
*Xianya Fang,Feiyang Ren,Xiang Chen,Yu Tian,Zhen Bi,Haiyang Yu,Sheng-Jun Huang*

Main category: cs.LG

TL;DR: SARE提出了一种针对多模态大语言模型对象幻觉的鲁棒性遗忘方法，通过目标最小最大优化和Targeted-SAM机制来平坦化损失景观，确保幻觉概念在参数扰动下的稳定消除。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在对象幻觉问题，现有遗忘方法存在结构性脆弱缺陷，仅实现表面抑制，模型容易陷入尖锐最小值，在轻量级再学习后幻觉会灾难性复发。

Method: 提出SARE框架，将遗忘建模为目标最小最大优化问题，采用Targeted-SAM机制显式平坦化幻觉概念周围的损失景观，通过模拟最坏情况参数扰动来抑制幻觉，确保对权重偏移的鲁棒性。

Result: SARE在遗忘效果上显著优于基线方法，同时保持一般生成质量。关键的是，它能在再学习和参数更新后持续抑制幻觉，验证了几何稳定化的有效性。

Conclusion: 通过几何稳定化方法解决多模态LLM对象幻觉遗忘的结构脆弱性问题，SARE框架实现了鲁棒且持久的幻觉抑制，为模型可靠性提供了新的解决方案。

Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.

</details>


### [43] [A Collision-Free Hot-Tier Extension for Engram-Style Conditional Memory: A Controlled Study of Training Dynamics](https://arxiv.org/abs/2601.16531)
*Tao Lin*

Main category: cs.LG

TL;DR: 高频键冲突不是Engram式条件记忆的主要瓶颈，碰撞消除设计在等参数设置下未能持续改善验证损失


<details>
  <summary>Details</summary>
Motivation: 研究高频键冲突是否是Engram式条件记忆的主要瓶颈，探索消除碰撞是否能改善模型性能

Method: 引入Engram-Nine碰撞消除热层扩展，通过最小完美哈希函数映射最高频n-gram，同时保留原始多头部哈希查找作为冷层；采用路由分层评估方法分解每令牌损失为热/冷层贡献

Result: 碰撞消除设计未能持续改善验证损失；发现训练中热冷层优势翻转现象：热层位置初始损失较低但冷层最终超越；碰撞消除配置翻转更早，表明碰撞提供隐式正则化；门控存在不匹配问题

Conclusion: 单纯提高查找精度不能保证更好的训练结果；主要限制可能在于门控信用分配而非索引精度；碰撞引起的噪声可能提供有益的正则化效果，不应简单消除

Abstract: We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.
  Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent "hot-to-cold advantage flip" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.
  Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.

</details>


### [44] [Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm](https://arxiv.org/abs/2601.16552)
*Xiaobin Li,Run Zhang*

Main category: cs.LG

TL;DR: JORC-UMAP：通过引入Ollivier-Ricci曲率和Jaccard相似性作为几何与拓扑先验，改进UMAP在非线性降维中的性能，减少拓扑撕裂和结构坍塌问题。


<details>
  <summary>Details</summary>
Motivation: UMAP在可视化高维数据时存在局限性，其局部欧氏距离假设无法准确捕捉内在流形几何结构，导致拓扑撕裂和结构坍塌。研究发现UMAP对k近邻图的敏感性是主要原因，需要更稳健的几何感知方法来改进。

Method: 提出JORC-UMAP方法：1）引入Ollivier-Ricci曲率作为几何先验，在几何瓶颈处加强边缘连接，减少冗余链接；2）结合Jaccard相似性作为拓扑先验，确保邻域一致性，弥补曲率估计对噪声的敏感性；3）将两种先验整合到UMAP框架中，更好地区分真实流形结构与虚假连接。

Result: 在合成和真实数据集上的实验表明，JORC-UMAP相比标准UMAP和其他降维方法，能更有效地减少撕裂和坍塌现象。通过SVM准确率和三元组保持分数的评估，JORC-UMAP在保持计算效率的同时，提供了更忠实的数据可视化效果。

Conclusion: JORC-UMAP通过结合几何和拓扑先验，为UMAP提供了几何感知的增强，能够更准确地捕捉数据的内在流形结构，减少可视化中的失真问题，为高维数据可视化提供了更可靠的工具。

Abstract: Nonlinear dimensionality reduction techniques, particularly UMAP, are widely used for visualizing high-dimensional data. However, UMAP's local Euclidean distance assumption often fails to capture intrinsic manifold geometry, leading to topological tearing and structural collapse. We identify UMAP's sensitivity to the k-nearest neighbor graph as a key cause. To address this, we introduce Ollivier-Ricci curvature as a geometric prior, reinforcing edges at geometric bottlenecks and reducing redundant links. Since curvature estimation is noise-sensitive, we also incorporate a topological prior using Jaccard similarity to ensure neighborhood consistency. The resulting method, JORC-UMAP, better distinguishes true manifold structure from spurious connections. Experiments on synthetic and real-world datasets show that JORC-UMAP reduces tearing and collapse more effectively than standard UMAP and other DR methods, as measured by SVM accuracy and triplet preservation scores, while maintaining computational efficiency. This work offers a geometry-aware enhancement to UMAP for more faithful data visualization.

</details>


### [45] [Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach](https://arxiv.org/abs/2601.16568)
*Abdurahman Maarouf,Alket Bakiaj,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 提出kNN-ICL框架，利用大语言模型进行上下文学习，仅需少量标注数据即可预测早期初创企业成功概率，解决VC投资中的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 早期初创企业成功预测面临数据稀缺挑战，传统机器学习方法需要大量标注数据，而VC公司通常只有少量早期初创企业数据，这限制了预测效果。

Method: 提出基于k近邻的上下文学习框架kNN-ICL，利用大语言模型，无需模型训练，仅使用少量标注初创企业作为演示示例，通过相似性选择最相关的历史初创企业作为上下文示例。

Result: 使用Crunchbase真实数据，kNN-ICL方法比监督机器学习基线和普通上下文学习获得更高预测准确率；仅需50个示例即可实现高平衡准确率。

Conclusion: 上下文学习可作为VC公司在数据稀缺环境中的决策工具，kNN-ICL框架在早期初创企业成功预测中表现出色，仅需少量标注数据。

Abstract: Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.

</details>


### [46] [Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting](https://arxiv.org/abs/2601.16632)
*Haonan Yang,Jianchao Tang,Zhuo Li*

Main category: cs.LG

TL;DR: DPAD是一个模型无关的辅助框架，通过双原型自适应解耦机制，增强时间序列预测模型的模式解耦和上下文感知能力


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法通常学习静态的平均表示，缺乏动态解耦和利用复杂交织时间模式的能力，无法实现上下文感知

Method: 提出双原型自适应解耦框架：1）构建动态双原型库（DDP），包含具有强时间先验的常见模式库和动态记忆关键罕见事件的罕见模式库；2）设计双路径上下文感知路由机制（DPC），从DDP中选择性检索上下文特定模式表示；3）引入解耦引导损失（DGLoss），确保每个原型库专注于其指定角色

Result: 综合实验表明，DPAD在各种真实世界基准测试中，能够一致地提升最先进模型的预测性能和可靠性

Conclusion: DPAD框架通过动态解耦时间模式并实现上下文感知适应，有效解决了现有方法在处理复杂交织时间模式时的局限性，为时间序列预测提供了模型无关的增强方案

Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.

</details>


### [47] [Provably Robust Bayesian Counterfactual Explanations under Model Changes](https://arxiv.org/abs/2601.16659)
*Jamie Duell,Xiuyi Fan*

Main category: cs.LG

TL;DR: 提出PSCE方法，生成具有概率安全保证的反事实解释，确保在高置信度和低预测方差下对模型变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中机器学习模型频繁更新，现有反事实解释容易变得无效或不可靠，需要能够适应模型变化的反事实解释方法。

Method: 基于贝叶斯原理，提出概率安全反事实解释(PSCE)方法，生成δ-安全（高预测置信度）和ε-鲁棒（低预测方差）的反事实解释，将不确定性感知约束集成到优化框架中。

Result: 在多个数据集上验证，与最先进的贝叶斯反事实方法相比，PSCE生成的反事实解释不仅更合理、更具区分性，而且在模型变化下具有可证明的鲁棒性。

Conclusion: PSCE方法为反事实解释提供了形式化的概率保证，能够在模型频繁更新的现实场景中生成可靠的反事实解释。

Abstract: Counterfactual explanations (CEs) offer interpretable insights into machine learning predictions by answering ``what if?" questions. However, in real-world settings where models are frequently updated, existing counterfactual explanations can quickly become invalid or unreliable. In this paper, we introduce Probabilistically Safe CEs (PSCE), a method for generating counterfactual explanations that are $δ$-safe, to ensure high predictive confidence, and $ε$-robust to ensure low predictive variance. Based on Bayesian principles, PSCE provides formal probabilistic guarantees for CEs under model changes which are adhered to in what we refer to as the $\langle δ, ε\rangle$-set. Uncertainty-aware constraints are integrated into our optimization framework and we validate our method empirically across diverse datasets. We compare our approach against state-of-the-art Bayesian CE methods, where PSCE produces counterfactual explanations that are not only more plausible and discriminative, but also provably robust under model change.

</details>


### [48] [Dynamic Expert-Guided Model Averaging for Causal Discovery](https://arxiv.org/abs/2601.16715)
*Adrick Tench,Thomas Demeester*

Main category: cs.LG

TL;DR: 提出一种利用动态请求专家知识（包括LLM）来集成多种因果发现算法的灵活模型平均方法，在干净和噪声数据上验证了其有效性


<details>
  <summary>Details</summary>
Motivation: 医疗领域需要准确因果模型来增强预测模型可解释性，支持反事实和干预推理以及治疗效果估计。但现有因果发现算法众多且无明确最佳选择，同时现实应用常违反算法假设，过度依赖专家知识

Method: 提出灵活的模型平均方法，利用动态请求的专家知识（包括LLM作为专家）来集成多样化的因果发现算法。该方法结合了最近关于动态请求专家知识和LLM作为专家的研究

Result: 实验证明该方法在干净和噪声数据上对不完美专家（如LLM）都有效。分析了不同专家正确度的影响，并评估了LLM在临床因果发现中的能力，为实践者提供了宝贵见解

Conclusion: 通过动态整合专家知识和多种因果发现算法，提供了一种实用的因果发现集成方法，特别适用于医疗领域等需要处理算法假设违反和专家知识依赖的场景

Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.

</details>


### [49] [Sample-wise Constrained Learning via a Sequential Penalty Approach with Applications in Image Processing](https://arxiv.org/abs/2601.16812)
*Francesca Lanzillotta,Chiara Albisani,Davide Pucci,Daniele Baracchi,Alessandro Piva,Matteo Lapucci*

Main category: cs.LG

TL;DR: 提出一种用于深度学习场景的序列惩罚方法，能够将数据样本处理要求作为严格约束而非任意惩罚项，并具有收敛保证


<details>
  <summary>Details</summary>
Motivation: 在许多学习任务中，对单个数据样本的处理要求应该作为优化问题中的严格约束而非任意惩罚项来形式化，但现有方法难以正确处理这类约束

Method: 提出一种序列惩罚方法，能够适当处理约束条件，在深度学习场景中具有收敛保证

Result: 该方法在图像处理任务上的实验结果表明其实际可行性

Conclusion: 序列惩罚方法能够有效处理深度学习中的约束优化问题，具有理论收敛保证和实际应用价值

Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.

</details>


### [50] [Calibrated Probabilistic Interpolation for GEDI Biomass](https://arxiv.org/abs/2601.16834)
*Robin Young,Srinivasan Keshav*

Main category: cs.LG

TL;DR: ANPs替代传统机器学习方法，通过概率元学习框架实现GEDI稀疏LiDAR观测的可靠墙到墙生物量制图，提供校准的预测区间并适应异质景观变化。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法（如随机森林和XGBoost）在处理GEDI稀疏LiDAR观测插值时，将空间预测视为独立事件，未适应异质景观的难度变化，且无法产生校准的预测区间。问题源于将集成方差与偶然不确定性混为一谈，并忽略了局部空间上下文。

Method: 引入注意力神经过程（ANPs），这是一种概率元学习框架，明确将预测条件化于局部观测集和地理空间基础模型嵌入。与静态集成不同，ANPs学习灵活的空间协方差函数，使不确定性估计在复杂景观中扩大，在均匀区域收缩。

Result: 在从热带亚马逊森林到北方和高山生态系统的五个不同生物群落中验证了该方法。ANPs实现了竞争性精度，同时保持接近理想的不确定性校准。通过少样本适应展示了操作实用性，模型使用最少局部数据即可恢复跨区域转移的大部分性能差距。

Conclusion: 该工作为大陆尺度地球观测提供了可扩展、理论严谨的集成方差替代方案，能够可靠地从稀疏GEDI观测生成墙到墙生物量图，并适应异质景观的复杂性。

Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.
  To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.

</details>


### [51] [The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics](https://arxiv.org/abs/2601.16849)
*Henri Nikoleit,Ankit Anand,Anurag Murty Naredla,Heiko Röglin*

Main category: cs.LG

TL;DR: 该研究展示了人类与LLM协作在解决理论计算机科学开放问题中的强大能力，通过改进FunSearch算法的输出来获得组合优化问题中标准启发式算法的最新下界。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索人类专家与大型语言模型(LLM)协作在理论计算机科学研究中的潜力，特别是针对组合优化问题中一些长期未得到改进的经典启发式算法下界问题。

Method: 采用FunSearch算法生成初始模式，然后通过人类专家的迭代精炼来改进输出，针对分层k-median聚类、装箱问题、背包问题以及Lovász汽油问题的推广等具体问题，生成使标准启发式算法表现不佳的对抗性实例。

Result: 成功获得了多个组合优化问题的最新下界，其中一些问题已经十多年没有显著改进。具体包括分层k-median聚类、装箱问题、背包问题以及Lovász汽油问题推广的改进构造。

Conclusion: LLM提供了关键的初始模式，但人类专业知识对于将这些模式转化为数学上严谨且有洞察力的构造至关重要。这项工作表明LLM是数学和计算机科学研究中的强大协作工具。

Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lovász's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.
  Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.

</details>


### [52] [GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints](https://arxiv.org/abs/2601.16905)
*Andy Zhu,Rongzhe Wei,Yupu Gu,Pan Li*

Main category: cs.LG

TL;DR: GRIP框架通过几何约束防止传统遗忘方法利用MoE架构的路由器漏洞，实现真正的知识擦除而非表面路由操纵


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法无法有效应用于MoE架构，因为它们会利用路由器漏洞通过操纵路由而非真正擦除知识，导致模型效用损失和表面遗忘

Method: 提出GRIP框架，通过将路由器梯度更新投影到专家特定零空间来施加几何约束，解耦路由稳定性与参数刚性，保持离散专家选择稳定同时允许连续路由器参数在零空间内可塑

Result: 在大规模MoE模型上的实验表明，GRIP适配器消除了专家选择偏移（实现超过95%的路由稳定性），同时保持了所有测试遗忘方法的效用

Conclusion: GRIP通过防止现有算法利用MoE模型的路由器漏洞，将密集架构的遗忘研究适配到MoE架构，实现了真正的知识擦除而非表面路由操纵

Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.

</details>


### [53] [FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization](https://arxiv.org/abs/2601.16897)
*Antesh Upadhyay,Sang Bin Moon,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: FedSGM是一个统一的联邦约束优化框架，解决了联邦学习中的四大挑战：函数约束、通信瓶颈、本地更新和部分客户端参与，通过投影自由、仅原变量的更新方法，结合双向误差反馈处理压缩，并提供了收敛保证。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临四个主要挑战：1) 函数约束（如公平性、隐私、资源限制等实际问题中的约束条件）；2) 通信瓶颈（客户端与服务器之间的带宽限制）；3) 本地更新（客户端在通信前进行多次本地计算）；4) 部分客户端参与（每轮只有部分客户端可用）。现有方法未能同时解决这些挑战，特别是缺乏处理函数约束的统一框架。

Method: 基于切换梯度方法，FedSGM采用投影自由、仅原变量的更新策略，避免昂贵的对偶变量调优或内部求解器。为处理通信限制，引入双向误差反馈来纠正压缩引入的偏差，并明确理解压缩噪声与多步本地更新之间的相互作用。还提出了软切换版本的FedSGM以稳定在可行性边界附近的更新。

Result: 理论分析表明，平均迭代达到规范的$\mathcal{O}(1/\sqrt{T})$收敛速率，并提供了额外的高概率界限，将优化进展与部分参与引起的采样噪声解耦。实验验证了FedSGM在Neyman-Pearson分类和约束马尔可夫决策过程任务上的理论保证。

Conclusion: FedSGM是首个统一处理函数约束、压缩、多步本地更新和部分客户端参与的框架，为约束联邦学习建立了理论基础。该框架通过投影自由、仅原变量的方法避免了复杂的对偶优化，并通过双向误差反馈有效处理了通信压缩带来的挑战。

Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\boldsymbol{\mathcal{O}}(1/\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.

</details>


### [54] [Embedding -based Crop Type Classification in the Groundnut Basin of Senegal](https://arxiv.org/abs/2601.16900)
*Madeline C. Lisaius,Srinivasan Keshav,Andrew Blake,Clement Atzberger*

Main category: cs.LG

TL;DR: 评估地理空间基础模型嵌入方法在小农户地区作物类型制图中的应用，发现TESSERA方法在性能、合理性、可迁移性和可访问性方面表现最佳


<details>
  <summary>Details</summary>
Motivation: 现有卫星遥感作物类型制图方法大多不适合小农户条件，需要开发适合小农户地区的实用嵌入方法

Method: 建立四部分标准（性能、合理性、可迁移性、可访问性），评估TESSERA和AlphaEarth等地理空间基础模型嵌入方法，并与现有基线方法在塞内加尔花生盆地地区进行比较

Result: TESSERA方法在四个标准中表现最佳，在一个时间迁移示例中比次优方法准确率高28%，表明TESSERA嵌入在塞内加尔作物类型分类和制图任务中有效

Conclusion: TESSERA嵌入方法是小农户地区作物类型制图的有效方法，满足实用嵌入方法的所有标准

Abstract: Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.

</details>


### [55] [The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning](https://arxiv.org/abs/2601.16906)
*Calarina Muslimani,Yunshu Du,Kenta Kawamoto,Kaushik Subramanian,Peter Stone,Peter Wurman*

Main category: cs.LG

TL;DR: 本文提出TAC（轨迹对齐系数）作为评估奖励函数与专家偏好匹配度的指标，研究其在指导人工奖励调优中的有效性，并进一步开发Soft-TAC作为可微近似用于直接从人类偏好数据学习奖励模型。


<details>
  <summary>Details</summary>
Motivation: 强化学习的成功依赖于准确反映任务目标的奖励函数，但奖励函数设计耗时且容易出错。需要支持RL从业者指定合适的奖励权重，并减少人工奖励设计的劳动强度。

Method: 1. 利用TAC评估奖励函数诱导的偏好与领域专家偏好的匹配度；2. 通过人因实验验证TAC在奖励调优中的有效性；3. 提出Soft-TAC作为TAC的可微近似，将其作为损失函数从人类偏好数据训练奖励模型。

Result: 1. 人因实验显示：提供TAC指导时，参与者能产生性能更好的奖励函数，并报告更低认知负荷；2. 在Gran Turismo 7验证中，使用Soft-TAC训练的奖励模型成功捕获偏好特定目标，产生比标准交叉熵损失更明显不同的行为策略。

Conclusion: TAC既能作为指导奖励调优的实用工具，也能作为复杂领域中奖励学习的目标。该工作为奖励函数设计和学习提供了新的方法论支持。

Abstract: The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.

</details>


### [56] [Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces](https://arxiv.org/abs/2601.16907)
*Nicolas Tacheny*

Main category: cs.LG

TL;DR: 该论文提出使用保序回归对预训练嵌入空间中的余弦相似度进行单调校准，以解决各向异性导致的绝对数值系统性误校准问题，同时保持原有的排序相关性和局部稳定性。


<details>
  <summary>Details</summary>
Motivation: 预训练嵌入空间中的原始余弦相似度虽然与人类判断有很强的排序相关性，但由于各向异性导致绝对数值系统性误校准：无论实际语义相关性如何，相似度分数都集中在狭窄的高相似度区间，限制了其作为定量度量的可解释性。先前工作通过修改嵌入空间（白化、对比微调）来解决，但这些变换会改变几何结构并需要重新计算所有嵌入。

Method: 使用基于人类相似性判断训练的保序回归，构建一个单调变换来实现近乎完美的校准，同时保持排序相关性和局部稳定性（在七种扰动类型上达到98%）。该方法将保序校准表征为保序重参数化，并证明所有基于顺序的构造（角度排序、最近邻、阈值图和基于分位数的决策）在此变换下都是不变的。

Result: 该方法实现了近乎完美的校准，同时保持了98%的局部稳定性（跨越七种扰动类型）。保序校准不会改变余弦相似度的排序特性，而是恢复其绝对数值的可解释性，无需改变嵌入空间几何结构或重新计算嵌入。

Conclusion: 保序回归校准提供了一种有效的方法来解决预训练嵌入空间中余弦相似度的绝对数值误校准问题，同时保持其原有的排序相关性和几何结构。该方法不是要取代余弦相似度，而是通过单调校准恢复其绝对数值的可解释性，且证明所有基于顺序的构造在此变换下都是不变的。

Abstract: While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.
  Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.
  We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.

</details>


### [57] [Group-realizable multi-group learning by minimizing empirical risk](https://arxiv.org/abs/2601.16922)
*Navid Ardeshir,Samuel Deng,Daniel Hsu,Jingwen Liu*

Main category: cs.LG

TL;DR: 多群体学习在群体可实现设置下的样本复杂度优于不可知设置，即使群体族有无限VC维，只要其VC维有限。通过经验风险最小化实现改进，但计算不可行，建议使用非适当学习替代。


<details>
  <summary>Details</summary>
Motivation: 研究多群体学习在不同设置下的样本复杂度差异，探索在群体族具有有限VC维但概念类可能具有无限VC维的情况下，如何获得更好的学习性能。

Method: 1. 分析群体可实现设置下的经验风险最小化方法；2. 证明该方法在计算上不可行；3. 提出基于非适当学习的替代方法。

Result: 群体可实现设置下的样本复杂度优于不可知设置，即使群体族是无限的（只要其VC维有限）。经验风险最小化在群体可实现概念类上能获得改进，但计算不可行。

Conclusion: 多群体学习在群体可实现设置下具有理论上的样本复杂度优势，但需要采用非适当学习等替代方法来解决计算不可行性问题。

Abstract: The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.

</details>


### [58] [3D Molecule Generation from Rigid Motifs via SE(3) Flows](https://arxiv.org/abs/2601.16955)
*Roman Poletukhin,Marcel Kollovieh,Eike Eberhard,Stephan Günnemann*

Main category: cs.LG

TL;DR: 该论文提出了一种基于刚性基元的三维分子生成方法，将分子视为刚性基元集合而非单个原子，实现了更高效的SE(3)等变生成建模。


<details>
  <summary>Details</summary>
Motivation: 传统三维分子结构生成通常在原子级别进行，而分子图生成技术常将片段作为结构单元。受蛋白质结构生成中框架方法的启发，作者希望将这种片段化思想扩展到三维分子生成，将一般分子视为刚性基元集合，以提高生成效率和表示压缩。

Method: 采用刚性基元作为分子表示的基本单元，而非传统原子表示。利用SE(3)-等变生成建模技术进行从头三维分子生成。该方法将分子表示为刚性基元集合，每个基元作为刚体处理。

Result: 在多个基准测试中取得与现有最优方法相当或更优的结果，在GEOM-Drugs数据集上原子稳定性表现更佳。同时实现了2-10倍的生成步骤减少，以及相比标准原子方法3.5倍的分子表示压缩。

Conclusion: 基于刚性基元的三维分子生成方法在保持或提高生成质量的同时，显著提升了计算效率和表示压缩率，为高效分子设计提供了新途径。

Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.

</details>


### [59] [Auto-Regressive Masked Diffusion Models](https://arxiv.org/abs/2601.16971)
*Mahdi Karami,Ali Ghodsi*

Main category: cs.LG

TL;DR: ARMD模型通过将掩码扩散过程重构为块级因果模型，统一了自回归模型的训练效率和扩散模型的并行生成能力，在语言建模任务上实现了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型（MDMs）在语言建模中存在性能差距，需要更多训练迭代。需要一种既能保持自回归模型训练效率，又能实现扩散模型并行生成能力的新架构。

Method: 将掩码扩散过程重构为块级因果模型，设计严格因果、置换等变架构，在单次前向传递中计算所有条件概率。采用渐进置换训练方案，支持跨步并行生成策略。

Result: 在标准语言建模基准测试中实现最先进性能，超越现有扩散基线，显著减少训练步骤，为并行文本生成设立新基准。

Conclusion: ARMD模型有效弥合了并行和顺序解码之间的性能差距，统一了自回归训练效率和扩散并行生成的优势。

Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.

</details>


### [60] [Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection](https://arxiv.org/abs/2601.16976)
*Estela Sánchez-Carballo,Francisco M. Melgarejo-Meseguer,José Luis Rojo-Álvarez*

Main category: cs.LG

TL;DR: 该论文提出使用潜在扩散模型(LDM)进行物联网攻击数据增强，以解决机器学习入侵检测系统中的类别不平衡问题，相比现有方法在样本保真度、多样性和计算效率方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 物联网环境中基于机器学习的入侵检测系统面临严重的类别不平衡问题（正常流量远多于攻击流量），现有数据增强方法（如简单过采样或生成模型）难以同时实现高样本保真度、多样性和计算效率。

Method: 提出使用潜在扩散模型进行物联网攻击数据增强，在潜在空间而非原始数据空间进行扩散过程，并与最先进的基线方法进行全面比较。实验针对三种代表性物联网攻击类型（DDoS、Mirai、中间人攻击），评估下游IDS性能和内在生成质量。

Result: 使用LDM生成的样本平衡训练数据显著提高了IDS性能，DDoS和Mirai攻击的F1分数达到0.99，始终优于竞争方法。定量和定性分析表明，LDM能有效保持特征依赖关系、生成多样样本，且采样时间比直接在数据空间操作的扩散模型减少约25%。

Conclusion: 潜在扩散模型是物联网攻击数据生成的有效且可扩展解决方案，能显著减轻物联网场景中基于机器学习的入侵检测系统的类别不平衡影响。

Abstract: Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely explored to mitigate this issue, existing approaches typically rely on simple oversampling techniques or generative models that struggle to simultaneously achieve high sample fidelity, diversity, and computational efficiency. To address these limitations, we propose the use of a Latent Diffusion Model (LDM) for attack data augmentation in IoT intrusion detection and provide a comprehensive comparison against state-of-the-art baselines. Experiments were conducted on three representative IoT attack types, specifically Distributed Denial-of-Service (DDoS), Mirai, and Man-in-the-Middle, evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Results show that balancing the training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores of up to 0.99 for DDoS and Mirai attacks and consistently outperforming competing methods. Additionally, quantitative and qualitative analyses demonstrate that LDMs effectively preserve feature dependencies while generating diverse samples and reduce sampling time by approximately 25\% compared to diffusion models operating directly in data space. These findings highlight latent diffusion as an effective and scalable solution for synthetic IoT attack data generation, substantially mitigating the impact of class imbalance in ML-based IDSs for IoT scenarios.

</details>


<div id='math.CV'></div>

# math.CV [[Back]](#toc)

### [61] [A Non-Autonomous Model for Parabolic Implosion](https://arxiv.org/abs/2601.16311)
*Katelynn Huneycutt,Samantha Sandberg-Clark,Liz Vivas*

Main category: math.CV

TL;DR: 该论文研究与非自主扰动抛物莫比乌斯映射相关的正交多项式，探讨非自主抛物内爆现象，包括随机扰动下的几乎必然收敛


<details>
  <summary>Details</summary>
Motivation: 正交多项式自然出现在莫比乌斯变换复合的研究中，作者希望探索与非自主扰动的抛物莫比乌斯映射相关的正交多项式类，研究非自主抛物内爆现象

Method: 考虑与非自主扰动的抛物莫比乌斯映射相关的几类正交多项式，分析这些多项式在非自主扰动下的行为，特别关注随机扰动机制

Result: 研究结果可视为非自主抛物内爆的实例，包括在随机扰动机制下几乎必然收敛的情况

Conclusion: 正交多项式与莫比乌斯变换复合的关联为研究非自主扰动抛物映射提供了新视角，随机扰动下的收敛性结果扩展了抛物内爆理论

Abstract: Orthogonal polynomials appear naturally in the study of compositions of Möbius transformations. In this paper, we consider several classes of orthogonal polynomials associated to non-autonomous perturbations of a parabolic Möbius map. Our results can be viewed as instances of non-autonomous parabolic implosion, including a random perturbative regime in which convergence holds almost surely.

</details>


### [62] [$L^p$--$L^q$ estimates for Shimorin-type integral operators](https://arxiv.org/abs/2601.16493)
*Yuerang Li,Zipeng Wang,Kenan Zhang*

Main category: math.CV

TL;DR: 研究Shimorin型算子T_ν在单位圆盘上的L^p-L^q有界性，确定临界边界并分析临界线上的新现象


<details>
  <summary>Details</summary>
Motivation: Shimorin型算子源于对数次调和加权Bergman空间的核表示研究，其L^p-L^q有界性的临界边界不明显，且临界线上出现新现象，需要系统分析

Method: 引入量c_ν，在(1/p,1/q)平面上确定T_ν有界性的临界边界，并在临界线上建立标准Bergman型L^p-L^q估计的充要条件

Result: 确定了T_ν有界性的临界边界，在临界线上建立了弱型和BMO型端点估计的充要条件，揭示了与经典Bergman算子的不同特性

Conclusion: Shimorin型算子的L^p-L^q有界性分析需要新的方法，临界线上的行为呈现新现象，为这类算子的调和分析性质提供了完整刻画

Abstract: Let $ν$ be a positive measure on $[0,1]$. A Shimorin-type operator $T_ν$ is an integral operator on the unit disk given by \[ T_νf(z) = \int_{\mathbb{D}} \frac{1}{1 - z\overlineλ} \left( \int_0^1 \frac{dν(r)}{1 - r z \overlineλ} \right) f(λ) \, dA(λ), \] which originates from Shimorin's work on Bergman-type kernel representations for logarithmically subharmonic weighted Bergman spaces.
  In this paper, we study $L^p$--$L^q$ estimates for $T_ν$. Unlike classical Bergman-type operators, the critical line on the $(1/p,1/q)$-plane that separates the boundedness and unboundedness regions of $T_ν$ is not immediately evident. Moreover, even along this line, new phenomena arise. In the present work, by introducing a quantity $c_ν$, \begin{itemize}
  \item we first determine the critical boundary in the $(1/p,1/q)$-plane for bounded $T_ν$;
  \item furthermore, on this critical line, we establish necessary and sufficient conditions for $T_ν$ which have standard Bergman-type $L^p$--$L^q$ estimates, meaning that it is bounded in the interior of the region and admits weak-type and BMO-type estimates at endpoints. \end{itemize}

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [63] [Diffusion Model Driven Airfoil Design: From Geometry Encoding to Practical Applications](https://arxiv.org/abs/2601.16228)
*Yingfan Geng,Jinhong Wang,Teng Cao*

Main category: physics.flu-dyn

TL;DR: 该研究比较了扩散模型在三种不同翼型数据编码格式（主成分权重、有序坐标、2D符号距离函数）上的性能，发现直接使用坐标训练效果最佳，并提出了基于扩散过程随机性的多目标优化方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型作为最先进的生成式机器学习架构，在翼型逆向设计中显示出潜力。本研究旨在系统比较扩散模型在不同翼型几何数据编码格式上的性能，探索最适合2D翼型设计的数据结构，并研究扩散模型在实际工程应用中的部署。

Method: 研究实现并训练了一系列扩散模型，使用三种不同的翼型几何数据编码格式：1）主成分权重（PCA权重），2）有序x-y坐标，3）2D符号距离函数（SDF）。通过系统比较不同数据结构上训练的扩散模型性能，评估各格式的优劣。此外，提出了基于扩散过程随机性的多目标优化流程，并研究了模型在超出训练集边界条件下的外推性能。

Result: 对于2D翼型设计问题，直接使用坐标训练的扩散模型性能最佳。使用潜在空间（PCA权重）训练会限制模型的设计自由度并降低训练效果。2D SDF数据虽然性能最差，但证明了在气动形状生成中的可行性，为更受青睐的3D问题铺平了道路。提出的多目标优化流程相比传统方法大大简化，模型在外推条件下的性能也得到了验证。

Conclusion: 扩散模型在翼型逆向设计中表现出色，直接使用坐标数据训练效果最好。SDF格式虽然当前性能有限，但在3D问题中具有潜力。基于扩散过程随机性的多目标优化方法为实际工程应用提供了简化方案，模型具备一定的外推能力。

Abstract: Diffusion model, the state-of-the-art generative machine learning architecture, has shown promising results airfoil inverse designs. In this study, we implemented and trained a series of diffusion models on three different airfoil geometry data encoding formats -- principal component weights, ordered $x$-$y$ coordinates, and 2D signed distance functions (SDF) -- to generate 2D airfoils. By systematically comparing the performance of diffusion models trained on different data structures, it is found that for 2D airfoil design problems, the diffusion model performs the best when directly trained with coordinates. Training with latent space (PCA weights in this study) limits the model's design freedom, and decreases the training effectiveness. Although the 2D SDF data appears to result in the least performing model, it proves its feasibility in aerodynamic shape generation, paving the way towards 3D problems where SDF is more favored. This study also investigated deploying the diffusion model in practical engineering applications. A multi-target optimization procedure is proposed based on the stochastic nature of the diffusion process, which drastically simplifies the procedure compared to conventional methods. The extrapolation performance of the model is also investigated by tasking the model with both aerodynamic and flow condition labels that are extrapolated beyond the training set boundaries.

</details>


### [64] [A Study of Improved Limiter Formulations for Second-Order Finite Volume Schemes Applied to Unstructured Grids](https://arxiv.org/abs/2601.16291)
*Frederico Bolsoni Oliveira,João Luiz F. Azevedo*

Main category: physics.flu-dyn

TL;DR: 该研究比较了三种限制器（Venkatakrishnan、Wang修正版、Nishikawa R3）在非结构网格二阶有限体积法中的表现，通过NACA 0012翼型跨音速湍流模拟验证，发现适当参数下三者结果相似但耗散特性不同。


<details>
  <summary>Details</summary>
Motivation: 在有限体积法中，MUSCL类分段线性重构常需限制器抑制数值振荡，但限制器会引入一系列缺点。本研究旨在通过比较三种不同限制器在非结构网格二阶有限体积法中的表现，分析其对数值方案的影响。

Method: 采用二阶有限体积法模拟非结构网格上的稳态湍流流动，比较三种限制器：原始Venkatakrishnan限制器、Wang修正版和Nishikawa R3限制器。使用雷诺平均Navier-Stokes方程建模气体动力学，负Spalart-Allmaras湍流模型解决封闭问题。分析NACA 0012翼型在不同攻角下的二维跨音速流动配置。

Result: 所有限制器在该案例的各种配置下均能产生相似结果，但具有不同的耗散特性，前提是控制常数在适当区间内使用。数值结果与文献中的实验数据吻合良好。

Conclusion: 三种限制器在适当参数设置下均能获得可接受的结果，但具有不同的数值耗散特性。研究强调了限制器控制参数选择的重要性，并验证了二阶有限体积法在跨音速湍流模拟中的可靠性。

Abstract: A general, compact way of achieving second-order in finite-volume numerical methods is to perform a MUSCL-like, piecewise linear reconstruction of flow properties at each cell interface. To avoid the surge of spurious oscillations in the discrete solution, a limiter function is commonly employed. This strategy, however, can add a series of drawbacks to the overall numerical scheme. The present paper investigates this behavior by considering three different limiter formulations in the context of a second-order, finite volume scheme for the simulation of steady, turbulent flows on unstructured meshes. Three limiter formulations are considered: the original Venkatakrishnan limiter, Wang's modification to the Venkatakrishnan limiter and Nishikawa's recently introduced R3 limiter. Three different configurations of the fully-developed, two-dimensional, transonic NACA 0012 airfoil are analyzed, configured with different angles of attack and similar freestream properties. The gas dynamics are modeled using the Reynolds-averaged Navier-Stokes (RANS) equations, where the negative Spalart-Allmaras turbulence model is used to solve the closure problem. All limiters are shown to yield similar results for all configurations of this case, although with different dissipative characteristics, provided their control constants are used within appropriate intervals. The presented numerical results are in good agreement with experimental data available in the literature.

</details>


### [65] [Elucidating Three-Dimensional Coherent Structures in a Multi-Stream Jet](https://arxiv.org/abs/2601.16351)
*Mitesh Thakor,Datta V Gaitonde,Yiyang Sun*

Main category: physics.flu-dyn

TL;DR: 研究真实喷嘴配置中三维剪切层结构，揭示低频宽带与高频单频动力学的分离机制及其对矩形射流轴切换行为的影响。


<details>
  <summary>Details</summary>
Motivation: 传统二维剪切层研究已较成熟，但实际工程配置中剪切层行为受邻近表面影响显著。本研究旨在探究真实喷嘴配置（包含侧壁、上边界单膨胀斜坡和下边界突出甲板）中三维相干结构的形成机制，特别是厚分流板下游的复杂剪切层动力学。

Method: 采用大涡模拟获取非定常流动数据，结合谱本征正交分解分离宽带与单频动力学特征。使用三全局解析分析阐明上下剪切层的放大机制，并通过波制造分析验证自持低频动力学。

Result: 谱本征正交分解显示宽带低频模态与单频高频模态在频带上清晰分离：低频宽带模态高度三维化，起源于上下剪切层；高频单频内容与分流板剪切层的二维不稳定性相关。三全局解析分析表明低频响应模态由喷嘴几何附近的局部强迫激发，受三维Kelvin-Helmholtz动力学控制。喷嘴角处产生的低频流向涡驱动了矩形射流特有的轴切换行为。

Conclusion: 真实喷嘴配置中的剪切层动力学呈现显著的三维特征，低频宽带与高频单频机制在空间和频率上分离。喷嘴角处产生的三维涡结构是驱动矩形射流轴切换行为的关键机制，这些角涡构成自持低频动力学的一部分，对实际工程应用中的流动控制具有重要意义。

Abstract: Nominal two-dimensional (2D) shear layers have been studied extensively, and their principal dynamics are well understood. In practical configurations, however, the behavior of such shear layers is affected by proximal surfaces. In this study, we investigate three-dimensional (3D) coherent structures developing downstream of a relatively thick splitter plate in a realistic nozzle featuring sidewalls, an upper boundary formed by a single expansion ramp, and a lower boundary defined by a protruding deck. As a result, in addition to the primary splitter plate shear layer (SPSL) arising from mixing between the core and bypass streams, the flow contains upper (USL) and lower (LSL) shear layers with the ambient. Large-eddy simulation data are analyzed to characterize the unsteady flow dynamics, while the mean flow provides insight into the underlying amplification mechanisms. Spectral proper orthogonal decomposition reveals a clear separation of broadband and tonal dynamics across frequency bands. The broadband low-frequency modes are highly 3D and originate in the USL and LSL. In contrast, tonal high-frequency content is associated with a 2D instability in the SPSL. Both the broadband and tonal signatures also appear in the nonlinear energy transfer mechanisms. Triglobal resolvent analysis further clarifies the amplification mechanisms within the USL and LSL. Low-frequency response modes are excited by forcing localized near the nozzle geometry and are governed by 3D Kelvin-Helmholtz dynamics. The low-frequency streamwise vortices generated at the nozzle corners drive the axis-switching behavior characteristic of rectangular jets. Wavemaker analysis further demonstrates that these corner vortices are part of self-sustaining low-frequency dynamics.

</details>


### [66] [Relation between the moments of longitudinal velocity derivatives and of dissipation in turbulence](https://arxiv.org/abs/2601.16436)
*Ping-Fan Yang,Haitao Xu,Alain Pumir*

Main category: physics.flu-dyn

TL;DR: 论文证明在均匀各向同性湍流中，能量耗散率ε的替代量ε_s = 15ν(∂₁u₁)²的高阶矩(n>2)与ε的高阶矩不完全成正比，还涉及应变张量不变量tr(S³)的贡献。


<details>
  <summary>Details</summary>
Motivation: 在湍流研究中，通常使用纵向速度导数∂₁u₁来估计能量耗散率ε，因为它们的平均值相等。然而，对于高阶统计矩，这种替代关系是否仍然成立尚不清楚。本文旨在探究ε和ε_s的高阶矩之间的精确关系。

Method: 通过理论分析推导ε_sⁿ矩的精确表达式，揭示其与εⁿ矩的关系。特别关注应变张量S的三次不变量tr(S³)的贡献，并分析无量纲比R≡tr(S³)/tr(S²)^{3/2}的分布影响。将理论结果与高斯分布假设下的近似进行比较。

Result: 对于n≥3的高阶矩，⟨ε_sⁿ⟩不仅包含与⟨εⁿ⟩成正比的项，还包含涉及tr(S³)的额外贡献项。研究发现，即使假设R在区间[-1/√6, 1/√6]内均匀分布（对应S的高斯分布），所得关系与精确分布的差异也不超过几个百分点。

Conclusion: 虽然ε_s = 15ν(∂₁u₁)²在平均值意义上能准确估计能量耗散率ε，但对于高阶统计矩(n>2)，两者不完全成正比。不过，即使采用简化的高斯分布假设，所得近似与精确结果的差异也很小，这在湍流测量实践中具有重要意义。

Abstract: In homogeneous and isotropic turbulence, measurements of the longitudinal velocity derivative, $\partial_1 u_1$, make it possible to estimate a surrogate of the rate of energy dissipation per unit mass, $ε$: $ε_s = 15 ν(\partial_1 u_1)^2 $, where $ν$ is the fluid viscosity, in the sense that the averages of $ε$ and $ε_s$ are equal. We show here that the $n^{th}$ moments of the fluctuations $ε$ and $ε_s$, for $n > 2$, are not exactly proportional to each other, and that the expression for the moment $\langle ε_s^n \rangle$ for $ n \ge 3$ involves in addition to a term proportional to $\langle ε^n \rangle$, other contributions involving the invariant of the strain tensor, $\SSs$: ${\rm tr}( \SSs^3)$. The contribution of this term depends on the distribution of the dimensionless ratio $\mathcal{R} \equiv {\rm tr}(\SSs^3)/{\rm tr}(\SSs^2)^{3/2}$. We find, however, that the relation obtained by assuming that $\mathcal{R}$ is uniformly distributed in the interval $-1/\sqrt{6} \le \mathcal{R} \le 1/\sqrt{6}$, which is obtained when the matrix $\SSs$ has a Gaussian distribution, differs by no more than a few percents from the exact distribution.

</details>


### [67] [Numerical investigation of unsteady flow in a reversible pump-turbine](https://arxiv.org/abs/2601.16584)
*Chirag Trivedi*

Main category: physics.flu-dyn

TL;DR: 该研究通过计算流体动力学模拟分析了模型水泵水轮机的非定常流场，重点关注了水轮机模式和泵模式下的流动特性差异，发现了泵模式下高阶谐波频率可能引发共振风险以及尾水管中迪恩涡旋导致的非对称流动。


<details>
  <summary>Details</summary>
Motivation: 水泵水轮机作为重要的可再生能源存储设备，在水轮机模式和泵模式下的流动条件存在显著差异。为了深入理解这种复杂流动现象，特别是非定常流动行为，需要进行详细的流场分析以优化设备性能和安全性。

Method: 研究创建了水泵水轮机的计算模型，采用包含5819万个节点的六面体网格。进行了总验证和验证误差为7.7%的数值模拟，分析了水轮机模式下的三种运行工况和泵模式下的四种运行工况。研究了叶片载荷、时变压力脉动、频率谱、径向和切向速度等流动特性。

Result: 频率分析显示泵模式下存在高达叶片通过频率十次谐波的频率振幅，这些高阶谐波频率可能达到高模态特征频率，增加共振风险。尾水管流场分析表明迪恩涡旋的强烈存在导致泵模式下转轮入口处高度非对称流动。

Conclusion: 该研究为水泵水轮机中复杂流动现象提供了重要见解，增进了对非定常流动行为的理解，特别强调了泵模式下高阶谐波频率的共振风险和迪恩涡旋导致的流动非对称性，对设备设计和运行安全具有重要意义。

Abstract: Hydropower is an important source of renewable energy that provides clean energy. Pump-turbine type hydraulic turbine is widely used to mitigate the intermittent energy demand and store a large-scale energy. Pump-turbine operates in reverse mode in pump mode to store energy. Flow conditions in turbine mode and pump mode operations is substantially different. This study investigates the unsteady flow field in the model pump-turbine. A computational model of the pump-turbine was created, and the model included hexahedral mesh of 58.19 million nodes. Total verification and validation error was 7.7%. Three operating conditions in turbine mode and four in pump mode were simulated. Flow characteristics, such as blade loading, time-dependent pressure fluctuations, frequency spectra, radial and tangential velocity were investigated. The frequency spectra revealed amplitude of frequencies up to tenth harmonics of the blade passing frequency in pump mode. The higher harmonic frequencies can potentially reach the high mode eigen frequencies and increase the risk of resonance. Flow field analysis in the draft tube indicted the strong presence of Dean vortices causing highly asymmetric flow at the runner inlet in pump mode operation. This study provides essential insights into the complex flow phenomena and advances the understanding of unsteady flow behaviour in pump-turbines.

</details>


### [68] [Libby-Fox perturbations and the analytic adjoint solution for laminar viscous flow along a flat plate](https://arxiv.org/abs/2601.16718)
*Carlos Lozano,Jorge Ponsin*

Main category: physics.flu-dyn

TL;DR: 研究二维平板边界层伴随方程的性质，基于描述Blasius边界层代数扰动的Libby-Fox理论，通过格林函数方法获得伴随解，分析得到特征值和特征函数的约束条件，并简要扩展到有压力梯度的Falkner-Skan情况。


<details>
  <summary>Details</summary>
Motivation: 从Libby-Fox理论视角研究二维平板边界层伴随方程的性质，该理论描述了Blasius边界层的代数扰动。研究伴随解的特性有助于理解边界层扰动的数学结构和约束条件。

Method: 通过扰动方程的格林函数方法获得伴随解，将其表示为Blasius解无限扰动模态的和。分析伴随解的性质，推导特征值和特征函数的约束条件。将分析扩展到具有非零压力梯度的Falkner-Skan解情况。

Result: 获得了伴随解的具体形式，分析得到了特征值和特征函数的约束条件。这些约束条件为边界层扰动分析提供了数学基础，并成功将分析框架扩展到Falkner-Skan边界层情况。

Conclusion: 基于Libby-Fox理论成功分析了二维平板边界层伴随方程的性质，获得了重要的数学约束条件，并将分析框架扩展到更一般的压力梯度情况，为边界层稳定性分析提供了理论工具。

Abstract: The properties of the solution to the adjoint two-dimensional boundary layer equations on a flat plate are investigated from the viewpoint of Libby-Fox theory that describes the algebraic perturbations to the Blasius boundary layer. The adjoint solution is obtained from the Green's function of the perturbation equation as a sum over the infinite perturbation modes of the Blasius solution. The analysis of the solution allows us to obtain constraints on the eigenvalues and eigenfunctions. The extension of the analysis to the case with non-zero pressure gradient, corresponding to the Falkner-Skan solution, is also briefly discussed.

</details>


### [69] [Thermodynamically consistent large-eddy simulation models](https://arxiv.org/abs/2601.16957)
*Thomas Dubos*

Main category: physics.flu-dyn

TL;DR: 论文推导了多组分流体任意状态方程下的滤波预算和湍流感热通量表达式，构建了满足热力学第一、第二定律的亚网格闭合模型族，并证明了顺梯度闭合与热力学定律的一致性。


<details>
  <summary>Details</summary>
Motivation: 研究多组分流体湍流建模中如何确保亚网格闭合方案与热力学基本定律（特别是熵增原理）保持一致，解决传统建模方法在热力学一致性方面存在的缺陷。

Method: 推导了多组分流体任意状态方程下的滤波预算方程和湍流感热通量一般表达式；在满足热力学第一、第二定律以及不相关热力学常数不变性的约束下，构建了亚网格闭合模型族；通过启发式方法构造了完全可压缩模型族。

Result: 明确推导了滤波模型中的局部熵产生率表达式；证明了当热和组分湍流扩散系数为正且无交叉扩散时，熵产生为正；给出了交叉扩散系数的容许范围判据；发现滤波模型比未滤波模型具有更广泛的不变性；在单一湍流扩散系数情况下，可以预报任意守恒变量而忽略其与熵的精确关系。

Conclusion: 顺梯度闭合方案与热力学第一、第二定律一致，即使它们导致湍流感热通量沿温度梯度向上传输；分子传导/扩散是自发的且能量守恒，而分层湍流混合由机械湍流驱动并通过消耗湍流动能实现。

Abstract: Filtered budgets for anelastic turbulence and a general expression of the turbulent sensible heat flux are derived for a multicomponent fluid with an arbitrary equation of state. A family of subgrid-scale closures is then found under the constraint of consistency with (i) the first and second laws of thermodynamics and (ii) invariance with respect to irrelevant thermodynamic constants. A similar family of fully compressible models is also constructed heuristically. These models predict turbulent kinetic energy, assume down-gradient closures for three-dimensional turbulent fluxes and impose certain relationships between the closures for the turbulent fluxes of heat, matter, entropy, and the work of buoyancy forces.
  A key finding is the explicit derivation of the local rate of entropy production in the filtered model. Positive entropy production is guaranteed whenever the turbulent diffusions of heat and composition are positive and no cross-diffusion occurs. Cross-diffusivities are admissible provided their magnitude is within the bounds of an explicit criterion. The filtered model is invariant under a wider class of transformations than the unfiltered model. Furthermore, in the special case of a single turbulent diffusivity, an arbitrary conservative variable can be prognosed while ignoring its precise relationship to entropy.
  These findings show that down-gradient closures are consistent with the first and second law of thermodynamics even when they lead to a turbulent sensible heat flux up the temperature gradient. Indeed, while molecular conduction/diffusion is spontaneous and energy-conserving, stratified turbulent mixing is driven by mechanical turbulence and enabled by the consumption of turbulent kinetic energy.

</details>
